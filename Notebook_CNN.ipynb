{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Plogeur/HAI923/blob/master/Notebook_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHoI_qwJETpf"
      },
      "source": [
        "<H1> Notebook : Création des modèles CNN </H1>\n",
        "\n",
        "Le modèles de réseaux de neurones convolutionnels Convolutional Neural Networks, sont devenus l'épine dorsale de nombreuses applications de pointe en traitement d'images, de la détection d'objets à la segmentation sémantique en passant par la reconnaissance d'images. Au cours de ce notebook, nous aborderons des sujets tels que l'architecture de base d'un CNN, la sélection de couches de convolution, de pooling et de normalisation, ainsi que les stratégies de régularisation pour améliorer la généralisation. Nous explorerons également le transfert d'apprentissage et le fine tuning à l'aide de réseaux pré-entraînés, afin d'exploiter des modèles déjà entraînés pour résoudre des problèmes spécifiques. Enfin, à moins que la procrastination ne l'emporte, nous aborderons également les transformateurs avec l'utilisation de l'architecture ViT.\n",
        "\n",
        "*Note à moi-même : c'est mort pour le VIT j'ai déjà la flemme de faire le reste*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VQSC8frX5Ao"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7eBBrtYb7_z",
        "outputId": "cdd8169c-4432-4b35-f1f4-3dff4388c463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.10/dist-packages (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZw2C6r8YJWW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import random\n",
        "import shutil\n",
        "import keras\n",
        "import pathlib\n",
        "import sys\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow as tf\n",
        "from keras import metrics\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.saving import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.regularizers import L1L2\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam, Adamax, Lion\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Input, Activation, Reshape, Dropout, Dense, GlobalAveragePooling2D, Flatten, Rescaling, Conv2D, BatchNormalization, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c2nI_bUG0lo",
        "outputId": "f18b1725-2a1b-4663-8a4e-a986dab6feac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Colab Notebooks\n",
            "/content/gdrive/MyDrive/Colab Notebooks/HAI923\n"
          ]
        }
      ],
      "source": [
        "# GLOBAL VARIABLE\n",
        "IMG_SIZE = 256\n",
        "CHANEL = 3\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, CHANEL)\n",
        "BATCH_SIZE = 4\n",
        "N_KFOLDS = 10\n",
        "STOPPING_PATIENCE = 200\n",
        "REDUCTION_PATIENCE = 15\n",
        "EPOCHS = 120\n",
        "VERBOSE = 1\n",
        "COLUMNS = 25\n",
        "SEED = 123\n",
        "POLICE_SIZE = 18 # Taille de la police pour les plot\n",
        "plt.rcParams.update({'font.size': POLICE_SIZE})\n",
        "\n",
        "# SET SEED\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# CALLBACKS\n",
        "def callbacks(modelName) :\n",
        "  EARLY_STOPPING = \\\n",
        "          EarlyStopping(\n",
        "              monitor='val_loss',\n",
        "              patience=STOPPING_PATIENCE,\n",
        "              verbose=VERBOSE,\n",
        "              mode='auto')\n",
        "\n",
        "  LR_REDUCTION = \\\n",
        "          ReduceLROnPlateau(\n",
        "              monitor='val_accuracy',\n",
        "              patience=REDUCTION_PATIENCE,\n",
        "              verbose=VERBOSE,\n",
        "              factor=0.5,\n",
        "              min_lr=0.00001)\n",
        "\n",
        "  CHECKPOINT = ModelCheckpoint(f\"Saved_Model/{modelName}.h5\", monitor='val_accuracy', verbose=VERBOSE,\n",
        "      save_best_only=True, mode='auto', save_freq=\"epoch\")\n",
        "\n",
        "  CALLBACKS = [EARLY_STOPPING, LR_REDUCTION, CHECKPOINT]\n",
        "  return CALLBACKS\n",
        "\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.F1Score(threshold=0.5, dtype='float32', name='f1_score')\n",
        "      ]\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "%cd /content/gdrive/MyDrive/Colab Notebooks/\n",
        "%mkdir -p HAI923/Résultats/Entrainement/\n",
        "%mkdir -p HAI923/Saved_Model/\n",
        "%cd HAI923/\n",
        "%pwd\n",
        "\n",
        "import zipfile\n",
        "if not(os.path.exists('Tiger-Fox-Elephant/')) :\n",
        "  if not(os.path.exists('Tiger-Fox-Elephant.zip')) :\n",
        "    !wget https://www.lirmm.fr/~poncelet/Ressources/Tiger-Fox-Elephant.zip\n",
        "  with zipfile.ZipFile(\"Tiger-Fox-Elephant.zip\",\"r\") as zip_ref :\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EbSJ_0DGdYH"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaHyQ2mY15Ie"
      },
      "outputs": [],
      "source": [
        "def create_dataset(my_path, my_classes, gray=False, onehot=False) :\n",
        "  X,y=create_X_y(my_path, my_classes, gray, onehot)\n",
        "  print(\"Les classes : \", my_classes)\n",
        "  print(\"Nombres de données : \", X.shape[0])\n",
        "  print (\"Résolution des images : \", X[0].shape)\n",
        "  X=X.astype('float')\n",
        "  X=X/255.0\n",
        "  return X,y\n",
        "\n",
        "def create_training_data(path_data, list_classes, gray=False):\n",
        "  training_data=[]\n",
        "  for classes in list_classes:\n",
        "    path=os.path.join(path_data, classes)\n",
        "    class_num=list_classes.index(classes)\n",
        "    for img in os.listdir(path):\n",
        "      try :\n",
        "        if gray == False :\n",
        "          img_array = cv2.imread(os.path.join(path,img), cv2.COLOR_BGR2RGB)\n",
        "          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "        else :\n",
        "          img_array = cv2.imread(os.path.join(path,img), cv2.COLOR_BGR2GRAY)\n",
        "          equ = cv2.equalizeHist(new_array)\n",
        "          new_array = np.hstack((new_array,equ))\n",
        "        training_data.append([new_array, class_num])\n",
        "      except Exception as e:\n",
        "        pass\n",
        "  return training_data\n",
        "\n",
        "def create_X_y(path_data, list_classes, gray=False, onehot=False):\n",
        "      training_data=create_training_data(path_data, list_classes, gray)\n",
        "      random.shuffle(training_data)\n",
        "      X=[]\n",
        "      y=[]\n",
        "      for features, label in training_data:\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "      if gray == False :\n",
        "        X=np.array(X).reshape(-1,IMG_SIZE, IMG_SIZE, 3)\n",
        "      else :\n",
        "        X=np.array(X).reshape(-1,IMG_SIZE, IMG_SIZE, 1)\n",
        "      if onehot == False :\n",
        "        y=np.array(y, dtype=np.float32)\n",
        "      else :\n",
        "        y=to_categorical(y, dtype=np.float32) #onehot\n",
        "\n",
        "      return X,y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrainement"
      ],
      "metadata": {
        "id": "vaeN26nLNAJo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcd9vnFHcf6x"
      },
      "outputs": [],
      "source": [
        "def trainModelNumpyAugment(givenModel, modelName=None) :\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.05,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    if modelName == None :\n",
        "      model = givenModel()\n",
        "      CALLBACKS = callbacks(str(givenModel.__name__))\n",
        "    else :\n",
        "      model = givenModel(modelName)\n",
        "      CALLBACKS = callbacks(str(givenModel.__name__)+str(modelName.__name__))\n",
        "\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    # fit du modele\n",
        "    history = model.fit(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n",
        "                        validation_data=(X_val, Y_val), epochs=EPOCHS,\n",
        "                        verbose=VERBOSE, callbacks=CALLBACKS)\n",
        "\n",
        "    # evaluate du modele\n",
        "    model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "\n",
        "    #plot acc and loss in function of epochs\n",
        "    if modelName == None :\n",
        "      plotCurve(history, str(givenModel.__name__))\n",
        "    else :\n",
        "      plotCurve(history, str(givenModel.__name__)+str(modelName.__name__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mediane(liste):\n",
        "    liste_triee = sorted(liste)\n",
        "    n = len(liste_triee)\n",
        "\n",
        "    if n % 2 == 1:\n",
        "        # Cas de nombre impair d'éléments\n",
        "        mediane = liste_triee[n // 2]\n",
        "    else:\n",
        "        # Cas de nombre pair d'éléments\n",
        "        milieu1 = liste_triee[n // 2 - 1]\n",
        "        milieu2 = liste_triee[n // 2]\n",
        "        mediane = (milieu1 + milieu2) / 2\n",
        "\n",
        "    return mediane"
      ],
      "metadata": {
        "id": "EPQ96m45NwVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s0y5Az1G4PD"
      },
      "outputs": [],
      "source": [
        "def trainModelNumpyKfoldAugment(givenModel, modelName=None) :\n",
        "    scores, histories = [[],[],[],[],[]], list()\n",
        "\n",
        "    kfold = KFold(N_KFOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.05,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    if modelName == None :\n",
        "      CALLBACKS = callbacks(givenModel.__name__)\n",
        "    else :\n",
        "      CALLBACKS = callbacks(str(givenModel.__name__)+str(modelName.__name__))\n",
        "\n",
        "    # parcourir les splits du k-fold\n",
        "    for fold, (train_ix, eval_ix) in enumerate(kfold.split(X_train), start=1):  # Add enumerate to track the fold number\n",
        "\n",
        "      print(\"\")\n",
        "      print(f\"############# Fold n°{fold} #############\")\n",
        "\n",
        "      # Redéfinition du modèle\n",
        "      if modelName == None :\n",
        "        model = givenModel()\n",
        "      else :\n",
        "        model = givenModel(modelName)\n",
        "\n",
        "      split_point = int(len(train_ix) * 0.920)\n",
        "\n",
        "      # Combine eval_ix elements with train_ix for validation data\n",
        "      X_val = np.concatenate((X_train[train_ix[split_point:]], X_train[eval_ix]), axis=0)\n",
        "      y_val = np.concatenate((Y_train[train_ix[split_point:]], Y_train[eval_ix]), axis=0)\n",
        "\n",
        "      # Selection des données pour training\n",
        "      x_train, y_train = X_train[train_ix[:split_point]], Y_train[train_ix[:split_point]]\n",
        "\n",
        "      print(f\"len(y_train) : {len(y_train)} and len(y_val) : {len(y_val)}\")\n",
        "\n",
        "      datagen.fit(x_train)\n",
        "\n",
        "      # fit du modele\n",
        "      history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
        "                          validation_data=(X_val, y_val), epochs=EPOCHS,\n",
        "                          verbose=VERBOSE, callbacks=CALLBACKS)\n",
        "\n",
        "      # evaluate du modele\n",
        "      loss, acc, pre, rec, fscore = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "\n",
        "      # Create a list of values from the evaluation\n",
        "      evaluation_values = [loss, acc, pre, rec, fscore]\n",
        "\n",
        "      # Append the values to the respective scores list\n",
        "      for i, value in enumerate(evaluation_values):\n",
        "          scores[i].append(value)\n",
        "\n",
        "      histories.append(history)\n",
        "\n",
        "    #plot acc and loss in function of epochs\n",
        "    if modelName == None :\n",
        "      plotCurvesKfolding(histories, str(givenModel.__name__))\n",
        "    else :\n",
        "      plotCurvesKfolding(histories, str(givenModel.__name__)+str(modelName.__name__))\n",
        "\n",
        "    ListMetrics = [\"loss\", \"accuracy\", \"precision\", \"recall\", \"f1-score\"]\n",
        "\n",
        "    for metric, ListMetricValue in zip(ListMetrics, scores) :\n",
        "\n",
        "      # Calculate mean and standard deviation\n",
        "      mean_accuracy = np.mean(ListMetricValue)\n",
        "      std_deviation = np.std(ListMetricValue)\n",
        "\n",
        "      # Calculate the standard error of the mean (SEM)\n",
        "      sem = std_deviation / np.sqrt(len(ListMetricValue))\n",
        "\n",
        "      # Set the desired confidence level (e.g., 95%)\n",
        "      confidence_level = 0.95\n",
        "\n",
        "      # Calculate the margin of error based on the confidence level\n",
        "      margin_of_error = stats.t.ppf((1 + confidence_level) / 2, len(ListMetricValue) - 1) * sem\n",
        "\n",
        "      # Calculate the confidence interval\n",
        "      lower_bound = mean_accuracy - margin_of_error\n",
        "      upper_bound = mean_accuracy + margin_of_error\n",
        "\n",
        "      med_accuracy = mediane(ListMetricValue)\n",
        "      diff_max_min = (np.max(ListMetricValue) - np.min(ListMetricValue))/2\n",
        "\n",
        "      # Print the results\n",
        "      print(f\"Test {metric} mean ± margin : {mean_accuracy:.3f} ± {margin_of_error:.3f} (95% CI: {lower_bound:.3f}, {upper_bound:.3f})\")\n",
        "      print(f\"Test {metric} mediane ± (max-min)/2 : {med_accuracy:.3f} ± {diff_max_min:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkvMr3BojJi9"
      },
      "source": [
        "# Visualisation Resultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oSLsGPLrIKv"
      },
      "outputs": [],
      "source": [
        "def plotCurve(history, ModelName) :\n",
        "\n",
        "  #plot acc\n",
        "  plt.figure(1, figsize = (15,8))\n",
        "  plt.subplot(221)\n",
        "  plt.title('Classification Accuracy')\n",
        "  plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "  plt.plot(history.history['val_accuracy'], color='red', label='test')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "  # plot loss\n",
        "  plt.subplot(222)\n",
        "  plt.title('Cross Entropy Loss')\n",
        "  plt.plot(history.history['loss'], color='blue', label='train')\n",
        "  plt.plot(history.history['val_loss'], color='red', label='test')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "  plt.show()\n",
        "  plt.savefig(f\"Résultats/Entrainement/Accuracy_and_loss_{ModelName}.png\")\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26nB8myL2ObE"
      },
      "outputs": [],
      "source": [
        "def plotCurvesKfolding(histories, ModelName) :\n",
        "\n",
        "  for i in range(len(histories)) :\n",
        "    #plot acc\n",
        "    plt.figure(1, figsize = (15,8))\n",
        "    plt.subplot(221)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(histories[i].history['val_accuracy'], color='red', label='test')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "    # plot loss\n",
        "    plt.subplot(222)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "    plt.plot(histories[i].history['val_loss'], color='red', label='test')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "  plt.show()\n",
        "  plt.savefig(f\"Résultats/Entrainement/Kfold_Accuracy_and_loss_{ModelName}.png\")\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J86aNzDojI7Z"
      },
      "outputs": [],
      "source": [
        "def plotCurvesFineTuningKfold(historiess, ModelName, next_epochs) :\n",
        "\n",
        "  for histories in historiess :\n",
        "    for i in range(len(histories)) :\n",
        "\n",
        "      number_of_training_session = len(histories[i])\n",
        "      acc = histories[i][0].history['accuracy']\n",
        "      val_acc = histories[i][0].history['val_accuracy']\n",
        "\n",
        "      loss = histories[i][0].history['loss']\n",
        "      val_loss = histories[i][0].history['val_loss']\n",
        "\n",
        "      for j in range(1, len(histories)) :\n",
        "        acc += histories[i][j].history['accuracy']\n",
        "        val_acc += histories[i][j].history['val_accuracy']\n",
        "\n",
        "        loss += histories[i][j].history['loss']\n",
        "        val_loss += histories[i][j].history['val_loss']\n",
        "\n",
        "      plt.figure(figsize=(8, 8))\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.plot(acc, label='Training Accuracy')\n",
        "      plt.plot(val_acc, label='Validation Accuracy')\n",
        "      plt.ylim([0.4, 1])\n",
        "\n",
        "      number=1\n",
        "      for epochs in next_epochs :\n",
        "        plt.plot([epochs+1, epochs+1], plt.ylim(), label='Fine Tuning ' + str(number))\n",
        "        number=+1\n",
        "\n",
        "      plt.legend(loc='upper left')\n",
        "      plt.title('Training and Validation Accuracy')\n",
        "\n",
        "      plt.subplot(2, 1, 2)\n",
        "      plt.plot(loss, label='Training Loss')\n",
        "      plt.plot(val_loss, label='Validation Loss')\n",
        "      plt.ylim([0, 4.0])\n",
        "\n",
        "      number=1\n",
        "      for epochs in next_epochs :\n",
        "        plt.plot([epochs+1, epochs+1], plt.ylim(), label='Fine Tuning ' + str(number))\n",
        "        number=+1\n",
        "\n",
        "      plt.legend(loc='upper left')\n",
        "      plt.title('Training and Validation Loss')\n",
        "      plt.xlabel('epoch')\n",
        "\n",
        "  plt.show()\n",
        "  plt.savefig(f\"Résultats/Entrainement/Kfold_Fine_tuning_Kfold_Accuracy_and_loss_{ModelName}.png\")\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vun5YlwnIC48"
      },
      "source": [
        "# Modèles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYhkZkaBeOdj"
      },
      "source": [
        "bon site web : https://paperswithcode.com/task/image-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocC1yn8CKaz6"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg4s8zyK_AVK"
      },
      "source": [
        "This is the first CNN architecture is a basic baseline model for image classification tasks. You can use it as a starting point and further customize it or adjust the number of layers and neurons to fit your specific problem and dataset. To use this model, you would call the baseline() function to obtain an instance of the model and then compile, train, and evaluate it with your data.\n",
        "\n",
        "This model is composed of 3 feature extraction blocks each one gonna reduce the dimensionality of the data. This reduction can help the model focus on the most important information while discarding less relevant details, which can lead to more efficient and effective learning.\n",
        "\n",
        "And a classification part composed of fully connect neuron (Dense) and regularization (dropout) that disable some % of Dense neuron in the training session. At the end you have the final dense layer that classify the picture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "148XTrezIGyI"
      },
      "outputs": [],
      "source": [
        "def baseline() :\n",
        "  model = Sequential()\n",
        "\n",
        "  # ---- Conv / Pool N°1\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # ---- Conv / Pool N°2\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # ---- Conv / Pool N°3\n",
        "  model.add(Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # Flattening\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(128, activation='relu')) #, kernel_regularizer=L1L2(1e-4)))  # Add L1L2 regularization\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(64, activation='relu')) #, kernel_regularizer=L1L2(1e-4)))  # Add L1L2 regularization\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  # Couche de sortie : classification => softmax sur le nombre de classe / sigmoid pour classe = 2\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  # compilation du model de classification\n",
        "  opt = Lion(learning_rate=1e-04)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TLO8404Fyw4"
      },
      "outputs": [],
      "source": [
        "def baselineWithRegularization() :\n",
        "  model = Sequential()\n",
        "\n",
        "  # ---- Conv / Pool N°1\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # ---- Conv / Pool N°2\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # ---- Conv / Pool N°3\n",
        "  model.add(Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # Flattening\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(128, activation='relu', kernel_regularizer=L1L2(1e-4)))  # Add L1L2 regularization\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(64, activation='relu', kernel_regularizer=L1L2(1e-4)))  # Add L1L2 regularization\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  # Couche de sortie : classification => softmax sur le nombre de classe / sigmoid pour classe = 2\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  # compilation du model de classification\n",
        "  opt = Lion(learning_rate=1e-04)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgJXlCHq3r72"
      },
      "source": [
        "## Testing trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWjhpxJp3uNd"
      },
      "outputs": [],
      "source": [
        "def TestingAlreadyTrainedModel(modelName) :\n",
        "\n",
        "  model = modelName(weights='imagenet')\n",
        "  ClassModel = [['tiger'],['African_elephant','Indian_elephant','tusker'],['Arctic_fox','red_fox','coyote']]\n",
        "  ListClass = ['tiger','elephant','fox']\n",
        "  print(f\"model {modelName.__name__} as a resolution input img : \", model.input_shape[1:3])\n",
        "  ClassModelIndex=0\n",
        "\n",
        "  # Loop through each class directory\n",
        "  for class_dir in ListClass :\n",
        "    GoodPred = 0\n",
        "    NbimgClass = 0\n",
        "    averagePred = []\n",
        "    confusionClass = []\n",
        "    misclassifications = {}\n",
        "\n",
        "    # Loop through the images in the class directory\n",
        "    for img_filename in os.listdir('Tiger-Fox-Elephant/'+class_dir) :\n",
        "      img_path = os.path.join('Tiger-Fox-Elephant/'+class_dir, img_filename)\n",
        "      img = image.load_img(img_path, target_size=model.input_shape[1:3])\n",
        "      x = image.img_to_array(img)\n",
        "      x = np.expand_dims(x, axis=0)\n",
        "      x = preprocess_input(x)\n",
        "\n",
        "      # Use the pre-trained model to make predictions\n",
        "      predictions = model.predict(x, verbose=0)\n",
        "\n",
        "      # Decode and append the predicted classes\n",
        "      decoded_predictions = decode_predictions(predictions, top=1)[0][0]\n",
        "      if decoded_predictions[1] in ClassModel[ClassModelIndex] :\n",
        "          GoodPred += 1\n",
        "          averagePred.append(decoded_predictions[2])\n",
        "      else :\n",
        "          # Update the misclassifications dictionary\n",
        "          if decoded_predictions[1] not in misclassifications:\n",
        "              misclassifications[decoded_predictions[1]] = 1\n",
        "          else:\n",
        "              misclassifications[decoded_predictions[1]] += 1\n",
        "\n",
        "      NbimgClass += 1\n",
        "\n",
        "    accuracy = (GoodPred / NbimgClass) * 100\n",
        "    most_misclassified = max(misclassifications, key=misclassifications.get)\n",
        "    print(f\"For the class {class_dir}, the accuracy is {accuracy:.2f}%\")\n",
        "    print(f\"The mean probability score for the correct predictions is {np.mean(averagePred)*100} %\")\n",
        "    print(f\"The most frequently confused animal is {most_misclassified}\")\n",
        "    print(\"\")\n",
        "    ClassModelIndex += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KX3cInmWEsl"
      },
      "source": [
        "## Transfert learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgSntULAo2jQ"
      },
      "source": [
        "https://keras.io/api/applications/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo5ycRki-Y0I"
      },
      "source": [
        "VGG16 transfer learning (sans regularization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3730Yty-deK"
      },
      "outputs": [],
      "source": [
        "def TLModelArchi_1(ModelName) :\n",
        "\n",
        "  IMG_SHAPE = (IMG_SIZE, IMG_SIZE, CHANEL)\n",
        "  base_model = ModelName(input_shape=IMG_SHAPE, include_top=False,\n",
        "                                                weights='imagenet')\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  x = base_model.output\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(256, activation='relu')(x)\n",
        "  x = Dense(128, activation='relu')(x)\n",
        "  outputs = Dense(1, activation='sigmoid')(x)\n",
        "  model = tf.keras.Model(base_model.input, outputs)\n",
        "\n",
        "  model.compile(Lion(learning_rate=.0001), loss='binary_crossentropy', metrics=METRICS)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If9vdRgVruiS"
      },
      "source": [
        "VGG16 transfer learning (avec regularization et freeze des layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPCEm6UNr0N-"
      },
      "outputs": [],
      "source": [
        "def TLModelArchi_2(ModelName) :\n",
        "\n",
        "  base_model = ModelName(input_shape=IMG_SHAPE, include_top=False,\n",
        "                                                weights='imagenet')\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "  x = Dense(512, activation='elu', kernel_regularizer=L1L2(1e-3.5))(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "  x = Dense(256, activation='elu', kernel_regularizer=L1L2(1e-3.5))(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "  outputs = Dense(1, activation='sigmoid')(x)\n",
        "  model = tf.keras.Model(base_model.input, outputs)\n",
        "\n",
        "  model.compile(Lion(learning_rate=.00001), loss='binary_crossentropy', metrics=METRICS)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v13UACfcOOJt"
      },
      "source": [
        "VGG16 transfer learning (sans regularization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd4uFTsVNssh"
      },
      "outputs": [],
      "source": [
        "def TLModelArchi_2Trainable(ModelName) :\n",
        "\n",
        "  base_model = ModelName(input_shape=IMG_SHAPE, include_top=False,\n",
        "                                                weights='imagenet')\n",
        "\n",
        "  base_model.trainable = True # By default is already True\n",
        "\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(512, activation='elu', kernel_regularizer=L1L2(1e-3))(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(256, activation='elu', kernel_regularizer=L1L2(1e-3))(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  outputs = Dense(1, activation='sigmoid')(x)\n",
        "  model = tf.keras.Model(base_model.input, outputs)\n",
        "\n",
        "  model.compile(Lion(learning_rate=.00001), loss='binary_crossentropy', metrics=METRICS)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fO3DjX0KhRG"
      },
      "source": [
        "## Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEWravlKIGty"
      },
      "outputs": [],
      "source": [
        "def modelFine(modelName) :\n",
        "\n",
        "  base_model = modelName(input_shape=IMG_SHAPE, include_top=False,\n",
        "                                                weights='imagenet')\n",
        "  base_model.trainable = False\n",
        "\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(512, activation='relu', kernel_regularizer=L1L2(1e-3))(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(256, activation='relu', kernel_regularizer=L1L2(1e-3))(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  outputs = Dense(1, activation='sigmoid')(x)\n",
        "  model = tf.keras.Model(base_model.input, outputs)\n",
        "\n",
        "  base_learning_rate = 0.0001\n",
        "  model.compile(optimizer=Lion(learning_rate=base_learning_rate),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=METRICS)\n",
        "\n",
        "  return model\n",
        "\n",
        "def FineTuningKfoldingAugment(modelName, fine_layer_tune) :\n",
        "\n",
        "  histories_fine = []\n",
        "  epochs_training = []\n",
        "  scores = [[],[],[],[],[]]\n",
        "  kfold = KFold(N_KFOLDS, shuffle=True, random_state=SEED)\n",
        "  CALLBACKS = callbacks(str(modelName.__name__+'_fine'))\n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.05,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "  for fold, (train_ix, eval_ix) in enumerate(kfold.split(X_train), start=1):  # Add enumerate to track the fold number\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"############# Fold n°{fold} #############\")\n",
        "\n",
        "    history_fine = []\n",
        "    model = modelFine(modelName)\n",
        "\n",
        "    split_point = int(len(train_ix) * 0.920)\n",
        "\n",
        "    # Combine eval_ix elements with train_ix for validation data\n",
        "    X_val = np.concatenate((X_train[train_ix[split_point:]], X_train[eval_ix]), axis=0)\n",
        "    y_val = np.concatenate((Y_train[train_ix[split_point:]], Y_train[eval_ix]), axis=0)\n",
        "\n",
        "    # Selection des données pour training\n",
        "    x_train, y_train = X_train[train_ix[:split_point]], Y_train[train_ix[:split_point]]\n",
        "\n",
        "    print(f\"len(y_train) : {len(y_train)} and len(y_val) : {len(y_val)}\")\n",
        "\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # 1 er training\n",
        "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
        "                        epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        callbacks=CALLBACKS))\n",
        "\n",
        "    base_learning_rate = 0.0001\n",
        "\n",
        "    # Other training\n",
        "    for training in fine_layer_tune :\n",
        "      for layer in model.layers[training+1:] :\n",
        "        layer.trainable = True\n",
        "\n",
        "      model.compile(loss='binary_crossentropy',\n",
        "              optimizer = Lion(learning_rate=base_learning_rate/100),\n",
        "              metrics=METRICS)\n",
        "\n",
        "      epochs_training.append(history_fine[-1].epoch[-1]+1)\n",
        "\n",
        "      history_fine.append(model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
        "                              epochs=EPOCHS, callbacks=CALLBACKS,\n",
        "                              validation_data=(X_val, y_val), batch_size=BATCH_SIZE,\n",
        "                              initial_epoch=history_fine[-1].epoch[-1]+1))\n",
        "\n",
        "    # Final history for this kfold\n",
        "    histories_fine.append(history_fine)\n",
        "\n",
        "    # evaluate du modele\n",
        "    loss, acc, pre, rec, fscore = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "\n",
        "    # Create a list of values from the evaluation\n",
        "    evaluation_values = [loss, acc, pre, rec, fscore]\n",
        "\n",
        "    # Append the values to the respective scores list\n",
        "    for i, value in enumerate(evaluation_values):\n",
        "        scores[i].append(value)\n",
        "\n",
        "  #plot acc and loss in function of epochs\n",
        "  plotCurvesFineTuningKfold(histories_fine)\n",
        "\n",
        "  ListMetrics = [\"loss\", \"accuracy\", \"precision\", \"recall\", \"f1-score\"]\n",
        "\n",
        "  for metric, ListMetricValue in zip(ListMetrics, scores) :\n",
        "\n",
        "    # Calculate mean and standard deviation\n",
        "    mean_accuracy = np.mean(ListMetricValue)\n",
        "    std_deviation = np.std(ListMetricValue)\n",
        "\n",
        "    # Calculate the standard error of the mean (SEM)\n",
        "    sem = std_deviation / np.sqrt(len(ListMetricValue))\n",
        "\n",
        "    # Set the desired confidence level (e.g., 95%)\n",
        "    confidence_level = 0.95\n",
        "\n",
        "    # Calculate the margin of error based on the confidence level\n",
        "    margin_of_error = stats.t.ppf((1 + confidence_level) / 2, len(ListMetricValue) - 1) * sem\n",
        "\n",
        "    # Calculate the confidence interval\n",
        "    lower_bound = mean_accuracy - margin_of_error\n",
        "    upper_bound = mean_accuracy + margin_of_error\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Test {metric}: {mean_accuracy:.3f} ± {margin_of_error:.3f} (95% CI: {lower_bound:.3f}, {upper_bound:.3f})\")\n",
        "\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO0rPpWc_ND4"
      },
      "source": [
        "## CNN + LSTM + Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwr_ZtGaApLJ"
      },
      "source": [
        "source :\n",
        "https://www.kaggle.com/code/siddarthapatnaik/2d-cnn-lstm-model-with-self-attention-mechanism#2D-CNN-Log-Mel-Spectrogram-without-Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-JSzSOxnfhD"
      },
      "outputs": [],
      "source": [
        "def get_2d_conv_LSTM_model() :\n",
        "  model = Sequential()\n",
        "\n",
        "  # ---- Conv / Pool N°1\n",
        "  model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # ---- Conv / Pool N°2\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # ---- Conv / Pool N°3\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # Reshape\n",
        "  model.add(Reshape((-1, 128)))\n",
        "\n",
        "  # LSTM\n",
        "  model.add(LSTM(128))\n",
        "\n",
        "  # Couche de sortie : classification => softmax sur le nombre de classe / sigmoid pour classe = 2\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  # compilation du model de classification\n",
        "  opt = Lion(learning_rate=1e-04)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PizeZh7-nvY3"
      },
      "outputs": [],
      "source": [
        "def get_2d_conv_LSTM_atten_model() :\n",
        "  model = Sequential()\n",
        "\n",
        "  # ---- Conv / Pool N°1\n",
        "  model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # ---- Conv / Pool N°2\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # ---- Conv / Pool N°3\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # Reshape\n",
        "  model.add(Reshape((-1, 128)))\n",
        "\n",
        "  #LSTM\n",
        "  model.add(LSTM(32, return_sequences=True))\n",
        "  model.add(SeqSelfAttention(attention_activation ='tanh'))\n",
        "  model.add(LSTM(32, return_sequences=False))\n",
        "\n",
        "  # Couche de sortie : classification => softmax pour nombreuse classes / sigmoid pour classe = 2\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  # compilation du model de classification\n",
        "  opt = Lion(learning_rate=1e-04)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZDJWo7cumO8"
      },
      "source": [
        "## Stacking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8v7ZM1UxV3q"
      },
      "outputs": [],
      "source": [
        "def stacked_model(ListPathModel) :\n",
        "\n",
        "  loaded_models = []  # Create a dictionary to store the loaded models\n",
        "\n",
        "  for pathModel in ListPathModel :\n",
        "      model = load_model(pathModel)\n",
        "      model.trainable = False\n",
        "      loaded_models.append(model)\n",
        "\n",
        "  # Define the input layer\n",
        "  commonInput = tf.keras.Input(shape=(IMG_SIZE,IMG_SIZE,CHANEL))\n",
        "  out = []\n",
        "\n",
        "  # Iterate over the member models\n",
        "  for model in loaded_models:\n",
        "      # Rename each model's layers for distinction\n",
        "      model._name = model.get_layer(index=0)._name + \"-test\" + str(loaded_models.index(model) + 1)\n",
        "      # Pass the common input through each model\n",
        "      out.append(model(commonInput))\n",
        "\n",
        "  # Concatenate the outputs of the member models\n",
        "  modeltmp = tf.keras.layers.concatenate(out, axis=-1)\n",
        "  modeltmp = Dense(128, activation='relu')(modeltmp)\n",
        "  modeltmp = Dropout(0.2)(modeltmp)\n",
        "  modeltmp = Dense(64, activation='relu')(modeltmp)\n",
        "  modeltmp = Dropout(0.2)(modeltmp)\n",
        "  modeltmp = Dense(1, activation='sigmoid')(modeltmp)\n",
        "\n",
        "  # Create the stacked model with the concatenated outputs\n",
        "  stacked_model = Model(commonInput, modeltmp)\n",
        "  stacked_model.compile(Lion(learning_rate=.00001), loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "  return stacked_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNgUyG-77NIP"
      },
      "source": [
        "## Soup (ouai comme chez mamie)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI8JKWlF7F1H"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "import time\n",
        "\n",
        "def uniform_soup(model, path, by_name = False):\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "    except:\n",
        "        print(\"If you want to use 'Model Soup for Tensorflow2', please install 'tensorflow2'\")\n",
        "        return model\n",
        "\n",
        "    if not isinstance(path, list):\n",
        "        path = [path]\n",
        "    soups = []\n",
        "    for i, model_path in enumerate(path):\n",
        "        model.load_weights(model_path, by_name = by_name)\n",
        "        soup = [np.array(w) for w in model.weights]\n",
        "        soups.append(soup)\n",
        "    if 0 < len(soups):\n",
        "        for w1, w2 in zip(model.weights, list(zip(*soups))):\n",
        "            tf.keras.backend.set_value(w1, np.mean(w2, axis = 0))\n",
        "    return model\n",
        "\n",
        "def greedy_soup(model, path, data, metric, update_greedy = False, compare = np.greater_equal, by_name = False, digits = 4, verbose = True, y_true = \"y_true\"):\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "    except:\n",
        "        print(\"If you want to use 'Model Soup for Tensorflow2', please install 'tensorflow2'\")\n",
        "        return model\n",
        "\n",
        "    if not isinstance(path, list):\n",
        "        path = [path]\n",
        "    score, soup = None, []\n",
        "    input_key = [inp.name for inp in model.inputs]\n",
        "    input_cnt = len(input_key)\n",
        "    for i, model_path in enumerate(path):\n",
        "        if update_greedy:\n",
        "            model.load_weights(model_path, by_name = by_name)\n",
        "            for w1, w2 in zip(model.weights, soup):\n",
        "                tf.keras.backend.set_value(w1, np.mean([w1, w2], axis = 0))\n",
        "        else:\n",
        "            model = uniform_soup(model, soup + [model_path], by_name = by_name)\n",
        "\n",
        "        iterator = iter(data)\n",
        "        history = []\n",
        "        step = 0\n",
        "        start_time = time.time()\n",
        "        while True:\n",
        "            try:\n",
        "                text = \"\"\n",
        "                iter_data = next(iterator)\n",
        "                if not isinstance(iter_data, dict):\n",
        "                    x = iter_data[:input_cnt]\n",
        "                    y = list(iter_data[input_cnt:])\n",
        "                    d_cnt = len(y[0])\n",
        "                else:\n",
        "                    x = [iter_data[k] for k in input_key if k in iter_data]\n",
        "                step += 1\n",
        "                #del x\n",
        "\n",
        "                logits = model.predict(x)\n",
        "                if not isinstance(logits, list):\n",
        "                    logits = [logits]\n",
        "                if isinstance(iter_data, dict):\n",
        "                    metric_key = [key for key in inspect.getfullargspec(metric).args if key != \"self\"]\n",
        "                    if len(metric_key) == 0:\n",
        "                        metric_key = [y_true]\n",
        "                    y = [iter_data[k] for k in metric_key if k in iter_data]\n",
        "                    d_cnt = len(y[0])\n",
        "                metric_val = np.array(metric(*(y + logits)))\n",
        "                if np.ndim(metric_val) == 0:\n",
        "                    metric_val = [float(metric_val)] * d_cnt\n",
        "                history += list(metric_val)\n",
        "                #del y, logits\n",
        "\n",
        "                if verbose:\n",
        "                    sys.stdout.write(\"\\r[{name}] step: {step} - time: {time:.2f}s - {key}: {val:.{digits}f}\".format(name = os.path.basename(model_path), step = step, time = (time.time() - start_time), key = metric.__name__ if hasattr(metric, \"__name__\") else str(metric), val = np.nanmean(history), digits = digits))\n",
        "                    sys.stdout.flush()\n",
        "            except (tf.errors.OutOfRangeError, StopIteration):\n",
        "                print(\"\")\n",
        "                #gc.collect()\n",
        "                break\n",
        "        if 0 < len(history) and (score is None or compare(np.nanmean(history), score)):\n",
        "            score = np.nanmean(history)\n",
        "            if update_greedy:\n",
        "                soup = [np.array(w) for w in model.weights]\n",
        "            else:\n",
        "                soup += [model_path]\n",
        "    if len(soup) != 0:\n",
        "        if update_greedy:\n",
        "            for w1, w2 in zip(model.weights, soup):\n",
        "                tf.keras.backend.set_value(w1, w2)\n",
        "        else:\n",
        "            model = uniform_soup(model, soup, by_name = by_name)\n",
        "        if verbose:\n",
        "            print(\"greedy soup best score : {val:.{digits}f}\".format(val = score, digits = digits))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b30zPGj-p9F0"
      },
      "source": [
        "# Entrainement des modèles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9_70PLgD8Mx"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pql0gkF1-VW",
        "outputId": "bce99cf9-29ca-4401-f055-772fc8383b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les classes :  ['tiger', 'Tiger_negative_class']\n",
            "Nombres de données :  200\n",
            "Résolution des images :  (256, 256, 3)\n",
            "Taille de X_train : 140, Taille de X_val : 30, Taille de X_test : 30\n"
          ]
        }
      ],
      "source": [
        "my_path=\"Tiger-Fox-Elephant/\"\n",
        "my_classes=['tiger','Tiger_negative_class']\n",
        "X, y = create_dataset(my_path, my_classes)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=SEED) # .15 pour kfold et .3 pour normal\n",
        "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5, random_state=SEED)\n",
        "print(f\"Taille de X_train : {len(X_train)}, Taille de X_val : {len(X_val)}, Taille de X_test : {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JIQ6vJZ7Qh-G",
        "outputId": "9aab39b7-0f4c-4f0e-db79-cc186af7bbe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.4429 - precision: 0.3913 - recall: 0.2647 - f1_score: 0.3158\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46667, saving model to Saved_Model/baseline.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/35 [==============================] - 13s 193ms/step - loss: 0.6972 - accuracy: 0.4429 - precision: 0.3913 - recall: 0.2647 - f1_score: 0.3158 - val_loss: 0.6942 - val_accuracy: 0.4667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.5071 - precision: 0.4857 - recall: 0.2500 - f1_score: 0.3301\n",
            "Epoch 2: val_accuracy improved from 0.46667 to 0.50000, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.6963 - accuracy: 0.5071 - precision: 0.4857 - recall: 0.2500 - f1_score: 0.3301 - val_loss: 0.6913 - val_accuracy: 0.5000 - val_precision: 0.5172 - val_recall: 0.9375 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 3/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7005 - accuracy: 0.4714 - precision: 0.4400 - recall: 0.3235 - f1_score: 0.3729\n",
            "Epoch 3: val_accuracy did not improve from 0.50000\n",
            "35/35 [==============================] - 2s 66ms/step - loss: 0.7005 - accuracy: 0.4714 - precision: 0.4400 - recall: 0.3235 - f1_score: 0.3729 - val_loss: 0.6925 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0625 - val_f1_score: 0.1176 - lr: 1.0000e-04\n",
            "Epoch 4/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.5214 - precision: 0.5063 - recall: 0.5882 - f1_score: 0.5442\n",
            "Epoch 4: val_accuracy improved from 0.50000 to 0.56667, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.6917 - accuracy: 0.5214 - precision: 0.5063 - recall: 0.5882 - f1_score: 0.5442 - val_loss: 0.6889 - val_accuracy: 0.5667 - val_precision: 0.5517 - val_recall: 1.0000 - val_f1_score: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 5/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.5429 - precision: 0.5256 - recall: 0.6029 - f1_score: 0.5616\n",
            "Epoch 5: val_accuracy did not improve from 0.56667\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.6872 - accuracy: 0.5429 - precision: 0.5256 - recall: 0.6029 - f1_score: 0.5616 - val_loss: 0.6857 - val_accuracy: 0.5667 - val_precision: 0.7143 - val_recall: 0.3125 - val_f1_score: 0.4348 - lr: 1.0000e-04\n",
            "Epoch 6/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6768 - accuracy: 0.5500 - precision: 0.5385 - recall: 0.5147 - f1_score: 0.5263\n",
            "Epoch 6: val_accuracy did not improve from 0.56667\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.6768 - accuracy: 0.5500 - precision: 0.5385 - recall: 0.5147 - f1_score: 0.5263 - val_loss: 0.6624 - val_accuracy: 0.5667 - val_precision: 0.5652 - val_recall: 0.8125 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 7/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.6286 - precision: 0.5870 - recall: 0.7941 - f1_score: 0.6750\n",
            "Epoch 7: val_accuracy improved from 0.56667 to 0.63333, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 3s 79ms/step - loss: 0.6264 - accuracy: 0.6286 - precision: 0.5870 - recall: 0.7941 - f1_score: 0.6750 - val_loss: 0.6466 - val_accuracy: 0.6333 - val_precision: 0.7273 - val_recall: 0.5000 - val_f1_score: 0.5926 - lr: 1.0000e-04\n",
            "Epoch 8/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6618 - accuracy: 0.5643 - precision: 0.5814 - recall: 0.3676 - f1_score: 0.4505\n",
            "Epoch 8: val_accuracy did not improve from 0.63333\n",
            "35/35 [==============================] - 3s 71ms/step - loss: 0.6618 - accuracy: 0.5643 - precision: 0.5814 - recall: 0.3676 - f1_score: 0.4505 - val_loss: 0.6363 - val_accuracy: 0.6333 - val_precision: 0.6923 - val_recall: 0.5625 - val_f1_score: 0.6207 - lr: 1.0000e-04\n",
            "Epoch 9/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6117 - accuracy: 0.6357 - precision: 0.6393 - recall: 0.5735 - f1_score: 0.6047\n",
            "Epoch 9: val_accuracy did not improve from 0.63333\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.6117 - accuracy: 0.6357 - precision: 0.6393 - recall: 0.5735 - f1_score: 0.6047 - val_loss: 0.6543 - val_accuracy: 0.6333 - val_precision: 0.6667 - val_recall: 0.6250 - val_f1_score: 0.6452 - lr: 1.0000e-04\n",
            "Epoch 10/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.6857 - precision: 0.7143 - recall: 0.5882 - f1_score: 0.6452\n",
            "Epoch 10: val_accuracy did not improve from 0.63333\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.6322 - accuracy: 0.6857 - precision: 0.7143 - recall: 0.5882 - f1_score: 0.6452 - val_loss: 0.6995 - val_accuracy: 0.5667 - val_precision: 0.6667 - val_recall: 0.3750 - val_f1_score: 0.4800 - lr: 1.0000e-04\n",
            "Epoch 11/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5721 - accuracy: 0.6857 - precision: 0.7609 - recall: 0.5147 - f1_score: 0.6140\n",
            "Epoch 11: val_accuracy improved from 0.63333 to 0.70000, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.5721 - accuracy: 0.6857 - precision: 0.7609 - recall: 0.5147 - f1_score: 0.6140 - val_loss: 0.6825 - val_accuracy: 0.7000 - val_precision: 0.6667 - val_recall: 0.8750 - val_f1_score: 0.7568 - lr: 1.0000e-04\n",
            "Epoch 12/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.7143 - precision: 0.7121 - recall: 0.6912 - f1_score: 0.7015\n",
            "Epoch 12: val_accuracy did not improve from 0.70000\n",
            "35/35 [==============================] - 5s 144ms/step - loss: 0.5902 - accuracy: 0.7143 - precision: 0.7121 - recall: 0.6912 - f1_score: 0.7015 - val_loss: 0.6674 - val_accuracy: 0.6333 - val_precision: 0.6667 - val_recall: 0.6250 - val_f1_score: 0.6452 - lr: 1.0000e-04\n",
            "Epoch 13/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5340 - accuracy: 0.7357 - precision: 0.8298 - recall: 0.5735 - f1_score: 0.6783\n",
            "Epoch 13: val_accuracy did not improve from 0.70000\n",
            "35/35 [==============================] - 7s 180ms/step - loss: 0.5340 - accuracy: 0.7357 - precision: 0.8298 - recall: 0.5735 - f1_score: 0.6783 - val_loss: 0.6653 - val_accuracy: 0.7000 - val_precision: 0.7692 - val_recall: 0.6250 - val_f1_score: 0.6897 - lr: 1.0000e-04\n",
            "Epoch 14/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5812 - accuracy: 0.6786 - precision: 0.6825 - recall: 0.6324 - f1_score: 0.6565\n",
            "Epoch 14: val_accuracy improved from 0.70000 to 0.73333, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.5812 - accuracy: 0.6786 - precision: 0.6825 - recall: 0.6324 - f1_score: 0.6565 - val_loss: 0.6111 - val_accuracy: 0.7333 - val_precision: 0.7857 - val_recall: 0.6875 - val_f1_score: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 15/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5096 - accuracy: 0.7929 - precision: 0.8000 - recall: 0.7647 - f1_score: 0.7820\n",
            "Epoch 15: val_accuracy did not improve from 0.73333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.5096 - accuracy: 0.7929 - precision: 0.8000 - recall: 0.7647 - f1_score: 0.7820 - val_loss: 0.6096 - val_accuracy: 0.7000 - val_precision: 0.7692 - val_recall: 0.6250 - val_f1_score: 0.6897 - lr: 1.0000e-04\n",
            "Epoch 16/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.7786 - precision: 0.8364 - recall: 0.6765 - f1_score: 0.7480\n",
            "Epoch 16: val_accuracy did not improve from 0.73333\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.4814 - accuracy: 0.7786 - precision: 0.8364 - recall: 0.6765 - f1_score: 0.7480 - val_loss: 0.6042 - val_accuracy: 0.7333 - val_precision: 0.7857 - val_recall: 0.6875 - val_f1_score: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 17/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.7643 - precision: 0.7869 - recall: 0.7059 - f1_score: 0.7442\n",
            "Epoch 17: val_accuracy improved from 0.73333 to 0.76667, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.4397 - accuracy: 0.7643 - precision: 0.7869 - recall: 0.7059 - f1_score: 0.7442 - val_loss: 0.5407 - val_accuracy: 0.7667 - val_precision: 0.8000 - val_recall: 0.7500 - val_f1_score: 0.7742 - lr: 1.0000e-04\n",
            "Epoch 18/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.8214 - precision: 0.8644 - recall: 0.7500 - f1_score: 0.8031\n",
            "Epoch 18: val_accuracy improved from 0.76667 to 0.83333, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 2s 71ms/step - loss: 0.4025 - accuracy: 0.8214 - precision: 0.8644 - recall: 0.7500 - f1_score: 0.8031 - val_loss: 0.5666 - val_accuracy: 0.8333 - val_precision: 0.8235 - val_recall: 0.8750 - val_f1_score: 0.8485 - lr: 1.0000e-04\n",
            "Epoch 19/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8143 - precision: 0.8387 - recall: 0.7647 - f1_score: 0.8000\n",
            "Epoch 19: val_accuracy did not improve from 0.83333\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.3903 - accuracy: 0.8143 - precision: 0.8387 - recall: 0.7647 - f1_score: 0.8000 - val_loss: 0.4003 - val_accuracy: 0.8000 - val_precision: 0.8125 - val_recall: 0.8125 - val_f1_score: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 20/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.8643 - precision: 0.8889 - recall: 0.8235 - f1_score: 0.8550\n",
            "Epoch 20: val_accuracy did not improve from 0.83333\n",
            "35/35 [==============================] - 3s 75ms/step - loss: 0.3010 - accuracy: 0.8643 - precision: 0.8889 - recall: 0.8235 - f1_score: 0.8550 - val_loss: 0.5460 - val_accuracy: 0.8333 - val_precision: 0.7895 - val_recall: 0.9375 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 21/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.8786 - precision: 0.8493 - recall: 0.9118 - f1_score: 0.8794\n",
            "Epoch 21: val_accuracy improved from 0.83333 to 0.86667, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.3163 - accuracy: 0.8786 - precision: 0.8493 - recall: 0.9118 - f1_score: 0.8794 - val_loss: 0.3271 - val_accuracy: 0.8667 - val_precision: 0.9286 - val_recall: 0.8125 - val_f1_score: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 22/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.9071 - precision: 0.9104 - recall: 0.8971 - f1_score: 0.9037\n",
            "Epoch 22: val_accuracy did not improve from 0.86667\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 0.2638 - accuracy: 0.9071 - precision: 0.9104 - recall: 0.8971 - f1_score: 0.9037 - val_loss: 0.4678 - val_accuracy: 0.8333 - val_precision: 0.8235 - val_recall: 0.8750 - val_f1_score: 0.8485 - lr: 1.0000e-04\n",
            "Epoch 23/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.8571 - precision: 0.8529 - recall: 0.8529 - f1_score: 0.8529\n",
            "Epoch 23: val_accuracy did not improve from 0.86667\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.2912 - accuracy: 0.8571 - precision: 0.8529 - recall: 0.8529 - f1_score: 0.8529 - val_loss: 0.3378 - val_accuracy: 0.8333 - val_precision: 0.8667 - val_recall: 0.8125 - val_f1_score: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 24/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.8714 - precision: 0.8906 - recall: 0.8382 - f1_score: 0.8636\n",
            "Epoch 24: val_accuracy did not improve from 0.86667\n",
            "35/35 [==============================] - 6s 164ms/step - loss: 0.2392 - accuracy: 0.8714 - precision: 0.8906 - recall: 0.8382 - f1_score: 0.8636 - val_loss: 0.7525 - val_accuracy: 0.7667 - val_precision: 0.7647 - val_recall: 0.8125 - val_f1_score: 0.7879 - lr: 1.0000e-04\n",
            "Epoch 25/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.8857 - precision: 0.8714 - recall: 0.8971 - f1_score: 0.8841\n",
            "Epoch 25: val_accuracy did not improve from 0.86667\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.3229 - accuracy: 0.8857 - precision: 0.8714 - recall: 0.8971 - f1_score: 0.8841 - val_loss: 0.6086 - val_accuracy: 0.8000 - val_precision: 0.8125 - val_recall: 0.8125 - val_f1_score: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 26/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3025 - accuracy: 0.9000 - precision: 0.9500 - recall: 0.8382 - f1_score: 0.8906\n",
            "Epoch 26: val_accuracy did not improve from 0.86667\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 0.3025 - accuracy: 0.9000 - precision: 0.9500 - recall: 0.8382 - f1_score: 0.8906 - val_loss: 0.3610 - val_accuracy: 0.8333 - val_precision: 0.8667 - val_recall: 0.8125 - val_f1_score: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 27/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.8571 - precision: 0.8529 - recall: 0.8529 - f1_score: 0.8529\n",
            "Epoch 27: val_accuracy did not improve from 0.86667\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.3277 - accuracy: 0.8571 - precision: 0.8529 - recall: 0.8529 - f1_score: 0.8529 - val_loss: 0.4729 - val_accuracy: 0.7667 - val_precision: 1.0000 - val_recall: 0.5625 - val_f1_score: 0.7200 - lr: 1.0000e-04\n",
            "Epoch 28/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.8786 - precision: 0.9048 - recall: 0.8382 - f1_score: 0.8702\n",
            "Epoch 28: val_accuracy improved from 0.86667 to 0.90000, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 6s 167ms/step - loss: 0.2955 - accuracy: 0.8786 - precision: 0.9048 - recall: 0.8382 - f1_score: 0.8702 - val_loss: 0.2563 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.0000e-04\n",
            "Epoch 29/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.9357 - precision: 0.9275 - recall: 0.9412 - f1_score: 0.9343\n",
            "Epoch 29: val_accuracy did not improve from 0.90000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2086 - accuracy: 0.9357 - precision: 0.9275 - recall: 0.9412 - f1_score: 0.9343 - val_loss: 0.4033 - val_accuracy: 0.8000 - val_precision: 1.0000 - val_recall: 0.6250 - val_f1_score: 0.7692 - lr: 1.0000e-04\n",
            "Epoch 30/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.9000 - precision: 0.9091 - recall: 0.8824 - f1_score: 0.8955\n",
            "Epoch 30: val_accuracy did not improve from 0.90000\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.2192 - accuracy: 0.9000 - precision: 0.9091 - recall: 0.8824 - f1_score: 0.8955 - val_loss: 0.2956 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 1.0000e-04\n",
            "Epoch 31/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2351 - accuracy: 0.9071 - precision: 0.8986 - recall: 0.9118 - f1_score: 0.9051\n",
            "Epoch 31: val_accuracy did not improve from 0.90000\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.2351 - accuracy: 0.9071 - precision: 0.8986 - recall: 0.9118 - f1_score: 0.9051 - val_loss: 0.2795 - val_accuracy: 0.9000 - val_precision: 0.8824 - val_recall: 0.9375 - val_f1_score: 0.9091 - lr: 1.0000e-04\n",
            "Epoch 32/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9286 - precision: 0.9531 - recall: 0.8971 - f1_score: 0.9242\n",
            "Epoch 32: val_accuracy did not improve from 0.90000\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.1847 - accuracy: 0.9286 - precision: 0.9531 - recall: 0.8971 - f1_score: 0.9242 - val_loss: 0.3760 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 1.0000 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 33/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.9071 - precision: 0.8986 - recall: 0.9118 - f1_score: 0.9051\n",
            "Epoch 33: val_accuracy did not improve from 0.90000\n",
            "35/35 [==============================] - 3s 85ms/step - loss: 0.2585 - accuracy: 0.9071 - precision: 0.8986 - recall: 0.9118 - f1_score: 0.9051 - val_loss: 0.2462 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.0000e-04\n",
            "Epoch 34/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9214 - precision: 0.9524 - recall: 0.8824 - f1_score: 0.9160\n",
            "Epoch 34: val_accuracy improved from 0.90000 to 0.93333, saving model to Saved_Model/baseline.h5\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.1971 - accuracy: 0.9214 - precision: 0.9524 - recall: 0.8824 - f1_score: 0.9160 - val_loss: 0.1852 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.0000e-04\n",
            "Epoch 35/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9143 - precision: 0.9375 - recall: 0.8824 - f1_score: 0.9091\n",
            "Epoch 35: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.1757 - accuracy: 0.9143 - precision: 0.9375 - recall: 0.8824 - f1_score: 0.9091 - val_loss: 0.2535 - val_accuracy: 0.9000 - val_precision: 0.8824 - val_recall: 0.9375 - val_f1_score: 0.9091 - lr: 1.0000e-04\n",
            "Epoch 36/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9429 - precision: 0.9412 - recall: 0.9412 - f1_score: 0.9412\n",
            "Epoch 36: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.1443 - accuracy: 0.9429 - precision: 0.9412 - recall: 0.9412 - f1_score: 0.9412 - val_loss: 0.3452 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 1.0000 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 37/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2091 - accuracy: 0.9071 - precision: 0.8873 - recall: 0.9265 - f1_score: 0.9065\n",
            "Epoch 37: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.2091 - accuracy: 0.9071 - precision: 0.8873 - recall: 0.9265 - f1_score: 0.9065 - val_loss: 0.5094 - val_accuracy: 0.8667 - val_precision: 0.8333 - val_recall: 0.9375 - val_f1_score: 0.8824 - lr: 1.0000e-04\n",
            "Epoch 38/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9429 - precision: 0.9688 - recall: 0.9118 - f1_score: 0.9394\n",
            "Epoch 38: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.1071 - accuracy: 0.9429 - precision: 0.9688 - recall: 0.9118 - f1_score: 0.9394 - val_loss: 0.2638 - val_accuracy: 0.8667 - val_precision: 0.8333 - val_recall: 0.9375 - val_f1_score: 0.8824 - lr: 1.0000e-04\n",
            "Epoch 39/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9357 - precision: 0.9041 - recall: 0.9706 - f1_score: 0.9362\n",
            "Epoch 39: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.1589 - accuracy: 0.9357 - precision: 0.9041 - recall: 0.9706 - f1_score: 0.9362 - val_loss: 0.3776 - val_accuracy: 0.7333 - val_precision: 0.9000 - val_recall: 0.5625 - val_f1_score: 0.6923 - lr: 1.0000e-04\n",
            "Epoch 40/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.9429 - precision: 0.9412 - recall: 0.9412 - f1_score: 0.9412\n",
            "Epoch 40: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 0.1728 - accuracy: 0.9429 - precision: 0.9412 - recall: 0.9412 - f1_score: 0.9412 - val_loss: 0.7627 - val_accuracy: 0.7333 - val_precision: 0.9000 - val_recall: 0.5625 - val_f1_score: 0.6923 - lr: 1.0000e-04\n",
            "Epoch 41/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1514 - accuracy: 0.9429 - precision: 0.9688 - recall: 0.9118 - f1_score: 0.9394\n",
            "Epoch 41: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.1514 - accuracy: 0.9429 - precision: 0.9688 - recall: 0.9118 - f1_score: 0.9394 - val_loss: 0.2454 - val_accuracy: 0.8667 - val_precision: 0.9286 - val_recall: 0.8125 - val_f1_score: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 42/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.9286 - precision: 0.9394 - recall: 0.9118 - f1_score: 0.9254\n",
            "Epoch 42: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.1913 - accuracy: 0.9286 - precision: 0.9394 - recall: 0.9118 - f1_score: 0.9254 - val_loss: 0.2921 - val_accuracy: 0.8000 - val_precision: 0.8125 - val_recall: 0.8125 - val_f1_score: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 43/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9500 - precision: 0.9552 - recall: 0.9412 - f1_score: 0.9481\n",
            "Epoch 43: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.1116 - accuracy: 0.9500 - precision: 0.9552 - recall: 0.9412 - f1_score: 0.9481 - val_loss: 0.2182 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 1.0000e-04\n",
            "Epoch 44/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.9429 - precision: 0.9412 - recall: 0.9412 - f1_score: 0.9412\n",
            "Epoch 44: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 67ms/step - loss: 0.1789 - accuracy: 0.9429 - precision: 0.9412 - recall: 0.9412 - f1_score: 0.9412 - val_loss: 0.2728 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.0000e-04\n",
            "Epoch 45/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9429 - precision: 0.9545 - recall: 0.9265 - f1_score: 0.9403\n",
            "Epoch 45: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.1265 - accuracy: 0.9429 - precision: 0.9545 - recall: 0.9265 - f1_score: 0.9403 - val_loss: 0.2812 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 1.0000 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 46/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9143 - precision: 0.9000 - recall: 0.9265 - f1_score: 0.9130\n",
            "Epoch 46: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 0.1814 - accuracy: 0.9143 - precision: 0.9000 - recall: 0.9265 - f1_score: 0.9130 - val_loss: 0.2406 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.0000e-04\n",
            "Epoch 47/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9286 - precision: 0.9143 - recall: 0.9412 - f1_score: 0.9275\n",
            "Epoch 47: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.1533 - accuracy: 0.9286 - precision: 0.9143 - recall: 0.9412 - f1_score: 0.9275 - val_loss: 0.1963 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.0000e-04\n",
            "Epoch 48/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.9143 - precision: 0.9375 - recall: 0.8824 - f1_score: 0.9091\n",
            "Epoch 48: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 0.1553 - accuracy: 0.9143 - precision: 0.9375 - recall: 0.8824 - f1_score: 0.9091 - val_loss: 0.2160 - val_accuracy: 0.8667 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 49/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9571 - precision: 0.9844 - recall: 0.9265 - f1_score: 0.9545\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 77ms/step - loss: 0.1200 - accuracy: 0.9571 - precision: 0.9844 - recall: 0.9265 - f1_score: 0.9545 - val_loss: 0.3142 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.0000e-04\n",
            "Epoch 50/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784\n",
            "Epoch 50: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 0.0617 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784 - val_loss: 0.6542 - val_accuracy: 0.7667 - val_precision: 0.9091 - val_recall: 0.6250 - val_f1_score: 0.7407 - lr: 5.0000e-05\n",
            "Epoch 51/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.9429 - precision: 0.9688 - recall: 0.9118 - f1_score: 0.9394\n",
            "Epoch 51: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 71ms/step - loss: 0.1546 - accuracy: 0.9429 - precision: 0.9688 - recall: 0.9118 - f1_score: 0.9394 - val_loss: 0.2827 - val_accuracy: 0.8000 - val_precision: 0.9167 - val_recall: 0.6875 - val_f1_score: 0.7857 - lr: 5.0000e-05\n",
            "Epoch 52/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9714 - precision: 0.9444 - recall: 1.0000 - f1_score: 0.9714\n",
            "Epoch 52: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 0.0785 - accuracy: 0.9714 - precision: 0.9444 - recall: 1.0000 - f1_score: 0.9714 - val_loss: 0.3342 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 5.0000e-05\n",
            "Epoch 53/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9412 - f1_score: 0.9697\n",
            "Epoch 53: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 78ms/step - loss: 0.0694 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9412 - f1_score: 0.9697 - val_loss: 0.1734 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 5.0000e-05\n",
            "Epoch 54/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9643 - precision: 0.9701 - recall: 0.9559 - f1_score: 0.9630\n",
            "Epoch 54: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.0958 - accuracy: 0.9643 - precision: 0.9701 - recall: 0.9559 - f1_score: 0.9630 - val_loss: 0.6372 - val_accuracy: 0.8000 - val_precision: 0.9167 - val_recall: 0.6875 - val_f1_score: 0.7857 - lr: 5.0000e-05\n",
            "Epoch 55/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9643 - precision: 0.9846 - recall: 0.9412 - f1_score: 0.9624\n",
            "Epoch 55: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.1303 - accuracy: 0.9643 - precision: 0.9846 - recall: 0.9412 - f1_score: 0.9624 - val_loss: 0.3676 - val_accuracy: 0.8000 - val_precision: 0.9167 - val_recall: 0.6875 - val_f1_score: 0.7857 - lr: 5.0000e-05\n",
            "Epoch 56/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9571 - precision: 0.9559 - recall: 0.9559 - f1_score: 0.9559\n",
            "Epoch 56: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.1116 - accuracy: 0.9571 - precision: 0.9559 - recall: 0.9559 - f1_score: 0.9559 - val_loss: 0.2710 - val_accuracy: 0.8667 - val_precision: 0.9286 - val_recall: 0.8125 - val_f1_score: 0.8667 - lr: 5.0000e-05\n",
            "Epoch 57/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9571 - precision: 0.9844 - recall: 0.9265 - f1_score: 0.9545\n",
            "Epoch 57: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 75ms/step - loss: 0.0941 - accuracy: 0.9571 - precision: 0.9844 - recall: 0.9265 - f1_score: 0.9545 - val_loss: 0.2341 - val_accuracy: 0.8667 - val_precision: 0.9286 - val_recall: 0.8125 - val_f1_score: 0.8667 - lr: 5.0000e-05\n",
            "Epoch 58/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9429 - precision: 0.9167 - recall: 0.9706 - f1_score: 0.9429\n",
            "Epoch 58: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.1034 - accuracy: 0.9429 - precision: 0.9167 - recall: 0.9706 - f1_score: 0.9429 - val_loss: 0.1738 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 5.0000e-05\n",
            "Epoch 59/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9571 - precision: 1.0000 - recall: 0.9118 - f1_score: 0.9538\n",
            "Epoch 59: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 0.1234 - accuracy: 0.9571 - precision: 1.0000 - recall: 0.9118 - f1_score: 0.9538 - val_loss: 0.1266 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8750 - val_f1_score: 0.9333 - lr: 5.0000e-05\n",
            "Epoch 60/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784\n",
            "Epoch 60: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.1031 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784 - val_loss: 0.1955 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 5.0000e-05\n",
            "Epoch 61/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9857 - precision: 0.9853 - recall: 0.9853 - f1_score: 0.9853\n",
            "Epoch 61: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.0670 - accuracy: 0.9857 - precision: 0.9853 - recall: 0.9853 - f1_score: 0.9853 - val_loss: 0.5331 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 5.0000e-05\n",
            "Epoch 62/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9714 - precision: 0.9706 - recall: 0.9706 - f1_score: 0.9706\n",
            "Epoch 62: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 73ms/step - loss: 0.0510 - accuracy: 0.9714 - precision: 0.9706 - recall: 0.9706 - f1_score: 0.9706 - val_loss: 0.2660 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 5.0000e-05\n",
            "Epoch 63/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9786 - precision: 0.9710 - recall: 0.9853 - f1_score: 0.9781\n",
            "Epoch 63: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 68ms/step - loss: 0.1003 - accuracy: 0.9786 - precision: 0.9710 - recall: 0.9853 - f1_score: 0.9781 - val_loss: 0.6568 - val_accuracy: 0.8000 - val_precision: 1.0000 - val_recall: 0.6250 - val_f1_score: 0.7692 - lr: 5.0000e-05\n",
            "Epoch 64/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9412 - f1_score: 0.9697\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.0835 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9412 - f1_score: 0.9697 - val_loss: 0.3371 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 5.0000e-05\n",
            "Epoch 65/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9714 - precision: 0.9706 - recall: 0.9706 - f1_score: 0.9706\n",
            "Epoch 65: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.0727 - accuracy: 0.9714 - precision: 0.9706 - recall: 0.9706 - f1_score: 0.9706 - val_loss: 0.3492 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 2.5000e-05\n",
            "Epoch 66/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9706 - f1_score: 0.9851\n",
            "Epoch 66: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 71ms/step - loss: 0.0421 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9706 - f1_score: 0.9851 - val_loss: 0.5333 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6875 - val_f1_score: 0.8148 - lr: 2.5000e-05\n",
            "Epoch 67/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 67: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.0207 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 2.5000e-05\n",
            "Epoch 68/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9786 - precision: 0.9710 - recall: 0.9853 - f1_score: 0.9781\n",
            "Epoch 68: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.0433 - accuracy: 0.9786 - precision: 0.9710 - recall: 0.9853 - f1_score: 0.9781 - val_loss: 0.5416 - val_accuracy: 0.8000 - val_precision: 1.0000 - val_recall: 0.6250 - val_f1_score: 0.7692 - lr: 2.5000e-05\n",
            "Epoch 69/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 69: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.0118 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.8000 - val_precision: 0.9167 - val_recall: 0.6875 - val_f1_score: 0.7857 - lr: 2.5000e-05\n",
            "Epoch 70/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926\n",
            "Epoch 70: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.0228 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926 - val_loss: 0.3766 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 2.5000e-05\n",
            "Epoch 71/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9714 - precision: 0.9571 - recall: 0.9853 - f1_score: 0.9710\n",
            "Epoch 71: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.0704 - accuracy: 0.9714 - precision: 0.9571 - recall: 0.9853 - f1_score: 0.9710 - val_loss: 1.5576 - val_accuracy: 0.7333 - val_precision: 0.9000 - val_recall: 0.5625 - val_f1_score: 0.6923 - lr: 2.5000e-05\n",
            "Epoch 72/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.9500 - precision: 1.0000 - recall: 0.8971 - f1_score: 0.9457\n",
            "Epoch 72: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.2726 - accuracy: 0.9500 - precision: 1.0000 - recall: 0.8971 - f1_score: 0.9457 - val_loss: 0.8110 - val_accuracy: 0.7667 - val_precision: 0.9091 - val_recall: 0.6250 - val_f1_score: 0.7407 - lr: 2.5000e-05\n",
            "Epoch 73/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9643 - precision: 0.9315 - recall: 1.0000 - f1_score: 0.9645\n",
            "Epoch 73: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 76ms/step - loss: 0.1210 - accuracy: 0.9643 - precision: 0.9315 - recall: 1.0000 - f1_score: 0.9645 - val_loss: 0.3074 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 2.5000e-05\n",
            "Epoch 74/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784\n",
            "Epoch 74: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 71ms/step - loss: 0.0431 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784 - val_loss: 0.3711 - val_accuracy: 0.8667 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8750 - lr: 2.5000e-05\n",
            "Epoch 75/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9714 - precision: 0.9706 - recall: 0.9706 - f1_score: 0.9706\n",
            "Epoch 75: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 69ms/step - loss: 0.0871 - accuracy: 0.9714 - precision: 0.9706 - recall: 0.9706 - f1_score: 0.9706 - val_loss: 0.4978 - val_accuracy: 0.8333 - val_precision: 0.8667 - val_recall: 0.8125 - val_f1_score: 0.8387 - lr: 2.5000e-05\n",
            "Epoch 76/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9786 - precision: 0.9851 - recall: 0.9706 - f1_score: 0.9778\n",
            "Epoch 76: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.0753 - accuracy: 0.9786 - precision: 0.9851 - recall: 0.9706 - f1_score: 0.9778 - val_loss: 0.3048 - val_accuracy: 0.9000 - val_precision: 0.8824 - val_recall: 0.9375 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 77/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9857 - precision: 0.9714 - recall: 1.0000 - f1_score: 0.9855\n",
            "Epoch 77: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 84ms/step - loss: 0.0534 - accuracy: 0.9857 - precision: 0.9714 - recall: 1.0000 - f1_score: 0.9855 - val_loss: 0.2852 - val_accuracy: 0.8667 - val_precision: 0.8750 - val_recall: 0.8750 - val_f1_score: 0.8750 - lr: 2.5000e-05\n",
            "Epoch 78/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9571 - precision: 0.9559 - recall: 0.9559 - f1_score: 0.9559\n",
            "Epoch 78: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0560 - accuracy: 0.9571 - precision: 0.9559 - recall: 0.9559 - f1_score: 0.9559 - val_loss: 0.3096 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 2.5000e-05\n",
            "Epoch 79/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.0530 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927 - val_loss: 0.4052 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 2.5000e-05\n",
            "Epoch 80/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926\n",
            "Epoch 80: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.0337 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926 - val_loss: 0.4007 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.2500e-05\n",
            "Epoch 81/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927\n",
            "Epoch 81: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 74ms/step - loss: 0.0269 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927 - val_loss: 0.3974 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.2500e-05\n",
            "Epoch 82/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926\n",
            "Epoch 82: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 73ms/step - loss: 0.0315 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926 - val_loss: 0.3879 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.2500e-05\n",
            "Epoch 83/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784\n",
            "Epoch 83: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.0298 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784 - val_loss: 0.3458 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.2500e-05\n",
            "Epoch 84/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9857 - precision: 0.9714 - recall: 1.0000 - f1_score: 0.9855\n",
            "Epoch 84: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 71ms/step - loss: 0.0269 - accuracy: 0.9857 - precision: 0.9714 - recall: 1.0000 - f1_score: 0.9855 - val_loss: 0.3454 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.2500e-05\n",
            "Epoch 85/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926\n",
            "Epoch 85: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 73ms/step - loss: 0.0228 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926 - val_loss: 0.4365 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.2500e-05\n",
            "Epoch 86/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9706 - f1_score: 0.9851\n",
            "Epoch 86: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.0255 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9706 - f1_score: 0.9851 - val_loss: 0.3651 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.2500e-05\n",
            "Epoch 87/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926\n",
            "Epoch 87: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 73ms/step - loss: 0.0158 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926 - val_loss: 0.3527 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.2500e-05\n",
            "Epoch 88/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784\n",
            "Epoch 88: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 2s 70ms/step - loss: 0.0846 - accuracy: 0.9786 - precision: 0.9577 - recall: 1.0000 - f1_score: 0.9784 - val_loss: 0.3439 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.2500e-05\n",
            "Epoch 89/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926\n",
            "Epoch 89: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.0150 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926 - val_loss: 0.5685 - val_accuracy: 0.8000 - val_precision: 0.9167 - val_recall: 0.6875 - val_f1_score: 0.7857 - lr: 1.2500e-05\n",
            "Epoch 90/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9706 - f1_score: 0.9851\n",
            "Epoch 90: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 78ms/step - loss: 0.0324 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9706 - f1_score: 0.9851 - val_loss: 0.5231 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 1.2500e-05\n",
            "Epoch 91/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927\n",
            "Epoch 91: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.0156 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927 - val_loss: 0.4105 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.2500e-05\n",
            "Epoch 92/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927\n",
            "Epoch 92: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.0320 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927 - val_loss: 0.4856 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.2500e-05\n",
            "Epoch 93/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9857 - precision: 0.9853 - recall: 0.9853 - f1_score: 0.9853\n",
            "Epoch 93: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 73ms/step - loss: 0.0165 - accuracy: 0.9857 - precision: 0.9853 - recall: 0.9853 - f1_score: 0.9853 - val_loss: 0.5395 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.2500e-05\n",
            "Epoch 94/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 94: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.0062 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.2500e-05\n",
            "Epoch 95/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 95: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 84ms/step - loss: 0.0037 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 96: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 71ms/step - loss: 0.0087 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926\n",
            "Epoch 97: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.0203 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926 - val_loss: 0.4635 - val_accuracy: 0.9000 - val_precision: 0.9333 - val_recall: 0.8750 - val_f1_score: 0.9032 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 98: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 73ms/step - loss: 0.0074 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927\n",
            "Epoch 99: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.0286 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927 - val_loss: 0.4513 - val_accuracy: 0.8667 - val_precision: 0.9286 - val_recall: 0.8125 - val_f1_score: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926\n",
            "Epoch 100: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 73ms/step - loss: 0.0422 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926 - val_loss: 0.6780 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 101: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 75ms/step - loss: 0.0055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927\n",
            "Epoch 102: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.0100 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927 - val_loss: 0.4038 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927\n",
            "Epoch 103: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.0254 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927 - val_loss: 0.4118 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 104: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 71ms/step - loss: 0.0036 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.8000 - val_precision: 0.9167 - val_recall: 0.6875 - val_f1_score: 0.7857 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9857 - precision: 0.9853 - recall: 0.9853 - f1_score: 0.9853\n",
            "Epoch 105: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 73ms/step - loss: 0.0646 - accuracy: 0.9857 - precision: 0.9853 - recall: 0.9853 - f1_score: 0.9853 - val_loss: 0.5438 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 106: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 74ms/step - loss: 0.0062 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926\n",
            "Epoch 107: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 86ms/step - loss: 0.0227 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9853 - f1_score: 0.9926 - val_loss: 0.3348 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927\n",
            "Epoch 108: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.0154 - accuracy: 0.9929 - precision: 0.9855 - recall: 1.0000 - f1_score: 0.9927 - val_loss: 0.1752 - val_accuracy: 0.9333 - val_precision: 0.9375 - val_recall: 0.9375 - val_f1_score: 0.9375 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 109: val_accuracy did not improve from 0.93333\n",
            "35/35 [==============================] - 3s 72ms/step - loss: 0.0115 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.8333 - val_precision: 0.9231 - val_recall: 0.7500 - val_f1_score: 0.8276 - lr: 1.0000e-05\n",
            "Epoch 109: early stopping\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.4556 - accuracy: 0.9000 - precision: 1.0000 - recall: 0.8125 - f1_score: 0.8966\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x793020b112d0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainModelNumpyAugment(baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Y8LwOUko7X",
        "outputId": "bf61ec90-c8d2-47f9-e5fe-ca5891fbc236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les classes :  ['tiger', 'Tiger_negative_class']\n",
            "Nombres de données :  200\n",
            "Résolution des images :  (256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "my_path=\"Tiger-Fox-Elephant/\"\n",
        "my_classes=['tiger','Tiger_negative_class']\n",
        "X, y = create_dataset(my_path, my_classes)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15, random_state=SEED) # .15 pour kfold et .3 pour normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYDJyEeoD-O1"
      },
      "outputs": [],
      "source": [
        "trainModelNumpyKfoldAugment(baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gq9f8yw2F6Sj",
        "outputId": "cbe20456-a8af-4202-fe6f-f3a0fe376178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Epoch 106: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.3097 - accuracy: 0.9214 - precision: 0.9130 - recall: 0.9265 - f1_score: 0.9197 - val_loss: 1.2966 - val_accuracy: 0.7000 - val_precision: 0.7692 - val_recall: 0.6250 - val_f1_score: 0.6897 - lr: 1.0000e-05\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.8857 - precision: 0.9333 - recall: 0.8235 - f1_score: 0.8750\n",
            "Epoch 107: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.3332 - accuracy: 0.8857 - precision: 0.9333 - recall: 0.8235 - f1_score: 0.8750 - val_loss: 1.2544 - val_accuracy: 0.7333 - val_precision: 0.7857 - val_recall: 0.6875 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.9000 - precision: 0.9219 - recall: 0.8676 - f1_score: 0.8939\n",
            "Epoch 108: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.3242 - accuracy: 0.9000 - precision: 0.9219 - recall: 0.8676 - f1_score: 0.8939 - val_loss: 1.2006 - val_accuracy: 0.7000 - val_precision: 0.7333 - val_recall: 0.6875 - val_f1_score: 0.7097 - lr: 1.0000e-05\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.8714 - precision: 0.8571 - recall: 0.8824 - f1_score: 0.8696\n",
            "Epoch 109: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.3028 - accuracy: 0.8714 - precision: 0.8571 - recall: 0.8824 - f1_score: 0.8696 - val_loss: 1.1409 - val_accuracy: 0.7333 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1_score: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8857 - precision: 0.9062 - recall: 0.8529 - f1_score: 0.8788\n",
            "Epoch 110: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.3207 - accuracy: 0.8857 - precision: 0.9062 - recall: 0.8529 - f1_score: 0.8788 - val_loss: 1.1257 - val_accuracy: 0.7667 - val_precision: 0.8000 - val_recall: 0.7500 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.8857 - precision: 0.9062 - recall: 0.8529 - f1_score: 0.8788\n",
            "Epoch 111: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 87ms/step - loss: 0.3093 - accuracy: 0.8857 - precision: 0.9062 - recall: 0.8529 - f1_score: 0.8788 - val_loss: 1.0831 - val_accuracy: 0.7667 - val_precision: 0.8462 - val_recall: 0.6875 - val_f1_score: 0.7586 - lr: 1.0000e-05\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.9000 - precision: 0.9219 - recall: 0.8676 - f1_score: 0.8939\n",
            "Epoch 112: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.2676 - accuracy: 0.9000 - precision: 0.9219 - recall: 0.8676 - f1_score: 0.8939 - val_loss: 1.0893 - val_accuracy: 0.7667 - val_precision: 0.8462 - val_recall: 0.6875 - val_f1_score: 0.7586 - lr: 1.0000e-05\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.8786 - precision: 0.9048 - recall: 0.8382 - f1_score: 0.8702\n",
            "Epoch 113: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 86ms/step - loss: 0.3534 - accuracy: 0.8786 - precision: 0.9048 - recall: 0.8382 - f1_score: 0.8702 - val_loss: 1.1423 - val_accuracy: 0.7333 - val_precision: 0.7857 - val_recall: 0.6875 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.8786 - precision: 0.8592 - recall: 0.8971 - f1_score: 0.8777\n",
            "Epoch 114: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.3131 - accuracy: 0.8786 - precision: 0.8592 - recall: 0.8971 - f1_score: 0.8777 - val_loss: 1.1274 - val_accuracy: 0.7333 - val_precision: 0.7857 - val_recall: 0.6875 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.9214 - precision: 0.9385 - recall: 0.8971 - f1_score: 0.9173\n",
            "Epoch 115: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 86ms/step - loss: 0.2874 - accuracy: 0.9214 - precision: 0.9385 - recall: 0.8971 - f1_score: 0.9173 - val_loss: 1.1554 - val_accuracy: 0.7667 - val_precision: 0.8000 - val_recall: 0.7500 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3418 - accuracy: 0.8786 - precision: 0.8923 - recall: 0.8529 - f1_score: 0.8722\n",
            "Epoch 116: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 87ms/step - loss: 0.3418 - accuracy: 0.8786 - precision: 0.8923 - recall: 0.8529 - f1_score: 0.8722 - val_loss: 1.1938 - val_accuracy: 0.7667 - val_precision: 0.8000 - val_recall: 0.7500 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.9286 - precision: 0.9265 - recall: 0.9265 - f1_score: 0.9265\n",
            "Epoch 117: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.2664 - accuracy: 0.9286 - precision: 0.9265 - recall: 0.9265 - f1_score: 0.9265 - val_loss: 1.2280 - val_accuracy: 0.7667 - val_precision: 0.8000 - val_recall: 0.7500 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.9286 - precision: 0.9143 - recall: 0.9412 - f1_score: 0.9275\n",
            "Epoch 118: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.2730 - accuracy: 0.9286 - precision: 0.9143 - recall: 0.9412 - f1_score: 0.9275 - val_loss: 1.2607 - val_accuracy: 0.7333 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1_score: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.9143 - precision: 0.8889 - recall: 0.9412 - f1_score: 0.9143\n",
            "Epoch 119: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.2978 - accuracy: 0.9143 - precision: 0.8889 - recall: 0.9412 - f1_score: 0.9143 - val_loss: 1.2774 - val_accuracy: 0.7333 - val_precision: 0.9000 - val_recall: 0.5625 - val_f1_score: 0.6923 - lr: 1.0000e-05\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.9143 - precision: 0.9375 - recall: 0.8824 - f1_score: 0.9091\n",
            "Epoch 120: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.2787 - accuracy: 0.9143 - precision: 0.9375 - recall: 0.8824 - f1_score: 0.9091 - val_loss: 1.2401 - val_accuracy: 0.7667 - val_precision: 0.9091 - val_recall: 0.6250 - val_f1_score: 0.7407 - lr: 1.0000e-05\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.9214 - precision: 0.9672 - recall: 0.8676 - f1_score: 0.9147\n",
            "Epoch 121: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2808 - accuracy: 0.9214 - precision: 0.9672 - recall: 0.8676 - f1_score: 0.9147 - val_loss: 1.2337 - val_accuracy: 0.7333 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1_score: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.9000 - precision: 0.8971 - recall: 0.8971 - f1_score: 0.8971\n",
            "Epoch 122: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.3013 - accuracy: 0.9000 - precision: 0.8971 - recall: 0.8971 - f1_score: 0.8971 - val_loss: 1.3229 - val_accuracy: 0.7333 - val_precision: 0.7500 - val_recall: 0.7500 - val_f1_score: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 122: early stopping\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.8161 - accuracy: 0.8000 - precision: 0.7778 - recall: 0.8750 - f1_score: 0.8235\n",
            "\n",
            "############# Fold n°4 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.5197 - accuracy: 0.5118 - precision: 0.5141 - recall: 0.8391 - f1_score: 0.6376\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 97ms/step - loss: 2.5197 - accuracy: 0.5118 - precision: 0.5141 - recall: 0.8391 - f1_score: 0.6376 - val_loss: 2.2394 - val_accuracy: 0.4333 - val_precision: 0.4333 - val_recall: 1.0000 - val_f1_score: 0.6047 - lr: 1.0000e-04\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.9952 - accuracy: 0.4571 - precision: 0.4684 - recall: 0.5211 - f1_score: 0.4933\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 1.9952 - accuracy: 0.4571 - precision: 0.4684 - recall: 0.5211 - f1_score: 0.4933 - val_loss: 1.7491 - val_accuracy: 0.5667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.5643 - accuracy: 0.5071 - precision: 0.5172 - recall: 0.4225 - f1_score: 0.4651\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 1.5643 - accuracy: 0.5071 - precision: 0.5172 - recall: 0.4225 - f1_score: 0.4651 - val_loss: 1.3894 - val_accuracy: 0.4333 - val_precision: 0.4286 - val_recall: 0.9231 - val_f1_score: 0.5854 - lr: 1.0000e-04\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.2643 - accuracy: 0.4857 - precision: 0.4878 - recall: 0.2817 - f1_score: 0.3571\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 1.2643 - accuracy: 0.4857 - precision: 0.4878 - recall: 0.2817 - f1_score: 0.3571 - val_loss: 1.1486 - val_accuracy: 0.5667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0838 - accuracy: 0.4286 - precision: 0.4458 - recall: 0.5211 - f1_score: 0.4805\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 1.0838 - accuracy: 0.4286 - precision: 0.4458 - recall: 0.5211 - f1_score: 0.4805 - val_loss: 1.0362 - val_accuracy: 0.4333 - val_precision: 0.4333 - val_recall: 1.0000 - val_f1_score: 0.6047 - lr: 1.0000e-04\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0286 - accuracy: 0.4786 - precision: 0.4911 - recall: 0.7746 - f1_score: 0.6011\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 1.0286 - accuracy: 0.4786 - precision: 0.4911 - recall: 0.7746 - f1_score: 0.6011 - val_loss: 1.0258 - val_accuracy: 0.4333 - val_precision: 0.4333 - val_recall: 1.0000 - val_f1_score: 0.6047 - lr: 1.0000e-04\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9962 - accuracy: 0.5071 - precision: 0.5094 - recall: 0.7606 - f1_score: 0.6102\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 87ms/step - loss: 0.9962 - accuracy: 0.5071 - precision: 0.5094 - recall: 0.7606 - f1_score: 0.6102 - val_loss: 0.9445 - val_accuracy: 0.4333 - val_precision: 0.4333 - val_recall: 1.0000 - val_f1_score: 0.6047 - lr: 1.0000e-04\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8838 - accuracy: 0.5571 - precision: 0.5360 - recall: 0.9437 - f1_score: 0.6837\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 87ms/step - loss: 0.8838 - accuracy: 0.5571 - precision: 0.5360 - recall: 0.9437 - f1_score: 0.6837 - val_loss: 0.8331 - val_accuracy: 0.4333 - val_precision: 0.4333 - val_recall: 1.0000 - val_f1_score: 0.6047 - lr: 1.0000e-04\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8117 - accuracy: 0.5214 - precision: 0.5204 - recall: 0.7183 - f1_score: 0.6036\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.8117 - accuracy: 0.5214 - precision: 0.5204 - recall: 0.7183 - f1_score: 0.6036 - val_loss: 0.7940 - val_accuracy: 0.4333 - val_precision: 0.4333 - val_recall: 1.0000 - val_f1_score: 0.6047 - lr: 1.0000e-04\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7739 - accuracy: 0.5429 - precision: 0.5280 - recall: 0.9296 - f1_score: 0.6735\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.7739 - accuracy: 0.5429 - precision: 0.5280 - recall: 0.9296 - f1_score: 0.6735 - val_loss: 0.7697 - val_accuracy: 0.4333 - val_precision: 0.4333 - val_recall: 1.0000 - val_f1_score: 0.6047 - lr: 1.0000e-04\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7610 - accuracy: 0.5143 - precision: 0.5111 - recall: 0.9718 - f1_score: 0.6699\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.7610 - accuracy: 0.5143 - precision: 0.5111 - recall: 0.9718 - f1_score: 0.6699 - val_loss: 0.7665 - val_accuracy: 0.4333 - val_precision: 0.4333 - val_recall: 1.0000 - val_f1_score: 0.6047 - lr: 1.0000e-04\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7567 - accuracy: 0.5286 - precision: 0.5188 - recall: 0.9718 - f1_score: 0.6765\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 87ms/step - loss: 0.7567 - accuracy: 0.5286 - precision: 0.5188 - recall: 0.9718 - f1_score: 0.6765 - val_loss: 0.7642 - val_accuracy: 0.4667 - val_precision: 0.4483 - val_recall: 1.0000 - val_f1_score: 0.6190 - lr: 1.0000e-04\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7333 - accuracy: 0.5929 - precision: 0.5593 - recall: 0.9296 - f1_score: 0.6984\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.7333 - accuracy: 0.5929 - precision: 0.5593 - recall: 0.9296 - f1_score: 0.6984 - val_loss: 0.7681 - val_accuracy: 0.5333 - val_precision: 0.4815 - val_recall: 1.0000 - val_f1_score: 0.6500 - lr: 1.0000e-04\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7363 - accuracy: 0.5929 - precision: 0.5603 - recall: 0.9155 - f1_score: 0.6952\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.7363 - accuracy: 0.5929 - precision: 0.5603 - recall: 0.9155 - f1_score: 0.6952 - val_loss: 0.7486 - val_accuracy: 0.5333 - val_precision: 0.4706 - val_recall: 0.6154 - val_f1_score: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7599 - accuracy: 0.5929 - precision: 0.6522 - recall: 0.4225 - f1_score: 0.5128\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.7599 - accuracy: 0.5929 - precision: 0.6522 - recall: 0.4225 - f1_score: 0.5128 - val_loss: 0.7741 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.2308 - val_f1_score: 0.3158 - lr: 1.0000e-04\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7667 - accuracy: 0.6000 - precision: 0.7143 - recall: 0.3521 - f1_score: 0.4717\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.7667 - accuracy: 0.6000 - precision: 0.7143 - recall: 0.3521 - f1_score: 0.4717 - val_loss: 0.7762 - val_accuracy: 0.5333 - val_precision: 0.4667 - val_recall: 0.5385 - val_f1_score: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.6000 - precision: 0.6056 - recall: 0.6056 - f1_score: 0.6056\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.7672 - accuracy: 0.6000 - precision: 0.6056 - recall: 0.6056 - f1_score: 0.6056 - val_loss: 0.7830 - val_accuracy: 0.4667 - val_precision: 0.4286 - val_recall: 0.6923 - val_f1_score: 0.5294 - lr: 1.0000e-04\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7389 - accuracy: 0.6071 - precision: 0.5952 - recall: 0.7042 - f1_score: 0.6452\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.7389 - accuracy: 0.6071 - precision: 0.5952 - recall: 0.7042 - f1_score: 0.6452 - val_loss: 0.7851 - val_accuracy: 0.4333 - val_precision: 0.4091 - val_recall: 0.6923 - val_f1_score: 0.5143 - lr: 5.0000e-05\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7312 - accuracy: 0.6143 - precision: 0.6024 - recall: 0.7042 - f1_score: 0.6494\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.7312 - accuracy: 0.6143 - precision: 0.6024 - recall: 0.7042 - f1_score: 0.6494 - val_loss: 0.7934 - val_accuracy: 0.4000 - val_precision: 0.3810 - val_recall: 0.6154 - val_f1_score: 0.4706 - lr: 5.0000e-05\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7158 - accuracy: 0.6143 - precision: 0.6104 - recall: 0.6620 - f1_score: 0.6351\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.7158 - accuracy: 0.6143 - precision: 0.6104 - recall: 0.6620 - f1_score: 0.6351 - val_loss: 0.7714 - val_accuracy: 0.5333 - val_precision: 0.4667 - val_recall: 0.5385 - val_f1_score: 0.5000 - lr: 5.0000e-05\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7248 - accuracy: 0.6143 - precision: 0.6393 - recall: 0.5493 - f1_score: 0.5909\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.7248 - accuracy: 0.6143 - precision: 0.6393 - recall: 0.5493 - f1_score: 0.5909 - val_loss: 0.7710 - val_accuracy: 0.5000 - val_precision: 0.4375 - val_recall: 0.5385 - val_f1_score: 0.4828 - lr: 5.0000e-05\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7231 - accuracy: 0.6000 - precision: 0.6056 - recall: 0.6056 - f1_score: 0.6056\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 87ms/step - loss: 0.7231 - accuracy: 0.6000 - precision: 0.6056 - recall: 0.6056 - f1_score: 0.6056 - val_loss: 0.7725 - val_accuracy: 0.4667 - val_precision: 0.4118 - val_recall: 0.5385 - val_f1_score: 0.4667 - lr: 5.0000e-05\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6792 - accuracy: 0.6786 - precision: 0.7031 - recall: 0.6338 - f1_score: 0.6667\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.6792 - accuracy: 0.6786 - precision: 0.7031 - recall: 0.6338 - f1_score: 0.6667 - val_loss: 0.7727 - val_accuracy: 0.4667 - val_precision: 0.4118 - val_recall: 0.5385 - val_f1_score: 0.4667 - lr: 5.0000e-05\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6679 - accuracy: 0.6714 - precision: 0.6812 - recall: 0.6620 - f1_score: 0.6714\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.6679 - accuracy: 0.6714 - precision: 0.6812 - recall: 0.6620 - f1_score: 0.6714 - val_loss: 0.8220 - val_accuracy: 0.4000 - val_precision: 0.3684 - val_recall: 0.5385 - val_f1_score: 0.4375 - lr: 5.0000e-05\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6710 - accuracy: 0.6857 - precision: 0.6901 - recall: 0.6901 - f1_score: 0.6901\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.6710 - accuracy: 0.6857 - precision: 0.6901 - recall: 0.6901 - f1_score: 0.6901 - val_loss: 0.7519 - val_accuracy: 0.5333 - val_precision: 0.4545 - val_recall: 0.3846 - val_f1_score: 0.4167 - lr: 5.0000e-05\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6641 - accuracy: 0.6643 - precision: 0.7609 - recall: 0.4930 - f1_score: 0.5983\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.6641 - accuracy: 0.6643 - precision: 0.7609 - recall: 0.4930 - f1_score: 0.5983 - val_loss: 0.7338 - val_accuracy: 0.5333 - val_precision: 0.4615 - val_recall: 0.4615 - val_f1_score: 0.4615 - lr: 5.0000e-05\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.6786 - precision: 0.6912 - recall: 0.6620 - f1_score: 0.6763\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.6676 - accuracy: 0.6786 - precision: 0.6912 - recall: 0.6620 - f1_score: 0.6763 - val_loss: 0.7354 - val_accuracy: 0.5000 - val_precision: 0.4444 - val_recall: 0.6154 - val_f1_score: 0.5161 - lr: 5.0000e-05\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6199 - accuracy: 0.7286 - precision: 0.7089 - recall: 0.7887 - f1_score: 0.7467\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.6199 - accuracy: 0.7286 - precision: 0.7089 - recall: 0.7887 - f1_score: 0.7467 - val_loss: 0.7605 - val_accuracy: 0.5000 - val_precision: 0.4375 - val_recall: 0.5385 - val_f1_score: 0.4828 - lr: 5.0000e-05\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.7214 - precision: 0.7162 - recall: 0.7465 - f1_score: 0.7310\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.6203 - accuracy: 0.7214 - precision: 0.7162 - recall: 0.7465 - f1_score: 0.7310 - val_loss: 0.7813 - val_accuracy: 0.5333 - val_precision: 0.4667 - val_recall: 0.5385 - val_f1_score: 0.5000 - lr: 5.0000e-05\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6319 - accuracy: 0.7143 - precision: 0.7719 - recall: 0.6197 - f1_score: 0.6875\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.6319 - accuracy: 0.7143 - precision: 0.7719 - recall: 0.6197 - f1_score: 0.6875 - val_loss: 0.7250 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.5385 - val_f1_score: 0.5185 - lr: 5.0000e-05\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6112 - accuracy: 0.6857 - precision: 0.6709 - recall: 0.7465 - f1_score: 0.7067\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.6112 - accuracy: 0.6857 - precision: 0.6709 - recall: 0.7465 - f1_score: 0.7067 - val_loss: 0.7258 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.6154 - val_f1_score: 0.5517 - lr: 5.0000e-05\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.7286 - precision: 0.7200 - recall: 0.7606 - f1_score: 0.7397\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.5599 - accuracy: 0.7286 - precision: 0.7200 - recall: 0.7606 - f1_score: 0.7397 - val_loss: 0.7258 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 5.0000e-05\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.7571 - precision: 0.7761 - recall: 0.7324 - f1_score: 0.7536\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.5974 - accuracy: 0.7571 - precision: 0.7761 - recall: 0.7324 - f1_score: 0.7536 - val_loss: 0.8279 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.6923 - val_f1_score: 0.5806 - lr: 5.0000e-05\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.7143 - precision: 0.7123 - recall: 0.7324 - f1_score: 0.7222\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.6013 - accuracy: 0.7143 - precision: 0.7123 - recall: 0.7324 - f1_score: 0.7222 - val_loss: 0.7334 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.4615 - val_f1_score: 0.4800 - lr: 5.0000e-05\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.7286 - precision: 0.7143 - recall: 0.7746 - f1_score: 0.7432\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.6260 - accuracy: 0.7286 - precision: 0.7143 - recall: 0.7746 - f1_score: 0.7432 - val_loss: 0.7286 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 0.4615 - val_f1_score: 0.4444 - lr: 5.0000e-05\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.7214 - precision: 0.7222 - recall: 0.7324 - f1_score: 0.7273\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.6286 - accuracy: 0.7214 - precision: 0.7222 - recall: 0.7324 - f1_score: 0.7273 - val_loss: 0.6942 - val_accuracy: 0.6333 - val_precision: 0.5833 - val_recall: 0.5385 - val_f1_score: 0.5600 - lr: 5.0000e-05\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6062 - accuracy: 0.7429 - precision: 0.7536 - recall: 0.7324 - f1_score: 0.7429\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.6062 - accuracy: 0.7429 - precision: 0.7536 - recall: 0.7324 - f1_score: 0.7429 - val_loss: 0.7103 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.5385 - val_f1_score: 0.5185 - lr: 5.0000e-05\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.7500 - precision: 0.7368 - recall: 0.7887 - f1_score: 0.7619\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.5857 - accuracy: 0.7500 - precision: 0.7368 - recall: 0.7887 - f1_score: 0.7619 - val_loss: 0.7550 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.6154 - val_f1_score: 0.5517 - lr: 5.0000e-05\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5764 - accuracy: 0.7357 - precision: 0.7742 - recall: 0.6761 - f1_score: 0.7218\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.5764 - accuracy: 0.7357 - precision: 0.7742 - recall: 0.6761 - f1_score: 0.7218 - val_loss: 0.7642 - val_accuracy: 0.6333 - val_precision: 0.5833 - val_recall: 0.5385 - val_f1_score: 0.5600 - lr: 5.0000e-05\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5864 - accuracy: 0.7429 - precision: 0.7778 - recall: 0.6901 - f1_score: 0.7313\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.5864 - accuracy: 0.7429 - precision: 0.7778 - recall: 0.6901 - f1_score: 0.7313 - val_loss: 0.7716 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.5385 - val_f1_score: 0.5185 - lr: 5.0000e-05\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5825 - accuracy: 0.7857 - precision: 0.7887 - recall: 0.7887 - f1_score: 0.7887\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.5825 - accuracy: 0.7857 - precision: 0.7887 - recall: 0.7887 - f1_score: 0.7887 - val_loss: 0.7628 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.6154 - val_f1_score: 0.5517 - lr: 5.0000e-05\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.8214 - precision: 0.8485 - recall: 0.7887 - f1_score: 0.8175\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.5491 - accuracy: 0.8214 - precision: 0.8485 - recall: 0.7887 - f1_score: 0.8175 - val_loss: 0.7188 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.5385 - val_f1_score: 0.5185 - lr: 5.0000e-05\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.7786 - precision: 0.8125 - recall: 0.7324 - f1_score: 0.7704\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.5126 - accuracy: 0.7786 - precision: 0.8125 - recall: 0.7324 - f1_score: 0.7704 - val_loss: 0.7461 - val_accuracy: 0.6667 - val_precision: 0.6154 - val_recall: 0.6154 - val_f1_score: 0.6154 - lr: 5.0000e-05\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.8000 - precision: 0.8308 - recall: 0.7606 - f1_score: 0.7941\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.5286 - accuracy: 0.8000 - precision: 0.8308 - recall: 0.7606 - f1_score: 0.7941 - val_loss: 0.9070 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.6923 - val_f1_score: 0.5806 - lr: 5.0000e-05\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.7643 - precision: 0.7262 - recall: 0.8592 - f1_score: 0.7871\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.5390 - accuracy: 0.7643 - precision: 0.7262 - recall: 0.8592 - f1_score: 0.7871 - val_loss: 0.7534 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 5.0000e-05\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.7571 - precision: 0.8136 - recall: 0.6761 - f1_score: 0.7385\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.5157 - accuracy: 0.7571 - precision: 0.8136 - recall: 0.6761 - f1_score: 0.7385 - val_loss: 0.7082 - val_accuracy: 0.6000 - val_precision: 0.5385 - val_recall: 0.5385 - val_f1_score: 0.5385 - lr: 5.0000e-05\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5360 - accuracy: 0.7643 - precision: 0.8065 - recall: 0.7042 - f1_score: 0.7519\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.5360 - accuracy: 0.7643 - precision: 0.8065 - recall: 0.7042 - f1_score: 0.7519 - val_loss: 0.7689 - val_accuracy: 0.6000 - val_precision: 0.5294 - val_recall: 0.6923 - val_f1_score: 0.6000 - lr: 5.0000e-05\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.7714 - precision: 0.7600 - recall: 0.8028 - f1_score: 0.7808\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.5458 - accuracy: 0.7714 - precision: 0.7600 - recall: 0.8028 - f1_score: 0.7808 - val_loss: 0.7607 - val_accuracy: 0.6667 - val_precision: 0.5882 - val_recall: 0.7692 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.7857 - precision: 0.8060 - recall: 0.7606 - f1_score: 0.7826\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.5104 - accuracy: 0.7857 - precision: 0.8060 - recall: 0.7606 - f1_score: 0.7826 - val_loss: 0.8011 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.5385 - val_f1_score: 0.5185 - lr: 5.0000e-05\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.8214 - precision: 0.8286 - recall: 0.8169 - f1_score: 0.8227\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.5327 - accuracy: 0.8214 - precision: 0.8286 - recall: 0.8169 - f1_score: 0.8227 - val_loss: 0.7517 - val_accuracy: 0.6000 - val_precision: 0.5333 - val_recall: 0.6154 - val_f1_score: 0.5714 - lr: 5.0000e-05\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.8071 - precision: 0.8143 - recall: 0.8028 - f1_score: 0.8085\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.5406 - accuracy: 0.8071 - precision: 0.8143 - recall: 0.8028 - f1_score: 0.8085 - val_loss: 0.7875 - val_accuracy: 0.5333 - val_precision: 0.4667 - val_recall: 0.5385 - val_f1_score: 0.5000 - lr: 5.0000e-05\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4662 - accuracy: 0.8286 - precision: 0.8507 - recall: 0.8028 - f1_score: 0.8261\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 87ms/step - loss: 0.4662 - accuracy: 0.8286 - precision: 0.8507 - recall: 0.8028 - f1_score: 0.8261 - val_loss: 0.9175 - val_accuracy: 0.5667 - val_precision: 0.5000 - val_recall: 0.5385 - val_f1_score: 0.5185 - lr: 5.0000e-05\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.8286 - precision: 0.8310 - recall: 0.8310 - f1_score: 0.8310\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.4989 - accuracy: 0.8286 - precision: 0.8310 - recall: 0.8310 - f1_score: 0.8310 - val_loss: 0.9049 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.6923 - val_f1_score: 0.6429 - lr: 5.0000e-05\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.7786 - precision: 0.7778 - recall: 0.7887 - f1_score: 0.7832\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.4991 - accuracy: 0.7786 - precision: 0.7778 - recall: 0.7887 - f1_score: 0.7832 - val_loss: 0.7883 - val_accuracy: 0.7333 - val_precision: 0.6667 - val_recall: 0.7692 - val_f1_score: 0.7143 - lr: 5.0000e-05\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.8000 - precision: 0.7945 - recall: 0.8169 - f1_score: 0.8056\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.5323 - accuracy: 0.8000 - precision: 0.7945 - recall: 0.8169 - f1_score: 0.8056 - val_loss: 0.7600 - val_accuracy: 0.6333 - val_precision: 0.6000 - val_recall: 0.4615 - val_f1_score: 0.5217 - lr: 5.0000e-05\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.7929 - precision: 0.8281 - recall: 0.7465 - f1_score: 0.7852\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.5588 - accuracy: 0.7929 - precision: 0.8281 - recall: 0.7465 - f1_score: 0.7852 - val_loss: 0.7333 - val_accuracy: 0.6667 - val_precision: 0.6154 - val_recall: 0.6154 - val_f1_score: 0.6154 - lr: 5.0000e-05\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.7929 - precision: 0.8000 - recall: 0.7887 - f1_score: 0.7943\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.5041 - accuracy: 0.7929 - precision: 0.8000 - recall: 0.7887 - f1_score: 0.7943 - val_loss: 0.8236 - val_accuracy: 0.5333 - val_precision: 0.4737 - val_recall: 0.6923 - val_f1_score: 0.5625 - lr: 5.0000e-05\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5120 - accuracy: 0.7714 - precision: 0.7349 - recall: 0.8592 - f1_score: 0.7922\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.5120 - accuracy: 0.7714 - precision: 0.7349 - recall: 0.8592 - f1_score: 0.7922 - val_loss: 0.7928 - val_accuracy: 0.6000 - val_precision: 0.5333 - val_recall: 0.6154 - val_f1_score: 0.5714 - lr: 5.0000e-05\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.8000 - precision: 0.8644 - recall: 0.7183 - f1_score: 0.7846\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.4859 - accuracy: 0.8000 - precision: 0.8644 - recall: 0.7183 - f1_score: 0.7846 - val_loss: 0.8233 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 5.0000e-05\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.8071 - precision: 0.8438 - recall: 0.7606 - f1_score: 0.8000\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 87ms/step - loss: 0.4539 - accuracy: 0.8071 - precision: 0.8438 - recall: 0.7606 - f1_score: 0.8000 - val_loss: 0.9107 - val_accuracy: 0.7000 - val_precision: 0.6429 - val_recall: 0.6923 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5128 - accuracy: 0.8214 - precision: 0.8194 - recall: 0.8310 - f1_score: 0.8252\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.5128 - accuracy: 0.8214 - precision: 0.8194 - recall: 0.8310 - f1_score: 0.8252 - val_loss: 0.7803 - val_accuracy: 0.7333 - val_precision: 0.6923 - val_recall: 0.6923 - val_f1_score: 0.6923 - lr: 5.0000e-05\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 0.7857 - precision: 0.8475 - recall: 0.7042 - f1_score: 0.7692\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.4810 - accuracy: 0.7857 - precision: 0.8475 - recall: 0.7042 - f1_score: 0.7692 - val_loss: 0.8442 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 5.0000e-05\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.8071 - precision: 0.8056 - recall: 0.8169 - f1_score: 0.8112\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.4844 - accuracy: 0.8071 - precision: 0.8056 - recall: 0.8169 - f1_score: 0.8112 - val_loss: 0.8568 - val_accuracy: 0.6000 - val_precision: 0.5333 - val_recall: 0.6154 - val_f1_score: 0.5714 - lr: 5.0000e-05\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4909 - accuracy: 0.8143 - precision: 0.8571 - recall: 0.7606 - f1_score: 0.8060\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.4909 - accuracy: 0.8143 - precision: 0.8571 - recall: 0.7606 - f1_score: 0.8060 - val_loss: 0.7016 - val_accuracy: 0.7333 - val_precision: 0.7273 - val_recall: 0.6154 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.7714 - precision: 0.7826 - recall: 0.7606 - f1_score: 0.7714\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.4848 - accuracy: 0.7714 - precision: 0.7826 - recall: 0.7606 - f1_score: 0.7714 - val_loss: 0.7746 - val_accuracy: 0.6333 - val_precision: 0.5833 - val_recall: 0.5385 - val_f1_score: 0.5600 - lr: 5.0000e-05\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.7571 - precision: 0.7761 - recall: 0.7324 - f1_score: 0.7536\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.5143 - accuracy: 0.7571 - precision: 0.7761 - recall: 0.7324 - f1_score: 0.7536 - val_loss: 0.8231 - val_accuracy: 0.6000 - val_precision: 0.5385 - val_recall: 0.5385 - val_f1_score: 0.5385 - lr: 5.0000e-05\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4786 - accuracy: 0.8286 - precision: 0.8852 - recall: 0.7606 - f1_score: 0.8182\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.4786 - accuracy: 0.8286 - precision: 0.8852 - recall: 0.7606 - f1_score: 0.8182 - val_loss: 0.8415 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 5.0000e-05\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4909 - accuracy: 0.8214 - precision: 0.8485 - recall: 0.7887 - f1_score: 0.8175\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.4909 - accuracy: 0.8214 - precision: 0.8485 - recall: 0.7887 - f1_score: 0.8175 - val_loss: 0.8547 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 5.0000e-05\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.8286 - precision: 0.8406 - recall: 0.8169 - f1_score: 0.8286\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.5270 - accuracy: 0.8286 - precision: 0.8406 - recall: 0.8169 - f1_score: 0.8286 - val_loss: 0.8303 - val_accuracy: 0.7000 - val_precision: 0.6250 - val_recall: 0.7692 - val_f1_score: 0.6897 - lr: 5.0000e-05\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.8071 - precision: 0.7750 - recall: 0.8732 - f1_score: 0.8212\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.4804 - accuracy: 0.8071 - precision: 0.7750 - recall: 0.8732 - f1_score: 0.8212 - val_loss: 0.8310 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 2.5000e-05\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.8214 - precision: 0.8286 - recall: 0.8169 - f1_score: 0.8227\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.5081 - accuracy: 0.8214 - precision: 0.8286 - recall: 0.8169 - f1_score: 0.8227 - val_loss: 0.8109 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 2.5000e-05\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.8357 - precision: 0.8871 - recall: 0.7746 - f1_score: 0.8271\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.4572 - accuracy: 0.8357 - precision: 0.8871 - recall: 0.7746 - f1_score: 0.8271 - val_loss: 0.8377 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 2.5000e-05\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.8143 - precision: 0.8169 - recall: 0.8169 - f1_score: 0.8169\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.4618 - accuracy: 0.8143 - precision: 0.8169 - recall: 0.8169 - f1_score: 0.8169 - val_loss: 0.8362 - val_accuracy: 0.6667 - val_precision: 0.6154 - val_recall: 0.6154 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.8643 - precision: 0.8939 - recall: 0.8310 - f1_score: 0.8613\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.4484 - accuracy: 0.8643 - precision: 0.8939 - recall: 0.8310 - f1_score: 0.8613 - val_loss: 0.8273 - val_accuracy: 0.6667 - val_precision: 0.6154 - val_recall: 0.6154 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.8357 - precision: 0.8636 - recall: 0.8028 - f1_score: 0.8321\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.4454 - accuracy: 0.8357 - precision: 0.8636 - recall: 0.8028 - f1_score: 0.8321 - val_loss: 0.8200 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 2.5000e-05\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.8500 - precision: 0.8571 - recall: 0.8451 - f1_score: 0.8511\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.4406 - accuracy: 0.8500 - precision: 0.8571 - recall: 0.8451 - f1_score: 0.8511 - val_loss: 0.8176 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 2.5000e-05\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.8000 - precision: 0.8413 - recall: 0.7465 - f1_score: 0.7910\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.4490 - accuracy: 0.8000 - precision: 0.8413 - recall: 0.7465 - f1_score: 0.7910 - val_loss: 0.8737 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 2.5000e-05\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.8643 - precision: 0.9194 - recall: 0.8028 - f1_score: 0.8571\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.4177 - accuracy: 0.8643 - precision: 0.9194 - recall: 0.8028 - f1_score: 0.8571 - val_loss: 0.9450 - val_accuracy: 0.7000 - val_precision: 0.6667 - val_recall: 0.6154 - val_f1_score: 0.6400 - lr: 2.5000e-05\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.8000 - precision: 0.8209 - recall: 0.7746 - f1_score: 0.7971\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.4735 - accuracy: 0.8000 - precision: 0.8209 - recall: 0.7746 - f1_score: 0.7971 - val_loss: 0.9175 - val_accuracy: 0.7000 - val_precision: 0.6429 - val_recall: 0.6923 - val_f1_score: 0.6667 - lr: 2.5000e-05\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.8000 - precision: 0.7945 - recall: 0.8169 - f1_score: 0.8056\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.4487 - accuracy: 0.8000 - precision: 0.7945 - recall: 0.8169 - f1_score: 0.8056 - val_loss: 0.8179 - val_accuracy: 0.7000 - val_precision: 0.6667 - val_recall: 0.6154 - val_f1_score: 0.6400 - lr: 2.5000e-05\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.8357 - precision: 0.8429 - recall: 0.8310 - f1_score: 0.8369\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.4343 - accuracy: 0.8357 - precision: 0.8429 - recall: 0.8310 - f1_score: 0.8369 - val_loss: 0.7664 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 2.5000e-05\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8857 - precision: 0.9508 - recall: 0.8169 - f1_score: 0.8788\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.3816 - accuracy: 0.8857 - precision: 0.9508 - recall: 0.8169 - f1_score: 0.8788 - val_loss: 0.9540 - val_accuracy: 0.6333 - val_precision: 0.5625 - val_recall: 0.6923 - val_f1_score: 0.6207 - lr: 2.5000e-05\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4631 - accuracy: 0.8214 - precision: 0.7949 - recall: 0.8732 - f1_score: 0.8322\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.4631 - accuracy: 0.8214 - precision: 0.7949 - recall: 0.8732 - f1_score: 0.8322 - val_loss: 0.9353 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.6923 - val_f1_score: 0.6429 - lr: 2.5000e-05\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 0.8214 - precision: 0.8382 - recall: 0.8028 - f1_score: 0.8201\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.4013 - accuracy: 0.8214 - precision: 0.8382 - recall: 0.8028 - f1_score: 0.8201 - val_loss: 0.8610 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 2.5000e-05\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.8500 - precision: 0.9032 - recall: 0.7887 - f1_score: 0.8421\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.4313 - accuracy: 0.8500 - precision: 0.9032 - recall: 0.7887 - f1_score: 0.8421 - val_loss: 0.8684 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.8286 - precision: 0.8615 - recall: 0.7887 - f1_score: 0.8235\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.4132 - accuracy: 0.8286 - precision: 0.8615 - recall: 0.7887 - f1_score: 0.8235 - val_loss: 0.9264 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4916 - accuracy: 0.8143 - precision: 0.8261 - recall: 0.8028 - f1_score: 0.8143\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.4916 - accuracy: 0.8143 - precision: 0.8261 - recall: 0.8028 - f1_score: 0.8143 - val_loss: 0.8728 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.8429 - precision: 0.8657 - recall: 0.8169 - f1_score: 0.8406\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.4141 - accuracy: 0.8429 - precision: 0.8657 - recall: 0.8169 - f1_score: 0.8406 - val_loss: 0.8648 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.8357 - precision: 0.8158 - recall: 0.8732 - f1_score: 0.8435\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.4695 - accuracy: 0.8357 - precision: 0.8158 - recall: 0.8732 - f1_score: 0.8435 - val_loss: 0.8583 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3960 - accuracy: 0.8643 - precision: 0.8939 - recall: 0.8310 - f1_score: 0.8613\n",
            "Epoch 90: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.3960 - accuracy: 0.8643 - precision: 0.8939 - recall: 0.8310 - f1_score: 0.8613 - val_loss: 0.8607 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8357 - precision: 0.8529 - recall: 0.8169 - f1_score: 0.8345\n",
            "Epoch 91: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.3808 - accuracy: 0.8357 - precision: 0.8529 - recall: 0.8169 - f1_score: 0.8345 - val_loss: 0.8879 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.8214 - precision: 0.8594 - recall: 0.7746 - f1_score: 0.8148\n",
            "Epoch 92: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.4079 - accuracy: 0.8214 - precision: 0.8594 - recall: 0.7746 - f1_score: 0.8148 - val_loss: 0.9456 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.8500 - precision: 0.8788 - recall: 0.8169 - f1_score: 0.8467\n",
            "Epoch 93: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.3935 - accuracy: 0.8500 - precision: 0.8788 - recall: 0.8169 - f1_score: 0.8467 - val_loss: 0.9736 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8571 - precision: 0.8592 - recall: 0.8592 - f1_score: 0.8592\n",
            "Epoch 94: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.3882 - accuracy: 0.8571 - precision: 0.8592 - recall: 0.8592 - f1_score: 0.8592 - val_loss: 0.9699 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.8786 - precision: 0.9091 - recall: 0.8451 - f1_score: 0.8759\n",
            "Epoch 95: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.3581 - accuracy: 0.8786 - precision: 0.9091 - recall: 0.8451 - f1_score: 0.8759 - val_loss: 0.9634 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3928 - accuracy: 0.8357 - precision: 0.8529 - recall: 0.8169 - f1_score: 0.8345\n",
            "Epoch 96: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.3928 - accuracy: 0.8357 - precision: 0.8529 - recall: 0.8169 - f1_score: 0.8345 - val_loss: 0.9802 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 1.2500e-05\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8571 - precision: 0.8493 - recall: 0.8732 - f1_score: 0.8611\n",
            "Epoch 97: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.4318 - accuracy: 0.8571 - precision: 0.8493 - recall: 0.8732 - f1_score: 0.8611 - val_loss: 0.9546 - val_accuracy: 0.6000 - val_precision: 0.5385 - val_recall: 0.5385 - val_f1_score: 0.5385 - lr: 1.2500e-05\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.8429 - precision: 0.8657 - recall: 0.8169 - f1_score: 0.8406\n",
            "Epoch 98: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.4242 - accuracy: 0.8429 - precision: 0.8657 - recall: 0.8169 - f1_score: 0.8406 - val_loss: 0.9363 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 0.8500 - precision: 0.9032 - recall: 0.7887 - f1_score: 0.8421\n",
            "Epoch 99: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.3741 - accuracy: 0.8500 - precision: 0.9032 - recall: 0.7887 - f1_score: 0.8421 - val_loss: 0.9431 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 1.2500e-05\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8643 - precision: 0.8824 - recall: 0.8451 - f1_score: 0.8633\n",
            "Epoch 100: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.3837 - accuracy: 0.8643 - precision: 0.8824 - recall: 0.8451 - f1_score: 0.8633 - val_loss: 0.9223 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 1.0000e-05\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4065 - accuracy: 0.8286 - precision: 0.8310 - recall: 0.8310 - f1_score: 0.8310\n",
            "Epoch 101: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 89ms/step - loss: 0.4065 - accuracy: 0.8286 - precision: 0.8310 - recall: 0.8310 - f1_score: 0.8310 - val_loss: 0.9038 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 1.0000e-05\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.8571 - precision: 0.8493 - recall: 0.8732 - f1_score: 0.8611\n",
            "Epoch 102: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.4032 - accuracy: 0.8571 - precision: 0.8493 - recall: 0.8732 - f1_score: 0.8611 - val_loss: 0.8989 - val_accuracy: 0.6000 - val_precision: 0.5385 - val_recall: 0.5385 - val_f1_score: 0.5385 - lr: 1.0000e-05\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.8714 - precision: 0.9206 - recall: 0.8169 - f1_score: 0.8657\n",
            "Epoch 103: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.3784 - accuracy: 0.8714 - precision: 0.9206 - recall: 0.8169 - f1_score: 0.8657 - val_loss: 0.9499 - val_accuracy: 0.6000 - val_precision: 0.5333 - val_recall: 0.6154 - val_f1_score: 0.5714 - lr: 1.0000e-05\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8500 - precision: 0.8676 - recall: 0.8310 - f1_score: 0.8489\n",
            "Epoch 104: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.3998 - accuracy: 0.8500 - precision: 0.8676 - recall: 0.8310 - f1_score: 0.8489 - val_loss: 1.0267 - val_accuracy: 0.6000 - val_precision: 0.5333 - val_recall: 0.6154 - val_f1_score: 0.5714 - lr: 1.0000e-05\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4137 - accuracy: 0.8500 - precision: 0.8289 - recall: 0.8873 - f1_score: 0.8571\n",
            "Epoch 105: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.4137 - accuracy: 0.8500 - precision: 0.8289 - recall: 0.8873 - f1_score: 0.8571 - val_loss: 1.0404 - val_accuracy: 0.6000 - val_precision: 0.5385 - val_recall: 0.5385 - val_f1_score: 0.5385 - lr: 1.0000e-05\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8786 - precision: 0.8971 - recall: 0.8592 - f1_score: 0.8777\n",
            "Epoch 106: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.3383 - accuracy: 0.8786 - precision: 0.8971 - recall: 0.8592 - f1_score: 0.8777 - val_loss: 0.9858 - val_accuracy: 0.6000 - val_precision: 0.5385 - val_recall: 0.5385 - val_f1_score: 0.5385 - lr: 1.0000e-05\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3697 - accuracy: 0.8714 - precision: 0.8841 - recall: 0.8592 - f1_score: 0.8714\n",
            "Epoch 107: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.3697 - accuracy: 0.8714 - precision: 0.8841 - recall: 0.8592 - f1_score: 0.8714 - val_loss: 1.0146 - val_accuracy: 0.6333 - val_precision: 0.5833 - val_recall: 0.5385 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8500 - precision: 0.8472 - recall: 0.8592 - f1_score: 0.8531\n",
            "Epoch 108: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.3995 - accuracy: 0.8500 - precision: 0.8472 - recall: 0.8592 - f1_score: 0.8531 - val_loss: 0.9692 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.8714 - precision: 0.9077 - recall: 0.8310 - f1_score: 0.8676\n",
            "Epoch 109: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.3567 - accuracy: 0.8714 - precision: 0.9077 - recall: 0.8310 - f1_score: 0.8676 - val_loss: 0.9575 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.8286 - precision: 0.8507 - recall: 0.8028 - f1_score: 0.8261\n",
            "Epoch 110: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.4380 - accuracy: 0.8286 - precision: 0.8507 - recall: 0.8028 - f1_score: 0.8261 - val_loss: 0.9821 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8857 - precision: 0.8986 - recall: 0.8732 - f1_score: 0.8857\n",
            "Epoch 111: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.3661 - accuracy: 0.8857 - precision: 0.8986 - recall: 0.8732 - f1_score: 0.8857 - val_loss: 1.0449 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.8143 - precision: 0.8358 - recall: 0.7887 - f1_score: 0.8116\n",
            "Epoch 112: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.4188 - accuracy: 0.8143 - precision: 0.8358 - recall: 0.7887 - f1_score: 0.8116 - val_loss: 1.0540 - val_accuracy: 0.7000 - val_precision: 0.6667 - val_recall: 0.6154 - val_f1_score: 0.6400 - lr: 1.0000e-05\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.8643 - precision: 0.8611 - recall: 0.8732 - f1_score: 0.8671\n",
            "Epoch 113: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.3440 - accuracy: 0.8643 - precision: 0.8611 - recall: 0.8732 - f1_score: 0.8671 - val_loss: 1.0450 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.8714 - precision: 0.8841 - recall: 0.8592 - f1_score: 0.8714\n",
            "Epoch 114: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.3672 - accuracy: 0.8714 - precision: 0.8841 - recall: 0.8592 - f1_score: 0.8714 - val_loss: 1.0064 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.8357 - precision: 0.8333 - recall: 0.8451 - f1_score: 0.8392\n",
            "Epoch 115: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.3452 - accuracy: 0.8357 - precision: 0.8333 - recall: 0.8451 - f1_score: 0.8392 - val_loss: 0.9991 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.8643 - precision: 0.8514 - recall: 0.8873 - f1_score: 0.8690\n",
            "Epoch 116: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.3714 - accuracy: 0.8643 - precision: 0.8514 - recall: 0.8873 - f1_score: 0.8690 - val_loss: 1.0012 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.8357 - precision: 0.8871 - recall: 0.7746 - f1_score: 0.8271\n",
            "Epoch 117: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.4271 - accuracy: 0.8357 - precision: 0.8871 - recall: 0.7746 - f1_score: 0.8271 - val_loss: 1.0139 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8643 - precision: 0.8939 - recall: 0.8310 - f1_score: 0.8613\n",
            "Epoch 118: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.3815 - accuracy: 0.8643 - precision: 0.8939 - recall: 0.8310 - f1_score: 0.8613 - val_loss: 1.0039 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3392 - accuracy: 0.8786 - precision: 0.8553 - recall: 0.9155 - f1_score: 0.8844\n",
            "Epoch 119: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.3392 - accuracy: 0.8786 - precision: 0.8553 - recall: 0.9155 - f1_score: 0.8844 - val_loss: 1.0851 - val_accuracy: 0.6000 - val_precision: 0.5333 - val_recall: 0.6154 - val_f1_score: 0.5714 - lr: 1.0000e-05\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.8143 - precision: 0.8000 - recall: 0.8451 - f1_score: 0.8219\n",
            "Epoch 120: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.4501 - accuracy: 0.8143 - precision: 0.8000 - recall: 0.8451 - f1_score: 0.8219 - val_loss: 1.0414 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8571 - precision: 0.9180 - recall: 0.7887 - f1_score: 0.8485\n",
            "Epoch 121: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 99ms/step - loss: 0.3677 - accuracy: 0.8571 - precision: 0.9180 - recall: 0.7887 - f1_score: 0.8485 - val_loss: 1.0074 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4168 - accuracy: 0.8429 - precision: 0.8769 - recall: 0.8028 - f1_score: 0.8382\n",
            "Epoch 122: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.4168 - accuracy: 0.8429 - precision: 0.8769 - recall: 0.8028 - f1_score: 0.8382 - val_loss: 0.9940 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8857 - precision: 0.8767 - recall: 0.9014 - f1_score: 0.8889\n",
            "Epoch 123: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.3676 - accuracy: 0.8857 - precision: 0.8767 - recall: 0.9014 - f1_score: 0.8889 - val_loss: 1.0006 - val_accuracy: 0.6333 - val_precision: 0.5833 - val_recall: 0.5385 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.8571 - precision: 0.8923 - recall: 0.8169 - f1_score: 0.8529\n",
            "Epoch 124: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.3526 - accuracy: 0.8571 - precision: 0.8923 - recall: 0.8169 - f1_score: 0.8529 - val_loss: 1.0290 - val_accuracy: 0.6667 - val_precision: 0.6154 - val_recall: 0.6154 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.8429 - precision: 0.8551 - recall: 0.8310 - f1_score: 0.8429\n",
            "Epoch 125: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.3752 - accuracy: 0.8429 - precision: 0.8551 - recall: 0.8310 - f1_score: 0.8429 - val_loss: 1.0799 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 1.0000e-05\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.8929 - precision: 0.9242 - recall: 0.8592 - f1_score: 0.8905\n",
            "Epoch 126: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.3524 - accuracy: 0.8929 - precision: 0.9242 - recall: 0.8592 - f1_score: 0.8905 - val_loss: 1.1493 - val_accuracy: 0.6333 - val_precision: 0.5625 - val_recall: 0.6923 - val_f1_score: 0.6207 - lr: 1.0000e-05\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8643 - precision: 0.8095 - recall: 0.9577 - f1_score: 0.8774\n",
            "Epoch 127: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.3548 - accuracy: 0.8643 - precision: 0.8095 - recall: 0.9577 - f1_score: 0.8774 - val_loss: 1.1164 - val_accuracy: 0.6000 - val_precision: 0.5333 - val_recall: 0.6154 - val_f1_score: 0.5714 - lr: 1.0000e-05\n",
            "Epoch 128/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8286 - precision: 0.8406 - recall: 0.8169 - f1_score: 0.8286\n",
            "Epoch 128: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.3850 - accuracy: 0.8286 - precision: 0.8406 - recall: 0.8169 - f1_score: 0.8286 - val_loss: 1.0330 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 129/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.8357 - precision: 0.8529 - recall: 0.8169 - f1_score: 0.8345\n",
            "Epoch 129: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 0.4009 - accuracy: 0.8357 - precision: 0.8529 - recall: 0.8169 - f1_score: 0.8345 - val_loss: 0.9984 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 130/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.8857 - precision: 0.9231 - recall: 0.8451 - f1_score: 0.8824\n",
            "Epoch 130: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.3321 - accuracy: 0.8857 - precision: 0.9231 - recall: 0.8451 - f1_score: 0.8824 - val_loss: 1.0109 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 131/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8429 - precision: 0.8356 - recall: 0.8592 - f1_score: 0.8472\n",
            "Epoch 131: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.3777 - accuracy: 0.8429 - precision: 0.8356 - recall: 0.8592 - f1_score: 0.8472 - val_loss: 1.0699 - val_accuracy: 0.6333 - val_precision: 0.5714 - val_recall: 0.6154 - val_f1_score: 0.5926 - lr: 1.0000e-05\n",
            "Epoch 132/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3541 - accuracy: 0.8714 - precision: 0.8533 - recall: 0.9014 - f1_score: 0.8767\n",
            "Epoch 132: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.3541 - accuracy: 0.8714 - precision: 0.8533 - recall: 0.9014 - f1_score: 0.8767 - val_loss: 1.0307 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 133/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.8571 - precision: 0.8923 - recall: 0.8169 - f1_score: 0.8529\n",
            "Epoch 133: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.3272 - accuracy: 0.8571 - precision: 0.8923 - recall: 0.8169 - f1_score: 0.8529 - val_loss: 1.0152 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 134/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8714 - precision: 0.8841 - recall: 0.8592 - f1_score: 0.8714\n",
            "Epoch 134: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.3434 - accuracy: 0.8714 - precision: 0.8841 - recall: 0.8592 - f1_score: 0.8714 - val_loss: 1.0564 - val_accuracy: 0.6667 - val_precision: 0.6364 - val_recall: 0.5385 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 135/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.8214 - precision: 0.8108 - recall: 0.8451 - f1_score: 0.8276\n",
            "Epoch 135: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 90ms/step - loss: 0.3643 - accuracy: 0.8214 - precision: 0.8108 - recall: 0.8451 - f1_score: 0.8276 - val_loss: 1.1298 - val_accuracy: 0.6667 - val_precision: 0.6154 - val_recall: 0.6154 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 136/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3396 - accuracy: 0.8571 - precision: 0.8493 - recall: 0.8732 - f1_score: 0.8611\n",
            "Epoch 136: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.3396 - accuracy: 0.8571 - precision: 0.8493 - recall: 0.8732 - f1_score: 0.8611 - val_loss: 1.1598 - val_accuracy: 0.6667 - val_precision: 0.6154 - val_recall: 0.6154 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 136: early stopping\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.5841 - accuracy: 0.7000 - precision: 0.6667 - recall: 0.8750 - f1_score: 0.7568\n",
            "\n",
            "############# Fold n°5 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.4630 - accuracy: 0.5118 - precision: 0.4954 - recall: 0.6585 - f1_score: 0.5654\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 6s 97ms/step - loss: 2.4630 - accuracy: 0.5118 - precision: 0.4954 - recall: 0.6585 - f1_score: 0.5654 - val_loss: 2.1469 - val_accuracy: 0.6667 - val_precision: 0.7500 - val_recall: 0.6667 - val_f1_score: 0.7059 - lr: 1.0000e-04\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.9000 - accuracy: 0.5286 - precision: 0.5000 - recall: 0.8636 - f1_score: 0.6333\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 1.9000 - accuracy: 0.5286 - precision: 0.5000 - recall: 0.8636 - f1_score: 0.6333 - val_loss: 1.6669 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.4913 - accuracy: 0.5286 - precision: 0.5000 - recall: 0.0152 - f1_score: 0.0294\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 1.4913 - accuracy: 0.5286 - precision: 0.5000 - recall: 0.0152 - f1_score: 0.0294 - val_loss: 1.3175 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.1994 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 1.1994 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 1.1004 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0443 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 1.0443 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 1.0117 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0105 - accuracy: 0.5357 - precision: 1.0000 - recall: 0.0152 - f1_score: 0.0299\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 91ms/step - loss: 1.0105 - accuracy: 0.5357 - precision: 1.0000 - recall: 0.0152 - f1_score: 0.0299 - val_loss: 1.0203 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9842 - accuracy: 0.5357 - precision: 1.0000 - recall: 0.0152 - f1_score: 0.0299\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 99ms/step - loss: 0.9842 - accuracy: 0.5357 - precision: 1.0000 - recall: 0.0152 - f1_score: 0.0299 - val_loss: 0.9343 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8687 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.8687 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.8235 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8026 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.8026 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7894 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.7683 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7643 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7547 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.7547 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7582 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7496 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.7496 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7535 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7476 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.7476 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7464 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7348 - accuracy: 0.5357 - precision: 1.0000 - recall: 0.0152 - f1_score: 0.0299\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.7348 - accuracy: 0.5357 - precision: 1.0000 - recall: 0.0152 - f1_score: 0.0299 - val_loss: 0.7405 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7354 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.7354 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7233 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7419 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.7419 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7267 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.7216 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7041 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7283 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.7283 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6963 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7175 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.7175 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6904 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7222 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.7222 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6997 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7168 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.7168 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6985 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7100 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.7100 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6833 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7187 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.7187 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6714 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7063 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.7063 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6657 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6833 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.6833 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6515 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.6999 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6534 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.6853 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6457 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.6749 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6471 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.6645 - accuracy: 0.5286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6468 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.1667 - val_f1_score: 0.2857 - lr: 5.0000e-05\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6728 - accuracy: 0.5786 - precision: 1.0000 - recall: 0.1061 - f1_score: 0.1918\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.6728 - accuracy: 0.5786 - precision: 1.0000 - recall: 0.1061 - f1_score: 0.1918 - val_loss: 0.6490 - val_accuracy: 0.6000 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000 - lr: 5.0000e-05\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.5857 - precision: 0.9000 - recall: 0.1364 - f1_score: 0.2368\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.6309 - accuracy: 0.5857 - precision: 0.9000 - recall: 0.1364 - f1_score: 0.2368 - val_loss: 0.6564 - val_accuracy: 0.6000 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000 - lr: 5.0000e-05\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6495 - accuracy: 0.6000 - precision: 1.0000 - recall: 0.1515 - f1_score: 0.2632\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.6495 - accuracy: 0.6000 - precision: 1.0000 - recall: 0.1515 - f1_score: 0.2632 - val_loss: 0.6493 - val_accuracy: 0.6000 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.6286 - precision: 0.8500 - recall: 0.2576 - f1_score: 0.3953\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.6349 - accuracy: 0.6286 - precision: 0.8500 - recall: 0.2576 - f1_score: 0.3953 - val_loss: 0.6469 - val_accuracy: 0.6333 - val_precision: 1.0000 - val_recall: 0.3889 - val_f1_score: 0.5600 - lr: 2.5000e-05\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.6500 - precision: 0.9474 - recall: 0.2727 - f1_score: 0.4235\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.6155 - accuracy: 0.6500 - precision: 0.9474 - recall: 0.2727 - f1_score: 0.4235 - val_loss: 0.6545 - val_accuracy: 0.6000 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.6571 - precision: 1.0000 - recall: 0.2727 - f1_score: 0.4286\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.6061 - accuracy: 0.6571 - precision: 1.0000 - recall: 0.2727 - f1_score: 0.4286 - val_loss: 0.6703 - val_accuracy: 0.6000 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.6429 - precision: 1.0000 - recall: 0.2424 - f1_score: 0.3902\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.6177 - accuracy: 0.6429 - precision: 1.0000 - recall: 0.2424 - f1_score: 0.3902 - val_loss: 0.6586 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.4444 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6167 - accuracy: 0.6571 - precision: 0.8750 - recall: 0.3182 - f1_score: 0.4667\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.6167 - accuracy: 0.6571 - precision: 0.8750 - recall: 0.3182 - f1_score: 0.4667 - val_loss: 0.6568 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.4444 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.6571 - precision: 0.8000 - recall: 0.3636 - f1_score: 0.5000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.6096 - accuracy: 0.6571 - precision: 0.8000 - recall: 0.3636 - f1_score: 0.5000 - val_loss: 0.6700 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.4444 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6069 - accuracy: 0.6429 - precision: 0.9000 - recall: 0.2727 - f1_score: 0.4186\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.6069 - accuracy: 0.6429 - precision: 0.9000 - recall: 0.2727 - f1_score: 0.4186 - val_loss: 0.6891 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.4444 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.7000 - precision: 0.9000 - recall: 0.4091 - f1_score: 0.5625\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.6144 - accuracy: 0.7000 - precision: 0.9000 - recall: 0.4091 - f1_score: 0.5625 - val_loss: 0.6702 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.4444 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5987 - accuracy: 0.7286 - precision: 0.9118 - recall: 0.4697 - f1_score: 0.6200\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.5987 - accuracy: 0.7286 - precision: 0.9118 - recall: 0.4697 - f1_score: 0.6200 - val_loss: 0.6938 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.4444 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.6857 - precision: 0.8438 - recall: 0.4091 - f1_score: 0.5510\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.6084 - accuracy: 0.6857 - precision: 0.8438 - recall: 0.4091 - f1_score: 0.5510 - val_loss: 0.6926 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.4444 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.7500 - precision: 0.8444 - recall: 0.5758 - f1_score: 0.6847\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.6111 - accuracy: 0.7500 - precision: 0.8444 - recall: 0.5758 - f1_score: 0.6847 - val_loss: 0.6778 - val_accuracy: 0.7667 - val_precision: 1.0000 - val_recall: 0.6111 - val_f1_score: 0.7586 - lr: 2.5000e-05\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7000 - precision: 0.8529 - recall: 0.4394 - f1_score: 0.5800\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.5973 - accuracy: 0.7000 - precision: 0.8529 - recall: 0.4394 - f1_score: 0.5800 - val_loss: 0.6905 - val_accuracy: 0.7333 - val_precision: 1.0000 - val_recall: 0.5556 - val_f1_score: 0.7143 - lr: 2.5000e-05\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.7286 - precision: 0.8684 - recall: 0.5000 - f1_score: 0.6346\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5772 - accuracy: 0.7286 - precision: 0.8684 - recall: 0.5000 - f1_score: 0.6346 - val_loss: 0.6981 - val_accuracy: 0.7333 - val_precision: 1.0000 - val_recall: 0.5556 - val_f1_score: 0.7143 - lr: 2.5000e-05\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5945 - accuracy: 0.7143 - precision: 0.8824 - recall: 0.4545 - f1_score: 0.6000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.5945 - accuracy: 0.7143 - precision: 0.8824 - recall: 0.4545 - f1_score: 0.6000 - val_loss: 0.7078 - val_accuracy: 0.7000 - val_precision: 1.0000 - val_recall: 0.5000 - val_f1_score: 0.6667 - lr: 2.5000e-05\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.6857 - precision: 0.8056 - recall: 0.4394 - f1_score: 0.5686\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.5667 - accuracy: 0.6857 - precision: 0.8056 - recall: 0.4394 - f1_score: 0.5686 - val_loss: 0.7084 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.4444 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.7214 - precision: 0.8462 - recall: 0.5000 - f1_score: 0.6286\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.5620 - accuracy: 0.7214 - precision: 0.8462 - recall: 0.5000 - f1_score: 0.6286 - val_loss: 0.7342 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.4444 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5712 - accuracy: 0.7214 - precision: 0.8649 - recall: 0.4848 - f1_score: 0.6214\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5712 - accuracy: 0.7214 - precision: 0.8649 - recall: 0.4848 - f1_score: 0.6214 - val_loss: 0.7074 - val_accuracy: 0.7000 - val_precision: 0.9091 - val_recall: 0.5556 - val_f1_score: 0.6897 - lr: 2.5000e-05\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.7929 - precision: 0.8627 - recall: 0.6667 - f1_score: 0.7521\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.5750 - accuracy: 0.7929 - precision: 0.8627 - recall: 0.6667 - f1_score: 0.7521 - val_loss: 0.7125 - val_accuracy: 0.7000 - val_precision: 0.9091 - val_recall: 0.5556 - val_f1_score: 0.6897 - lr: 2.5000e-05\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.7929 - precision: 0.8627 - recall: 0.6667 - f1_score: 0.7521\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.5944 - accuracy: 0.7929 - precision: 0.8627 - recall: 0.6667 - f1_score: 0.7521 - val_loss: 0.7288 - val_accuracy: 0.7333 - val_precision: 1.0000 - val_recall: 0.5556 - val_f1_score: 0.7143 - lr: 2.5000e-05\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.7857 - precision: 0.8913 - recall: 0.6212 - f1_score: 0.7321\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.5734 - accuracy: 0.7857 - precision: 0.8913 - recall: 0.6212 - f1_score: 0.7321 - val_loss: 0.7284 - val_accuracy: 0.7333 - val_precision: 1.0000 - val_recall: 0.5556 - val_f1_score: 0.7143 - lr: 2.5000e-05\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.7714 - precision: 0.8696 - recall: 0.6061 - f1_score: 0.7143\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.5749 - accuracy: 0.7714 - precision: 0.8696 - recall: 0.6061 - f1_score: 0.7143 - val_loss: 0.7282 - val_accuracy: 0.7333 - val_precision: 1.0000 - val_recall: 0.5556 - val_f1_score: 0.7143 - lr: 2.5000e-05\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.7214 - precision: 0.8462 - recall: 0.5000 - f1_score: 0.6286\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.5676 - accuracy: 0.7214 - precision: 0.8462 - recall: 0.5000 - f1_score: 0.6286 - val_loss: 0.7387 - val_accuracy: 0.7333 - val_precision: 1.0000 - val_recall: 0.5556 - val_f1_score: 0.7143 - lr: 2.5000e-05\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.8143 - precision: 0.9000 - recall: 0.6818 - f1_score: 0.7759\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.5639 - accuracy: 0.8143 - precision: 0.9000 - recall: 0.6818 - f1_score: 0.7759 - val_loss: 0.7113 - val_accuracy: 0.7667 - val_precision: 0.9231 - val_recall: 0.6667 - val_f1_score: 0.7742 - lr: 2.5000e-05\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.7429 - precision: 0.8409 - recall: 0.5606 - f1_score: 0.6727\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5683 - accuracy: 0.7429 - precision: 0.8409 - recall: 0.5606 - f1_score: 0.6727 - val_loss: 0.7398 - val_accuracy: 0.7333 - val_precision: 1.0000 - val_recall: 0.5556 - val_f1_score: 0.7143 - lr: 2.5000e-05\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7929 - precision: 0.8776 - recall: 0.6515 - f1_score: 0.7478\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.5446 - accuracy: 0.7929 - precision: 0.8776 - recall: 0.6515 - f1_score: 0.7478 - val_loss: 0.7172 - val_accuracy: 0.7667 - val_precision: 0.8667 - val_recall: 0.7222 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.7643 - precision: 0.8511 - recall: 0.6061 - f1_score: 0.7080\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.5359 - accuracy: 0.7643 - precision: 0.8511 - recall: 0.6061 - f1_score: 0.7080 - val_loss: 0.7672 - val_accuracy: 0.7333 - val_precision: 1.0000 - val_recall: 0.5556 - val_f1_score: 0.7143 - lr: 2.5000e-05\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.7500 - precision: 0.8444 - recall: 0.5758 - f1_score: 0.6847\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.5351 - accuracy: 0.7500 - precision: 0.8444 - recall: 0.5758 - f1_score: 0.6847 - val_loss: 0.7817 - val_accuracy: 0.7000 - val_precision: 1.0000 - val_recall: 0.5000 - val_f1_score: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5442 - accuracy: 0.7857 - precision: 0.8333 - recall: 0.6818 - f1_score: 0.7500\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5442 - accuracy: 0.7857 - precision: 0.8333 - recall: 0.6818 - f1_score: 0.7500 - val_loss: 0.7345 - val_accuracy: 0.7667 - val_precision: 0.8667 - val_recall: 0.7222 - val_f1_score: 0.7879 - lr: 1.2500e-05\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.8143 - precision: 0.8571 - recall: 0.7273 - f1_score: 0.7869\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.5392 - accuracy: 0.8143 - precision: 0.8571 - recall: 0.7273 - f1_score: 0.7869 - val_loss: 0.7352 - val_accuracy: 0.7667 - val_precision: 0.8667 - val_recall: 0.7222 - val_f1_score: 0.7879 - lr: 1.2500e-05\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.8286 - precision: 0.8750 - recall: 0.7424 - f1_score: 0.8033\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.5365 - accuracy: 0.8286 - precision: 0.8750 - recall: 0.7424 - f1_score: 0.8033 - val_loss: 0.7348 - val_accuracy: 0.7667 - val_precision: 0.9231 - val_recall: 0.6667 - val_f1_score: 0.7742 - lr: 1.2500e-05\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.7786 - precision: 0.8571 - recall: 0.6364 - f1_score: 0.7304\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5474 - accuracy: 0.7786 - precision: 0.8571 - recall: 0.6364 - f1_score: 0.7304 - val_loss: 0.7298 - val_accuracy: 0.7667 - val_precision: 0.9231 - val_recall: 0.6667 - val_f1_score: 0.7742 - lr: 1.2500e-05\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.7714 - precision: 0.8148 - recall: 0.6667 - f1_score: 0.7333\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.5305 - accuracy: 0.7714 - precision: 0.8148 - recall: 0.6667 - f1_score: 0.7333 - val_loss: 0.7585 - val_accuracy: 0.7000 - val_precision: 0.9091 - val_recall: 0.5556 - val_f1_score: 0.6897 - lr: 1.2500e-05\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.8000 - precision: 0.8519 - recall: 0.6970 - f1_score: 0.7667\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.5618 - accuracy: 0.8000 - precision: 0.8519 - recall: 0.6970 - f1_score: 0.7667 - val_loss: 0.7114 - val_accuracy: 0.7667 - val_precision: 0.8667 - val_recall: 0.7222 - val_f1_score: 0.7879 - lr: 1.2500e-05\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.8071 - precision: 0.8545 - recall: 0.7121 - f1_score: 0.7769\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.5229 - accuracy: 0.8071 - precision: 0.8545 - recall: 0.7121 - f1_score: 0.7769 - val_loss: 0.7363 - val_accuracy: 0.8000 - val_precision: 0.9286 - val_recall: 0.7222 - val_f1_score: 0.8125 - lr: 1.2500e-05\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.7929 - precision: 0.8491 - recall: 0.6818 - f1_score: 0.7563\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.5247 - accuracy: 0.7929 - precision: 0.8491 - recall: 0.6818 - f1_score: 0.7563 - val_loss: 0.7824 - val_accuracy: 0.7333 - val_precision: 0.9167 - val_recall: 0.6111 - val_f1_score: 0.7333 - lr: 1.2500e-05\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.7786 - precision: 0.8431 - recall: 0.6515 - f1_score: 0.7350\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.5414 - accuracy: 0.7786 - precision: 0.8431 - recall: 0.6515 - f1_score: 0.7350 - val_loss: 0.7710 - val_accuracy: 0.8000 - val_precision: 0.9286 - val_recall: 0.7222 - val_f1_score: 0.8125 - lr: 1.2500e-05\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.8000 - precision: 0.8654 - recall: 0.6818 - f1_score: 0.7627\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 92ms/step - loss: 0.5139 - accuracy: 0.8000 - precision: 0.8654 - recall: 0.6818 - f1_score: 0.7627 - val_loss: 0.7619 - val_accuracy: 0.7667 - val_precision: 0.8667 - val_recall: 0.7222 - val_f1_score: 0.7879 - lr: 1.2500e-05\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.8143 - precision: 0.8704 - recall: 0.7121 - f1_score: 0.7833\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.5266 - accuracy: 0.8143 - precision: 0.8704 - recall: 0.7121 - f1_score: 0.7833 - val_loss: 0.7487 - val_accuracy: 0.8000 - val_precision: 0.9286 - val_recall: 0.7222 - val_f1_score: 0.8125 - lr: 1.2500e-05\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.8000 - precision: 0.8654 - recall: 0.6818 - f1_score: 0.7627\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.5265 - accuracy: 0.8000 - precision: 0.8654 - recall: 0.6818 - f1_score: 0.7627 - val_loss: 0.7471 - val_accuracy: 0.8000 - val_precision: 0.9286 - val_recall: 0.7222 - val_f1_score: 0.8125 - lr: 1.2500e-05\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.8000 - precision: 0.8519 - recall: 0.6970 - f1_score: 0.7667\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.5319 - accuracy: 0.8000 - precision: 0.8519 - recall: 0.6970 - f1_score: 0.7667 - val_loss: 0.7402 - val_accuracy: 0.7667 - val_precision: 0.8667 - val_recall: 0.7222 - val_f1_score: 0.7879 - lr: 1.2500e-05\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.8071 - precision: 0.8545 - recall: 0.7121 - f1_score: 0.7769\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.5314 - accuracy: 0.8071 - precision: 0.8545 - recall: 0.7121 - f1_score: 0.7769 - val_loss: 0.7462 - val_accuracy: 0.7667 - val_precision: 0.8667 - val_recall: 0.7222 - val_f1_score: 0.7879 - lr: 1.2500e-05\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.8071 - precision: 0.8980 - recall: 0.6667 - f1_score: 0.7652\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.5281 - accuracy: 0.8071 - precision: 0.8980 - recall: 0.6667 - f1_score: 0.7652 - val_loss: 0.7548 - val_accuracy: 0.8000 - val_precision: 0.9286 - val_recall: 0.7222 - val_f1_score: 0.8125 - lr: 1.2500e-05\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.8143 - precision: 0.8333 - recall: 0.7576 - f1_score: 0.7937\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5253 - accuracy: 0.8143 - precision: 0.8333 - recall: 0.7576 - f1_score: 0.7937 - val_loss: 0.7237 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.2500e-05\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.8286 - precision: 0.8750 - recall: 0.7424 - f1_score: 0.8033\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.5247 - accuracy: 0.8286 - precision: 0.8750 - recall: 0.7424 - f1_score: 0.8033 - val_loss: 0.7568 - val_accuracy: 0.8000 - val_precision: 0.9286 - val_recall: 0.7222 - val_f1_score: 0.8125 - lr: 1.2500e-05\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.7929 - precision: 0.8364 - recall: 0.6970 - f1_score: 0.7603\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.5841 - accuracy: 0.7929 - precision: 0.8364 - recall: 0.6970 - f1_score: 0.7603 - val_loss: 0.7244 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.2500e-05\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.8286 - precision: 0.8387 - recall: 0.7879 - f1_score: 0.8125\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.5333 - accuracy: 0.8286 - precision: 0.8387 - recall: 0.7879 - f1_score: 0.8125 - val_loss: 0.7263 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.2500e-05\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5140 - accuracy: 0.8143 - precision: 0.8333 - recall: 0.7576 - f1_score: 0.7937\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.5140 - accuracy: 0.8143 - precision: 0.8333 - recall: 0.7576 - f1_score: 0.7937 - val_loss: 0.8060 - val_accuracy: 0.7000 - val_precision: 0.8462 - val_recall: 0.6111 - val_f1_score: 0.7097 - lr: 1.2500e-05\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7714 - precision: 0.8696 - recall: 0.6061 - f1_score: 0.7143\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.5446 - accuracy: 0.7714 - precision: 0.8696 - recall: 0.6061 - f1_score: 0.7143 - val_loss: 0.8322 - val_accuracy: 0.7000 - val_precision: 0.8462 - val_recall: 0.6111 - val_f1_score: 0.7097 - lr: 1.2500e-05\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5477 - accuracy: 0.7857 - precision: 0.8333 - recall: 0.6818 - f1_score: 0.7500\n",
            "Epoch 81: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.5477 - accuracy: 0.7857 - precision: 0.8333 - recall: 0.6818 - f1_score: 0.7500 - val_loss: 0.7197 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.2500e-05\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.8429 - precision: 0.8548 - recall: 0.8030 - f1_score: 0.8281\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5281 - accuracy: 0.8429 - precision: 0.8548 - recall: 0.8030 - f1_score: 0.8281 - val_loss: 0.6934 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5095 - accuracy: 0.8214 - precision: 0.8596 - recall: 0.7424 - f1_score: 0.7967\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.5095 - accuracy: 0.8214 - precision: 0.8596 - recall: 0.7424 - f1_score: 0.7967 - val_loss: 0.7422 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.8357 - precision: 0.8909 - recall: 0.7424 - f1_score: 0.8099\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5216 - accuracy: 0.8357 - precision: 0.8909 - recall: 0.7424 - f1_score: 0.8099 - val_loss: 0.8026 - val_accuracy: 0.7667 - val_precision: 1.0000 - val_recall: 0.6111 - val_f1_score: 0.7586 - lr: 1.0000e-05\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5006 - accuracy: 0.7857 - precision: 0.8462 - recall: 0.6667 - f1_score: 0.7458\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5006 - accuracy: 0.7857 - precision: 0.8462 - recall: 0.6667 - f1_score: 0.7458 - val_loss: 0.7724 - val_accuracy: 0.8000 - val_precision: 0.9286 - val_recall: 0.7222 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.8357 - precision: 0.8644 - recall: 0.7727 - f1_score: 0.8160\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.5237 - accuracy: 0.8357 - precision: 0.8644 - recall: 0.7727 - f1_score: 0.8160 - val_loss: 0.7335 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.8286 - precision: 0.8621 - recall: 0.7576 - f1_score: 0.8065\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.5071 - accuracy: 0.8286 - precision: 0.8621 - recall: 0.7576 - f1_score: 0.8065 - val_loss: 0.7522 - val_accuracy: 0.7333 - val_precision: 0.8571 - val_recall: 0.6667 - val_f1_score: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.8214 - precision: 0.8596 - recall: 0.7424 - f1_score: 0.7967\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.5380 - accuracy: 0.8214 - precision: 0.8596 - recall: 0.7424 - f1_score: 0.7967 - val_loss: 0.7227 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.7929 - precision: 0.8246 - recall: 0.7121 - f1_score: 0.7642\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.5172 - accuracy: 0.7929 - precision: 0.8246 - recall: 0.7121 - f1_score: 0.7642 - val_loss: 0.7452 - val_accuracy: 0.7333 - val_precision: 0.8571 - val_recall: 0.6667 - val_f1_score: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.8071 - precision: 0.8421 - recall: 0.7273 - f1_score: 0.7805\n",
            "Epoch 90: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.5181 - accuracy: 0.8071 - precision: 0.8421 - recall: 0.7273 - f1_score: 0.7805 - val_loss: 0.7836 - val_accuracy: 0.7333 - val_precision: 0.8571 - val_recall: 0.6667 - val_f1_score: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.8214 - precision: 0.8475 - recall: 0.7576 - f1_score: 0.8000\n",
            "Epoch 91: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.5309 - accuracy: 0.8214 - precision: 0.8475 - recall: 0.7576 - f1_score: 0.8000 - val_loss: 0.7595 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8357 - precision: 0.8413 - recall: 0.8030 - f1_score: 0.8217\n",
            "Epoch 92: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.4911 - accuracy: 0.8357 - precision: 0.8413 - recall: 0.8030 - f1_score: 0.8217 - val_loss: 0.7385 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.8071 - precision: 0.8421 - recall: 0.7273 - f1_score: 0.7805\n",
            "Epoch 93: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.5264 - accuracy: 0.8071 - precision: 0.8421 - recall: 0.7273 - f1_score: 0.7805 - val_loss: 0.7857 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.8071 - precision: 0.8421 - recall: 0.7273 - f1_score: 0.7805\n",
            "Epoch 94: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.5051 - accuracy: 0.8071 - precision: 0.8421 - recall: 0.7273 - f1_score: 0.7805 - val_loss: 0.7783 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.8357 - precision: 0.8909 - recall: 0.7424 - f1_score: 0.8099\n",
            "Epoch 95: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.4865 - accuracy: 0.8357 - precision: 0.8909 - recall: 0.7424 - f1_score: 0.8099 - val_loss: 0.7642 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4978 - accuracy: 0.7929 - precision: 0.8491 - recall: 0.6818 - f1_score: 0.7563\n",
            "Epoch 96: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.4978 - accuracy: 0.7929 - precision: 0.8491 - recall: 0.6818 - f1_score: 0.7563 - val_loss: 0.7994 - val_accuracy: 0.8333 - val_precision: 0.9333 - val_recall: 0.7778 - val_f1_score: 0.8485 - lr: 1.0000e-05\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.8071 - precision: 0.8679 - recall: 0.6970 - f1_score: 0.7731\n",
            "Epoch 97: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.4841 - accuracy: 0.8071 - precision: 0.8679 - recall: 0.6970 - f1_score: 0.7731 - val_loss: 0.7919 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.8143 - precision: 0.8571 - recall: 0.7273 - f1_score: 0.7869\n",
            "Epoch 98: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.5013 - accuracy: 0.8143 - precision: 0.8571 - recall: 0.7273 - f1_score: 0.7869 - val_loss: 0.7850 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.8214 - precision: 0.8475 - recall: 0.7576 - f1_score: 0.8000\n",
            "Epoch 99: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.4970 - accuracy: 0.8214 - precision: 0.8475 - recall: 0.7576 - f1_score: 0.8000 - val_loss: 0.8319 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.8214 - precision: 0.8596 - recall: 0.7424 - f1_score: 0.7967\n",
            "Epoch 100: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.5019 - accuracy: 0.8214 - precision: 0.8596 - recall: 0.7424 - f1_score: 0.7967 - val_loss: 0.8116 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.8286 - precision: 0.8750 - recall: 0.7424 - f1_score: 0.8033\n",
            "Epoch 101: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.5019 - accuracy: 0.8286 - precision: 0.8750 - recall: 0.7424 - f1_score: 0.8033 - val_loss: 0.7954 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.8357 - precision: 0.8525 - recall: 0.7879 - f1_score: 0.8189\n",
            "Epoch 102: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5170 - accuracy: 0.8357 - precision: 0.8525 - recall: 0.7879 - f1_score: 0.8189 - val_loss: 0.7600 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8000 - precision: 0.8065 - recall: 0.7576 - f1_score: 0.7813\n",
            "Epoch 103: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5182 - accuracy: 0.8000 - precision: 0.8065 - recall: 0.7576 - f1_score: 0.7813 - val_loss: 0.7554 - val_accuracy: 0.8667 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.8143 - precision: 0.8333 - recall: 0.7576 - f1_score: 0.7937\n",
            "Epoch 104: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.4915 - accuracy: 0.8143 - precision: 0.8333 - recall: 0.7576 - f1_score: 0.7937 - val_loss: 0.8277 - val_accuracy: 0.7333 - val_precision: 0.8571 - val_recall: 0.6667 - val_f1_score: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.8214 - precision: 0.8475 - recall: 0.7576 - f1_score: 0.8000\n",
            "Epoch 105: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.4865 - accuracy: 0.8214 - precision: 0.8475 - recall: 0.7576 - f1_score: 0.8000 - val_loss: 0.8469 - val_accuracy: 0.7000 - val_precision: 0.8462 - val_recall: 0.6111 - val_f1_score: 0.7097 - lr: 1.0000e-05\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.8143 - precision: 0.8333 - recall: 0.7576 - f1_score: 0.7937\n",
            "Epoch 106: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.4928 - accuracy: 0.8143 - precision: 0.8333 - recall: 0.7576 - f1_score: 0.7937 - val_loss: 0.7738 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.8429 - precision: 0.8333 - recall: 0.8333 - f1_score: 0.8333\n",
            "Epoch 107: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.5076 - accuracy: 0.8429 - precision: 0.8333 - recall: 0.8333 - f1_score: 0.8333 - val_loss: 0.8142 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.7929 - precision: 0.8246 - recall: 0.7121 - f1_score: 0.7642\n",
            "Epoch 108: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.5030 - accuracy: 0.7929 - precision: 0.8246 - recall: 0.7121 - f1_score: 0.7642 - val_loss: 0.8151 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.8143 - precision: 0.8448 - recall: 0.7424 - f1_score: 0.7903\n",
            "Epoch 109: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.4966 - accuracy: 0.8143 - precision: 0.8448 - recall: 0.7424 - f1_score: 0.7903 - val_loss: 0.8203 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.8286 - precision: 0.8500 - recall: 0.7727 - f1_score: 0.8095\n",
            "Epoch 110: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 93ms/step - loss: 0.4968 - accuracy: 0.8286 - precision: 0.8500 - recall: 0.7727 - f1_score: 0.8095 - val_loss: 0.8926 - val_accuracy: 0.7667 - val_precision: 0.8667 - val_recall: 0.7222 - val_f1_score: 0.7879 - lr: 1.0000e-05\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.8143 - precision: 0.8448 - recall: 0.7424 - f1_score: 0.7903\n",
            "Epoch 111: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.4927 - accuracy: 0.8143 - precision: 0.8448 - recall: 0.7424 - f1_score: 0.7903 - val_loss: 0.8420 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.8500 - precision: 0.8358 - recall: 0.8485 - f1_score: 0.8421\n",
            "Epoch 112: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.4750 - accuracy: 0.8500 - precision: 0.8358 - recall: 0.8485 - f1_score: 0.8421 - val_loss: 0.8544 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.8714 - precision: 0.8871 - recall: 0.8333 - f1_score: 0.8594\n",
            "Epoch 113: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.4803 - accuracy: 0.8714 - precision: 0.8871 - recall: 0.8333 - f1_score: 0.8594 - val_loss: 0.9217 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.8500 - precision: 0.8358 - recall: 0.8485 - f1_score: 0.8421\n",
            "Epoch 114: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.5035 - accuracy: 0.8500 - precision: 0.8358 - recall: 0.8485 - f1_score: 0.8421 - val_loss: 0.9025 - val_accuracy: 0.8000 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.8214 - precision: 0.8254 - recall: 0.7879 - f1_score: 0.8062\n",
            "Epoch 115: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.4804 - accuracy: 0.8214 - precision: 0.8254 - recall: 0.7879 - f1_score: 0.8062 - val_loss: 0.8361 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.8500 - precision: 0.8462 - recall: 0.8333 - f1_score: 0.8397\n",
            "Epoch 116: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.4658 - accuracy: 0.8500 - precision: 0.8462 - recall: 0.8333 - f1_score: 0.8397 - val_loss: 0.8753 - val_accuracy: 0.8000 - val_precision: 0.8750 - val_recall: 0.7778 - val_f1_score: 0.8235 - lr: 1.0000e-05\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.8286 - precision: 0.8621 - recall: 0.7576 - f1_score: 0.8065\n",
            "Epoch 117: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.4843 - accuracy: 0.8286 - precision: 0.8621 - recall: 0.7576 - f1_score: 0.8065 - val_loss: 0.8583 - val_accuracy: 0.8333 - val_precision: 0.9333 - val_recall: 0.7778 - val_f1_score: 0.8485 - lr: 1.0000e-05\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.8357 - precision: 0.8413 - recall: 0.8030 - f1_score: 0.8217\n",
            "Epoch 118: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.4792 - accuracy: 0.8357 - precision: 0.8413 - recall: 0.8030 - f1_score: 0.8217 - val_loss: 0.8588 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4808 - accuracy: 0.8286 - precision: 0.8387 - recall: 0.7879 - f1_score: 0.8125\n",
            "Epoch 119: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4808 - accuracy: 0.8286 - precision: 0.8387 - recall: 0.7879 - f1_score: 0.8125 - val_loss: 0.8380 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.8500 - precision: 0.8689 - recall: 0.8030 - f1_score: 0.8346\n",
            "Epoch 120: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.4827 - accuracy: 0.8500 - precision: 0.8689 - recall: 0.8030 - f1_score: 0.8346 - val_loss: 0.7802 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.8500 - precision: 0.8462 - recall: 0.8333 - f1_score: 0.8397\n",
            "Epoch 121: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4711 - accuracy: 0.8500 - precision: 0.8462 - recall: 0.8333 - f1_score: 0.8397 - val_loss: 0.7809 - val_accuracy: 0.8667 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.8571 - precision: 0.8710 - recall: 0.8182 - f1_score: 0.8437\n",
            "Epoch 122: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.4672 - accuracy: 0.8571 - precision: 0.8710 - recall: 0.8182 - f1_score: 0.8437 - val_loss: 0.8590 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.8214 - precision: 0.8361 - recall: 0.7727 - f1_score: 0.8031\n",
            "Epoch 123: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.4785 - accuracy: 0.8214 - precision: 0.8361 - recall: 0.7727 - f1_score: 0.8031 - val_loss: 0.8907 - val_accuracy: 0.8333 - val_precision: 0.8824 - val_recall: 0.8333 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4871 - accuracy: 0.8500 - precision: 0.8169 - recall: 0.8788 - f1_score: 0.8467\n",
            "Epoch 124: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.4871 - accuracy: 0.8500 - precision: 0.8169 - recall: 0.8788 - f1_score: 0.8467 - val_loss: 0.8180 - val_accuracy: 0.8333 - val_precision: 0.8421 - val_recall: 0.8889 - val_f1_score: 0.8649 - lr: 1.0000e-05\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.8714 - precision: 0.8529 - recall: 0.8788 - f1_score: 0.8657\n",
            "Epoch 125: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.4904 - accuracy: 0.8714 - precision: 0.8529 - recall: 0.8788 - f1_score: 0.8657 - val_loss: 0.8389 - val_accuracy: 0.8667 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.8500 - precision: 0.8261 - recall: 0.8636 - f1_score: 0.8444\n",
            "Epoch 126: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4716 - accuracy: 0.8500 - precision: 0.8261 - recall: 0.8636 - f1_score: 0.8444 - val_loss: 0.8459 - val_accuracy: 0.8667 - val_precision: 0.8889 - val_recall: 0.8889 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.8357 - precision: 0.8525 - recall: 0.7879 - f1_score: 0.8189\n",
            "Epoch 127: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.4432 - accuracy: 0.8357 - precision: 0.8525 - recall: 0.7879 - f1_score: 0.8189 - val_loss: 0.9157 - val_accuracy: 0.8000 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1_score: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 127: early stopping\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 1.1625 - accuracy: 0.8000 - precision: 0.7778 - recall: 0.8750 - f1_score: 0.8235\n",
            "\n",
            "############# Fold n°6 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.5108 - accuracy: 0.5176 - precision: 0.5046 - recall: 0.6627 - f1_score: 0.5729\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 7s 133ms/step - loss: 2.5108 - accuracy: 0.5176 - precision: 0.5046 - recall: 0.6627 - f1_score: 0.5729 - val_loss: 2.2266 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.9811 - accuracy: 0.5429 - precision: 0.5714 - recall: 0.1791 - f1_score: 0.2727\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 98ms/step - loss: 1.9811 - accuracy: 0.5429 - precision: 0.5714 - recall: 0.1791 - f1_score: 0.2727 - val_loss: 1.7481 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.5650 - accuracy: 0.3929 - precision: 0.2750 - recall: 0.1642 - f1_score: 0.2056\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 1.5650 - accuracy: 0.3929 - precision: 0.2750 - recall: 0.1642 - f1_score: 0.2056 - val_loss: 1.3802 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.2556 - accuracy: 0.5286 - precision: 0.5185 - recall: 0.2090 - f1_score: 0.2979\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 1.2556 - accuracy: 0.5286 - precision: 0.5185 - recall: 0.2090 - f1_score: 0.2979 - val_loss: 1.1463 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0835 - accuracy: 0.5071 - precision: 0.3750 - recall: 0.0448 - f1_score: 0.0800\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 1.0835 - accuracy: 0.5071 - precision: 0.3750 - recall: 0.0448 - f1_score: 0.0800 - val_loss: 1.0397 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0340 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 1.0340 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 1.0340 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0026 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 1.0026 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.9507 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8890 - accuracy: 0.5000 - precision: 0.4211 - recall: 0.1194 - f1_score: 0.1860\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.8890 - accuracy: 0.5000 - precision: 0.4211 - recall: 0.1194 - f1_score: 0.1860 - val_loss: 0.8386 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8160 - accuracy: 0.5286 - precision: 0.5455 - recall: 0.0896 - f1_score: 0.1538\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.8160 - accuracy: 0.5286 - precision: 0.5455 - recall: 0.0896 - f1_score: 0.1538 - val_loss: 0.7988 - val_accuracy: 0.4667 - val_precision: 1.0000 - val_recall: 0.0588 - val_f1_score: 0.1111 - lr: 1.0000e-04\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7798 - accuracy: 0.4429 - precision: 0.4127 - recall: 0.3881 - f1_score: 0.4000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.7798 - accuracy: 0.4429 - precision: 0.4127 - recall: 0.3881 - f1_score: 0.4000 - val_loss: 0.7669 - val_accuracy: 0.6000 - val_precision: 0.7273 - val_recall: 0.4706 - val_f1_score: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.5071 - precision: 0.4853 - recall: 0.4925 - f1_score: 0.4889\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.7622 - accuracy: 0.5071 - precision: 0.4853 - recall: 0.4925 - f1_score: 0.4889 - val_loss: 0.7594 - val_accuracy: 0.5667 - val_precision: 0.7500 - val_recall: 0.3529 - val_f1_score: 0.4800 - lr: 1.0000e-04\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7569 - accuracy: 0.5214 - precision: 0.5000 - recall: 0.1493 - f1_score: 0.2299\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.7569 - accuracy: 0.5214 - precision: 0.5000 - recall: 0.1493 - f1_score: 0.2299 - val_loss: 0.7580 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7530 - accuracy: 0.5571 - precision: 1.0000 - recall: 0.0746 - f1_score: 0.1389\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.7530 - accuracy: 0.5571 - precision: 1.0000 - recall: 0.0746 - f1_score: 0.1389 - val_loss: 0.7538 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7468 - accuracy: 0.5571 - precision: 0.5676 - recall: 0.3134 - f1_score: 0.4038\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.7468 - accuracy: 0.5571 - precision: 0.5676 - recall: 0.3134 - f1_score: 0.4038 - val_loss: 0.7488 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.1176 - val_f1_score: 0.2105 - lr: 1.0000e-04\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7419 - accuracy: 0.5571 - precision: 0.5455 - recall: 0.4478 - f1_score: 0.4918\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.7419 - accuracy: 0.5571 - precision: 0.5455 - recall: 0.4478 - f1_score: 0.4918 - val_loss: 0.7421 - val_accuracy: 0.5667 - val_precision: 0.6250 - val_recall: 0.5882 - val_f1_score: 0.6061 - lr: 1.0000e-04\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7475 - accuracy: 0.4429 - precision: 0.4321 - recall: 0.5224 - f1_score: 0.4730\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.7475 - accuracy: 0.4429 - precision: 0.4321 - recall: 0.5224 - f1_score: 0.4730 - val_loss: 0.7396 - val_accuracy: 0.6000 - val_precision: 0.6667 - val_recall: 0.5882 - val_f1_score: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.5071 - precision: 0.4000 - recall: 0.0597 - f1_score: 0.1039\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.7448 - accuracy: 0.5071 - precision: 0.4000 - recall: 0.0597 - f1_score: 0.1039 - val_loss: 0.7490 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7415 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.7415 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7466 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7383 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.7383 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7441 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7363 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.7363 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7417 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7343 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.7343 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7394 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7315 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.7315 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7371 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7289 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.7289 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7349 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7272 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.7272 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7330 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7252 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.7252 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7311 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7189 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.7189 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7249 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.7171 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7240 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.7169 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7232 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7157 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.7157 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7225 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7144 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.7144 - accuracy: 0.5214 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7200 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 5.0000e-05\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7127 - accuracy: 0.5286 - precision: 0.6000 - recall: 0.0448 - f1_score: 0.0833\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.7127 - accuracy: 0.5286 - precision: 0.6000 - recall: 0.0448 - f1_score: 0.0833 - val_loss: 0.7167 - val_accuracy: 0.4667 - val_precision: 1.0000 - val_recall: 0.0588 - val_f1_score: 0.1111 - lr: 5.0000e-05\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7022 - accuracy: 0.6071 - precision: 0.6765 - recall: 0.3433 - f1_score: 0.4554\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.7022 - accuracy: 0.6071 - precision: 0.6765 - recall: 0.3433 - f1_score: 0.4554 - val_loss: 0.7003 - val_accuracy: 0.5333 - val_precision: 0.5789 - val_recall: 0.6471 - val_f1_score: 0.6111 - lr: 5.0000e-05\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7126 - accuracy: 0.4929 - precision: 0.4722 - recall: 0.5075 - f1_score: 0.4892\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.7126 - accuracy: 0.4929 - precision: 0.4722 - recall: 0.5075 - f1_score: 0.4892 - val_loss: 0.6979 - val_accuracy: 0.6333 - val_precision: 0.7143 - val_recall: 0.5882 - val_f1_score: 0.6452 - lr: 5.0000e-05\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.5857 - precision: 0.6667 - recall: 0.2687 - f1_score: 0.3830\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.7004 - accuracy: 0.5857 - precision: 0.6667 - recall: 0.2687 - f1_score: 0.3830 - val_loss: 0.6944 - val_accuracy: 0.5667 - val_precision: 0.7000 - val_recall: 0.4118 - val_f1_score: 0.5185 - lr: 5.0000e-05\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.6214 - precision: 0.6296 - recall: 0.5075 - f1_score: 0.5620\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.6840 - accuracy: 0.6214 - precision: 0.6296 - recall: 0.5075 - f1_score: 0.5620 - val_loss: 0.6671 - val_accuracy: 0.6333 - val_precision: 0.6875 - val_recall: 0.6471 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.5500 - precision: 0.5333 - recall: 0.4776 - f1_score: 0.5039\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.6958 - accuracy: 0.5500 - precision: 0.5333 - recall: 0.4776 - f1_score: 0.5039 - val_loss: 0.6681 - val_accuracy: 0.6000 - val_precision: 0.7273 - val_recall: 0.4706 - val_f1_score: 0.5714 - lr: 5.0000e-05\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.5929 - precision: 0.6042 - recall: 0.4328 - f1_score: 0.5043\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.6763 - accuracy: 0.5929 - precision: 0.6042 - recall: 0.4328 - f1_score: 0.5043 - val_loss: 0.6555 - val_accuracy: 0.6333 - val_precision: 0.7500 - val_recall: 0.5294 - val_f1_score: 0.6207 - lr: 5.0000e-05\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6470 - accuracy: 0.6929 - precision: 0.7069 - recall: 0.6119 - f1_score: 0.6560\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.6470 - accuracy: 0.6929 - precision: 0.7069 - recall: 0.6119 - f1_score: 0.6560 - val_loss: 0.6364 - val_accuracy: 0.6000 - val_precision: 0.6667 - val_recall: 0.5882 - val_f1_score: 0.6250 - lr: 5.0000e-05\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.6429 - precision: 0.6441 - recall: 0.5672 - f1_score: 0.6032\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.6442 - accuracy: 0.6429 - precision: 0.6441 - recall: 0.5672 - f1_score: 0.6032 - val_loss: 0.6512 - val_accuracy: 0.6333 - val_precision: 0.7500 - val_recall: 0.5294 - val_f1_score: 0.6207 - lr: 5.0000e-05\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.6857 - precision: 0.8108 - recall: 0.4478 - f1_score: 0.5769\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 94ms/step - loss: 0.6070 - accuracy: 0.6857 - precision: 0.8108 - recall: 0.4478 - f1_score: 0.5769 - val_loss: 0.6369 - val_accuracy: 0.6667 - val_precision: 0.7692 - val_recall: 0.5882 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.6643 - precision: 0.6786 - recall: 0.5672 - f1_score: 0.6179\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.6322 - accuracy: 0.6643 - precision: 0.6786 - recall: 0.5672 - f1_score: 0.6179 - val_loss: 0.6180 - val_accuracy: 0.6667 - val_precision: 0.7692 - val_recall: 0.5882 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.6714 - precision: 0.7059 - recall: 0.5373 - f1_score: 0.6102\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.6377 - accuracy: 0.6714 - precision: 0.7059 - recall: 0.5373 - f1_score: 0.6102 - val_loss: 0.6245 - val_accuracy: 0.6333 - val_precision: 0.7500 - val_recall: 0.5294 - val_f1_score: 0.6207 - lr: 5.0000e-05\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6528 - accuracy: 0.6714 - precision: 0.7838 - recall: 0.4328 - f1_score: 0.5577\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.6528 - accuracy: 0.6714 - precision: 0.7838 - recall: 0.4328 - f1_score: 0.5577 - val_loss: 0.6277 - val_accuracy: 0.6333 - val_precision: 0.7500 - val_recall: 0.5294 - val_f1_score: 0.6207 - lr: 5.0000e-05\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.6143 - precision: 0.6444 - recall: 0.4328 - f1_score: 0.5179\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.6571 - accuracy: 0.6143 - precision: 0.6444 - recall: 0.4328 - f1_score: 0.5179 - val_loss: 0.6149 - val_accuracy: 0.6333 - val_precision: 0.7500 - val_recall: 0.5294 - val_f1_score: 0.6207 - lr: 5.0000e-05\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6255 - accuracy: 0.6857 - precision: 0.7949 - recall: 0.4627 - f1_score: 0.5849\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.6255 - accuracy: 0.6857 - precision: 0.7949 - recall: 0.4627 - f1_score: 0.5849 - val_loss: 0.6069 - val_accuracy: 0.6333 - val_precision: 0.7500 - val_recall: 0.5294 - val_f1_score: 0.6207 - lr: 5.0000e-05\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.6500 - precision: 0.7045 - recall: 0.4627 - f1_score: 0.5586\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.6133 - accuracy: 0.6500 - precision: 0.7045 - recall: 0.4627 - f1_score: 0.5586 - val_loss: 0.5866 - val_accuracy: 0.7000 - val_precision: 0.7857 - val_recall: 0.6471 - val_f1_score: 0.7097 - lr: 5.0000e-05\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.6214 - precision: 0.6458 - recall: 0.4627 - f1_score: 0.5391\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.6254 - accuracy: 0.6214 - precision: 0.6458 - recall: 0.4627 - f1_score: 0.5391 - val_loss: 0.5916 - val_accuracy: 0.6667 - val_precision: 0.7692 - val_recall: 0.5882 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6521 - accuracy: 0.6214 - precision: 0.6591 - recall: 0.4328 - f1_score: 0.5225\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.6521 - accuracy: 0.6214 - precision: 0.6591 - recall: 0.4328 - f1_score: 0.5225 - val_loss: 0.6041 - val_accuracy: 0.7000 - val_precision: 0.8333 - val_recall: 0.5882 - val_f1_score: 0.6897 - lr: 5.0000e-05\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6326 - accuracy: 0.6429 - precision: 0.7297 - recall: 0.4030 - f1_score: 0.5192\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.6326 - accuracy: 0.6429 - precision: 0.7297 - recall: 0.4030 - f1_score: 0.5192 - val_loss: 0.6000 - val_accuracy: 0.6667 - val_precision: 0.8182 - val_recall: 0.5294 - val_f1_score: 0.6429 - lr: 5.0000e-05\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6691 - accuracy: 0.6643 - precision: 0.7500 - recall: 0.4478 - f1_score: 0.5607\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.6691 - accuracy: 0.6643 - precision: 0.7500 - recall: 0.4478 - f1_score: 0.5607 - val_loss: 0.5842 - val_accuracy: 0.6333 - val_precision: 0.7500 - val_recall: 0.5294 - val_f1_score: 0.6207 - lr: 5.0000e-05\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.6643 - precision: 0.7174 - recall: 0.4925 - f1_score: 0.5841\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.6066 - accuracy: 0.6643 - precision: 0.7174 - recall: 0.4925 - f1_score: 0.5841 - val_loss: 0.6083 - val_accuracy: 0.5667 - val_precision: 0.6250 - val_recall: 0.5882 - val_f1_score: 0.6061 - lr: 5.0000e-05\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6542 - accuracy: 0.6357 - precision: 0.6667 - recall: 0.4776 - f1_score: 0.5565\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.6542 - accuracy: 0.6357 - precision: 0.6667 - recall: 0.4776 - f1_score: 0.5565 - val_loss: 0.5701 - val_accuracy: 0.6667 - val_precision: 0.7692 - val_recall: 0.5882 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6166 - accuracy: 0.6857 - precision: 0.7447 - recall: 0.5224 - f1_score: 0.6140\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.6166 - accuracy: 0.6857 - precision: 0.7447 - recall: 0.5224 - f1_score: 0.6140 - val_loss: 0.5543 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 5.0000e-05\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.6929 - precision: 0.7609 - recall: 0.5224 - f1_score: 0.6195\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.5984 - accuracy: 0.6929 - precision: 0.7609 - recall: 0.5224 - f1_score: 0.6195 - val_loss: 0.5497 - val_accuracy: 0.7333 - val_precision: 0.9091 - val_recall: 0.5882 - val_f1_score: 0.7143 - lr: 5.0000e-05\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.7000 - precision: 0.7551 - recall: 0.5522 - f1_score: 0.6379\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.6013 - accuracy: 0.7000 - precision: 0.7551 - recall: 0.5522 - f1_score: 0.6379 - val_loss: 0.5131 - val_accuracy: 0.7000 - val_precision: 0.7857 - val_recall: 0.6471 - val_f1_score: 0.7097 - lr: 5.0000e-05\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.7571 - precision: 0.8113 - recall: 0.6418 - f1_score: 0.7167\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.5317 - accuracy: 0.7571 - precision: 0.8113 - recall: 0.6418 - f1_score: 0.7167 - val_loss: 0.5084 - val_accuracy: 0.6667 - val_precision: 0.7692 - val_recall: 0.5882 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5863 - accuracy: 0.7429 - precision: 0.7925 - recall: 0.6269 - f1_score: 0.7000\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.5863 - accuracy: 0.7429 - precision: 0.7925 - recall: 0.6269 - f1_score: 0.7000 - val_loss: 0.5301 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 5.0000e-05\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.7429 - precision: 0.7627 - recall: 0.6716 - f1_score: 0.7143\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.5406 - accuracy: 0.7429 - precision: 0.7627 - recall: 0.6716 - f1_score: 0.7143 - val_loss: 0.5219 - val_accuracy: 0.7000 - val_precision: 0.7857 - val_recall: 0.6471 - val_f1_score: 0.7097 - lr: 5.0000e-05\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.7357 - precision: 0.7586 - recall: 0.6567 - f1_score: 0.7040\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 99ms/step - loss: 0.5400 - accuracy: 0.7357 - precision: 0.7586 - recall: 0.6567 - f1_score: 0.7040 - val_loss: 0.5229 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 5.0000e-05\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.7429 - precision: 0.7818 - recall: 0.6418 - f1_score: 0.7049\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.5271 - accuracy: 0.7429 - precision: 0.7818 - recall: 0.6418 - f1_score: 0.7049 - val_loss: 0.5190 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 5.0000e-05\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.7357 - precision: 0.8125 - recall: 0.5821 - f1_score: 0.6783\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.5393 - accuracy: 0.7357 - precision: 0.8125 - recall: 0.5821 - f1_score: 0.6783 - val_loss: 0.4970 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 5.0000e-05\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5095 - accuracy: 0.7429 - precision: 0.8780 - recall: 0.5373 - f1_score: 0.6667\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.5095 - accuracy: 0.7429 - precision: 0.8780 - recall: 0.5373 - f1_score: 0.6667 - val_loss: 0.5521 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 5.0000e-05\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.7714 - precision: 0.8302 - recall: 0.6567 - f1_score: 0.7333\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.5468 - accuracy: 0.7714 - precision: 0.8302 - recall: 0.6567 - f1_score: 0.7333 - val_loss: 0.4819 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 5.0000e-05\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.7786 - precision: 0.8214 - recall: 0.6866 - f1_score: 0.7480\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.5202 - accuracy: 0.7786 - precision: 0.8214 - recall: 0.6866 - f1_score: 0.7480 - val_loss: 0.5662 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 5.0000e-05\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.7286 - precision: 0.7843 - recall: 0.5970 - f1_score: 0.6780\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.5004 - accuracy: 0.7286 - precision: 0.7843 - recall: 0.5970 - f1_score: 0.6780 - val_loss: 0.5118 - val_accuracy: 0.7000 - val_precision: 0.7857 - val_recall: 0.6471 - val_f1_score: 0.7097 - lr: 5.0000e-05\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.7286 - precision: 0.8537 - recall: 0.5224 - f1_score: 0.6481\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.5172 - accuracy: 0.7286 - precision: 0.8537 - recall: 0.5224 - f1_score: 0.6481 - val_loss: 0.4983 - val_accuracy: 0.7000 - val_precision: 0.8333 - val_recall: 0.5882 - val_f1_score: 0.6897 - lr: 5.0000e-05\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4908 - accuracy: 0.7857 - precision: 0.8776 - recall: 0.6418 - f1_score: 0.7414\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4908 - accuracy: 0.7857 - precision: 0.8776 - recall: 0.6418 - f1_score: 0.7414 - val_loss: 0.5273 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 5.0000e-05\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.7714 - precision: 0.8182 - recall: 0.6716 - f1_score: 0.7377\n",
            "Epoch 68: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.4811 - accuracy: 0.7714 - precision: 0.8182 - recall: 0.6716 - f1_score: 0.7377 - val_loss: 0.4499 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 5.0000e-05\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5235 - accuracy: 0.7286 - precision: 0.8537 - recall: 0.5224 - f1_score: 0.6481\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.5235 - accuracy: 0.7286 - precision: 0.8537 - recall: 0.5224 - f1_score: 0.6481 - val_loss: 0.4271 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 2.5000e-05\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.7571 - precision: 0.8511 - recall: 0.5970 - f1_score: 0.7018\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.4780 - accuracy: 0.7571 - precision: 0.8511 - recall: 0.5970 - f1_score: 0.7018 - val_loss: 0.4637 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.7714 - precision: 0.8889 - recall: 0.5970 - f1_score: 0.7143\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4416 - accuracy: 0.7714 - precision: 0.8889 - recall: 0.5970 - f1_score: 0.7143 - val_loss: 0.4635 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.7786 - precision: 0.8462 - recall: 0.6567 - f1_score: 0.7395\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.4401 - accuracy: 0.7786 - precision: 0.8462 - recall: 0.6567 - f1_score: 0.7395 - val_loss: 0.4944 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.7857 - precision: 0.8936 - recall: 0.6269 - f1_score: 0.7368\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.4266 - accuracy: 0.7857 - precision: 0.8936 - recall: 0.6269 - f1_score: 0.7368 - val_loss: 0.4880 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4816 - accuracy: 0.7643 - precision: 0.8864 - recall: 0.5821 - f1_score: 0.7027\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.4816 - accuracy: 0.7643 - precision: 0.8864 - recall: 0.5821 - f1_score: 0.7027 - val_loss: 0.4263 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3916 - accuracy: 0.8429 - precision: 0.9592 - recall: 0.7015 - f1_score: 0.8103\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3916 - accuracy: 0.8429 - precision: 0.9592 - recall: 0.7015 - f1_score: 0.8103 - val_loss: 0.5389 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.7857 - precision: 0.8364 - recall: 0.6866 - f1_score: 0.7541\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.4300 - accuracy: 0.7857 - precision: 0.8364 - recall: 0.6866 - f1_score: 0.7541 - val_loss: 0.5546 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.8071 - precision: 0.8704 - recall: 0.7015 - f1_score: 0.7769\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.4255 - accuracy: 0.8071 - precision: 0.8704 - recall: 0.7015 - f1_score: 0.7769 - val_loss: 0.4703 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8071 - precision: 0.8846 - recall: 0.6866 - f1_score: 0.7731\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.4492 - accuracy: 0.8071 - precision: 0.8846 - recall: 0.6866 - f1_score: 0.7731 - val_loss: 0.5333 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.8286 - precision: 0.8909 - recall: 0.7313 - f1_score: 0.8033\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.4322 - accuracy: 0.8286 - precision: 0.8909 - recall: 0.7313 - f1_score: 0.8033 - val_loss: 0.5050 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.8214 - precision: 0.8750 - recall: 0.7313 - f1_score: 0.7967\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.4351 - accuracy: 0.8214 - precision: 0.8750 - recall: 0.7313 - f1_score: 0.7967 - val_loss: 0.5133 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4541 - accuracy: 0.8071 - precision: 0.9167 - recall: 0.6567 - f1_score: 0.7652\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4541 - accuracy: 0.8071 - precision: 0.9167 - recall: 0.6567 - f1_score: 0.7652 - val_loss: 0.4980 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4217 - accuracy: 0.8071 - precision: 0.8704 - recall: 0.7015 - f1_score: 0.7769\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.4217 - accuracy: 0.8071 - precision: 0.8704 - recall: 0.7015 - f1_score: 0.7769 - val_loss: 0.5311 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.8000 - precision: 0.8980 - recall: 0.6567 - f1_score: 0.7586\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.4282 - accuracy: 0.8000 - precision: 0.8980 - recall: 0.6567 - f1_score: 0.7586 - val_loss: 0.5720 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 2.5000e-05\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8429 - precision: 0.8571 - recall: 0.8060 - f1_score: 0.8308\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.4041 - accuracy: 0.8429 - precision: 0.8571 - recall: 0.8060 - f1_score: 0.8308 - val_loss: 0.4721 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 2.5000e-05\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4763 - accuracy: 0.7857 - precision: 0.8364 - recall: 0.6866 - f1_score: 0.7541\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4763 - accuracy: 0.7857 - precision: 0.8364 - recall: 0.6866 - f1_score: 0.7541 - val_loss: 0.4443 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 2.5000e-05\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.7929 - precision: 0.7969 - recall: 0.7612 - f1_score: 0.7786\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.4376 - accuracy: 0.7929 - precision: 0.7969 - recall: 0.7612 - f1_score: 0.7786 - val_loss: 0.4871 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8429 - precision: 0.8947 - recall: 0.7612 - f1_score: 0.8226\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.4292 - accuracy: 0.8429 - precision: 0.8947 - recall: 0.7612 - f1_score: 0.8226 - val_loss: 0.5406 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 2.5000e-05\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.8214 - precision: 0.8889 - recall: 0.7164 - f1_score: 0.7934\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4414 - accuracy: 0.8214 - precision: 0.8889 - recall: 0.7164 - f1_score: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8071 - precision: 0.9000 - recall: 0.6716 - f1_score: 0.7692\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.4086 - accuracy: 0.8071 - precision: 0.9000 - recall: 0.6716 - f1_score: 0.7692 - val_loss: 0.5431 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.8214 - precision: 0.9375 - recall: 0.6716 - f1_score: 0.7826\n",
            "Epoch 90: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.4046 - accuracy: 0.8214 - precision: 0.9375 - recall: 0.6716 - f1_score: 0.7826 - val_loss: 0.5373 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.8214 - precision: 0.8750 - recall: 0.7313 - f1_score: 0.7967\n",
            "Epoch 91: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.3653 - accuracy: 0.8214 - precision: 0.8750 - recall: 0.7313 - f1_score: 0.7967 - val_loss: 0.6629 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 2.5000e-05\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.7857 - precision: 0.8364 - recall: 0.6866 - f1_score: 0.7541\n",
            "Epoch 92: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4223 - accuracy: 0.7857 - precision: 0.8364 - recall: 0.6866 - f1_score: 0.7541 - val_loss: 0.6409 - val_accuracy: 0.8333 - val_precision: 0.8750 - val_recall: 0.8235 - val_f1_score: 0.8485 - lr: 2.5000e-05\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.8143 - precision: 0.8868 - recall: 0.7015 - f1_score: 0.7833\n",
            "Epoch 93: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.4265 - accuracy: 0.8143 - precision: 0.8868 - recall: 0.7015 - f1_score: 0.7833 - val_loss: 0.5049 - val_accuracy: 0.8333 - val_precision: 0.8750 - val_recall: 0.8235 - val_f1_score: 0.8485 - lr: 2.5000e-05\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.8071 - precision: 0.8846 - recall: 0.6866 - f1_score: 0.7731\n",
            "Epoch 94: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.4166 - accuracy: 0.8071 - precision: 0.8846 - recall: 0.6866 - f1_score: 0.7731 - val_loss: 0.5104 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 2.5000e-05\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3783 - accuracy: 0.8286 - precision: 0.8308 - recall: 0.8060 - f1_score: 0.8182\n",
            "Epoch 95: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.3783 - accuracy: 0.8286 - precision: 0.8308 - recall: 0.8060 - f1_score: 0.8182 - val_loss: 0.6028 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.8143 - precision: 0.8596 - recall: 0.7313 - f1_score: 0.7903\n",
            "Epoch 96: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.3984 - accuracy: 0.8143 - precision: 0.8596 - recall: 0.7313 - f1_score: 0.7903 - val_loss: 0.6299 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.8500 - precision: 0.9107 - recall: 0.7612 - f1_score: 0.8293\n",
            "Epoch 97: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3533 - accuracy: 0.8500 - precision: 0.9107 - recall: 0.7612 - f1_score: 0.8293 - val_loss: 0.6089 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.8071 - precision: 0.8571 - recall: 0.7164 - f1_score: 0.7805\n",
            "Epoch 98: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.4330 - accuracy: 0.8071 - precision: 0.8571 - recall: 0.7164 - f1_score: 0.7805 - val_loss: 0.6086 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 2.5000e-05\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.8214 - precision: 0.9200 - recall: 0.6866 - f1_score: 0.7863\n",
            "Epoch 99: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.3964 - accuracy: 0.8214 - precision: 0.9200 - recall: 0.6866 - f1_score: 0.7863 - val_loss: 0.6374 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 2.5000e-05\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.8643 - precision: 0.8871 - recall: 0.8209 - f1_score: 0.8527\n",
            "Epoch 100: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3740 - accuracy: 0.8643 - precision: 0.8871 - recall: 0.8209 - f1_score: 0.8527 - val_loss: 0.5479 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 2.5000e-05\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.8643 - precision: 0.9138 - recall: 0.7910 - f1_score: 0.8480\n",
            "Epoch 101: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.3664 - accuracy: 0.8643 - precision: 0.9138 - recall: 0.7910 - f1_score: 0.8480 - val_loss: 0.4881 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 2.5000e-05\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.8571 - precision: 0.9608 - recall: 0.7313 - f1_score: 0.8305\n",
            "Epoch 102: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.3642 - accuracy: 0.8571 - precision: 0.9608 - recall: 0.7313 - f1_score: 0.8305 - val_loss: 0.6330 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 2.5000e-05\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.7786 - precision: 0.8000 - recall: 0.7164 - f1_score: 0.7559\n",
            "Epoch 103: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.4323 - accuracy: 0.7786 - precision: 0.8000 - recall: 0.7164 - f1_score: 0.7559 - val_loss: 0.6824 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 2.5000e-05\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3991 - accuracy: 0.8429 - precision: 0.9245 - recall: 0.7313 - f1_score: 0.8167\n",
            "Epoch 104: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3991 - accuracy: 0.8429 - precision: 0.9245 - recall: 0.7313 - f1_score: 0.8167 - val_loss: 0.6680 - val_accuracy: 0.7000 - val_precision: 0.8333 - val_recall: 0.5882 - val_f1_score: 0.6897 - lr: 2.5000e-05\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8357 - precision: 0.9583 - recall: 0.6866 - f1_score: 0.8000\n",
            "Epoch 105: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.4510 - accuracy: 0.8357 - precision: 0.9583 - recall: 0.6866 - f1_score: 0.8000 - val_loss: 0.6692 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.8214 - precision: 0.8889 - recall: 0.7164 - f1_score: 0.7934\n",
            "Epoch 106: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.4277 - accuracy: 0.8214 - precision: 0.8889 - recall: 0.7164 - f1_score: 0.7934 - val_loss: 0.7217 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 2.5000e-05\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.8214 - precision: 0.8281 - recall: 0.7910 - f1_score: 0.8092\n",
            "Epoch 107: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.4247 - accuracy: 0.8214 - precision: 0.8281 - recall: 0.7910 - f1_score: 0.8092 - val_loss: 0.6096 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.7059 - val_f1_score: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.7929 - precision: 0.8800 - recall: 0.6567 - f1_score: 0.7521\n",
            "Epoch 108: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 0.4058 - accuracy: 0.7929 - precision: 0.8800 - recall: 0.6567 - f1_score: 0.7521 - val_loss: 0.5735 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 1.2500e-05\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3704 - accuracy: 0.8643 - precision: 0.9615 - recall: 0.7463 - f1_score: 0.8403\n",
            "Epoch 109: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.3704 - accuracy: 0.8643 - precision: 0.9615 - recall: 0.7463 - f1_score: 0.8403 - val_loss: 0.5528 - val_accuracy: 0.7667 - val_precision: 0.8125 - val_recall: 0.7647 - val_f1_score: 0.7879 - lr: 1.2500e-05\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3356 - accuracy: 0.8571 - precision: 0.9273 - recall: 0.7612 - f1_score: 0.8361\n",
            "Epoch 110: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3356 - accuracy: 0.8571 - precision: 0.9273 - recall: 0.7612 - f1_score: 0.8361 - val_loss: 0.6472 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 1.2500e-05\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.8786 - precision: 0.9310 - recall: 0.8060 - f1_score: 0.8640\n",
            "Epoch 111: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.3391 - accuracy: 0.8786 - precision: 0.9310 - recall: 0.8060 - f1_score: 0.8640 - val_loss: 0.8008 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 1.2500e-05\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.7857 - precision: 0.7937 - recall: 0.7463 - f1_score: 0.7692\n",
            "Epoch 112: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.4252 - accuracy: 0.7857 - precision: 0.7937 - recall: 0.7463 - f1_score: 0.7692 - val_loss: 0.5787 - val_accuracy: 0.8000 - val_precision: 0.8235 - val_recall: 0.8235 - val_f1_score: 0.8235 - lr: 1.2500e-05\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.8429 - precision: 0.9091 - recall: 0.7463 - f1_score: 0.8197\n",
            "Epoch 113: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3724 - accuracy: 0.8429 - precision: 0.9091 - recall: 0.7463 - f1_score: 0.8197 - val_loss: 0.5149 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.2500e-05\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.8000 - precision: 0.9333 - recall: 0.6269 - f1_score: 0.7500\n",
            "Epoch 114: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.3765 - accuracy: 0.8000 - precision: 0.9333 - recall: 0.6269 - f1_score: 0.7500 - val_loss: 0.5180 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 1.2500e-05\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8571 - precision: 0.9434 - recall: 0.7463 - f1_score: 0.8333\n",
            "Epoch 115: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.3901 - accuracy: 0.8571 - precision: 0.9434 - recall: 0.7463 - f1_score: 0.8333 - val_loss: 0.5897 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.2500e-05\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4014 - accuracy: 0.8571 - precision: 0.9273 - recall: 0.7612 - f1_score: 0.8361\n",
            "Epoch 116: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.4014 - accuracy: 0.8571 - precision: 0.9273 - recall: 0.7612 - f1_score: 0.8361 - val_loss: 0.6580 - val_accuracy: 0.8333 - val_precision: 0.8750 - val_recall: 0.8235 - val_f1_score: 0.8485 - lr: 1.2500e-05\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4000 - accuracy: 0.8143 - precision: 0.8596 - recall: 0.7313 - f1_score: 0.7903\n",
            "Epoch 117: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.4000 - accuracy: 0.8143 - precision: 0.8596 - recall: 0.7313 - f1_score: 0.7903 - val_loss: 0.6765 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.2500e-05\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.8857 - precision: 0.9474 - recall: 0.8060 - f1_score: 0.8710\n",
            "Epoch 118: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.3089 - accuracy: 0.8857 - precision: 0.9474 - recall: 0.8060 - f1_score: 0.8710 - val_loss: 0.6907 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.2500e-05\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.8357 - precision: 0.9074 - recall: 0.7313 - f1_score: 0.8099\n",
            "Epoch 119: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 96ms/step - loss: 0.3416 - accuracy: 0.8357 - precision: 0.9074 - recall: 0.7313 - f1_score: 0.8099 - val_loss: 0.7821 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.2500e-05\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.8714 - precision: 0.9016 - recall: 0.8209 - f1_score: 0.8594\n",
            "Epoch 120: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.3175 - accuracy: 0.8714 - precision: 0.9016 - recall: 0.8209 - f1_score: 0.8594 - val_loss: 0.8667 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.2500e-05\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.8571 - precision: 0.9123 - recall: 0.7761 - f1_score: 0.8387\n",
            "Epoch 121: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3898 - accuracy: 0.8571 - precision: 0.9123 - recall: 0.7761 - f1_score: 0.8387 - val_loss: 0.9787 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.2500e-05\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.8929 - precision: 0.9194 - recall: 0.8507 - f1_score: 0.8837\n",
            "Epoch 122: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.2769 - accuracy: 0.8929 - precision: 0.9194 - recall: 0.8507 - f1_score: 0.8837 - val_loss: 1.0691 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.2500e-05\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.8286 - precision: 0.8644 - recall: 0.7612 - f1_score: 0.8095\n",
            "Epoch 123: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.4021 - accuracy: 0.8286 - precision: 0.8644 - recall: 0.7612 - f1_score: 0.8095 - val_loss: 1.0374 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8429 - precision: 0.8814 - recall: 0.7761 - f1_score: 0.8254\n",
            "Epoch 124: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.3282 - accuracy: 0.8429 - precision: 0.8814 - recall: 0.7761 - f1_score: 0.8254 - val_loss: 0.9107 - val_accuracy: 0.7000 - val_precision: 0.8333 - val_recall: 0.5882 - val_f1_score: 0.6897 - lr: 1.0000e-05\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.8643 - precision: 0.9138 - recall: 0.7910 - f1_score: 0.8480\n",
            "Epoch 125: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.3671 - accuracy: 0.8643 - precision: 0.9138 - recall: 0.7910 - f1_score: 0.8480 - val_loss: 0.8550 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8357 - precision: 0.9231 - recall: 0.7164 - f1_score: 0.8067\n",
            "Epoch 126: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.3661 - accuracy: 0.8357 - precision: 0.9231 - recall: 0.7164 - f1_score: 0.8067 - val_loss: 0.8606 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.8857 - precision: 0.9180 - recall: 0.8358 - f1_score: 0.8750\n",
            "Epoch 127: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.3134 - accuracy: 0.8857 - precision: 0.9180 - recall: 0.8358 - f1_score: 0.8750 - val_loss: 0.9360 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 128/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3445 - accuracy: 0.8714 - precision: 0.9298 - recall: 0.7910 - f1_score: 0.8548\n",
            "Epoch 128: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3445 - accuracy: 0.8714 - precision: 0.9298 - recall: 0.7910 - f1_score: 0.8548 - val_loss: 0.9456 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 129/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.8857 - precision: 0.8923 - recall: 0.8657 - f1_score: 0.8788\n",
            "Epoch 129: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.3375 - accuracy: 0.8857 - precision: 0.8923 - recall: 0.8657 - f1_score: 0.8788 - val_loss: 0.8066 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 130/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8714 - precision: 0.9623 - recall: 0.7612 - f1_score: 0.8500\n",
            "Epoch 130: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.3308 - accuracy: 0.8714 - precision: 0.9623 - recall: 0.7612 - f1_score: 0.8500 - val_loss: 0.7376 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 131/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8571 - precision: 0.9273 - recall: 0.7612 - f1_score: 0.8361\n",
            "Epoch 131: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.3471 - accuracy: 0.8571 - precision: 0.9273 - recall: 0.7612 - f1_score: 0.8361 - val_loss: 0.8131 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 132/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.8929 - precision: 0.9643 - recall: 0.8060 - f1_score: 0.8780\n",
            "Epoch 132: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.3017 - accuracy: 0.8929 - precision: 0.9643 - recall: 0.8060 - f1_score: 0.8780 - val_loss: 0.7287 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 133/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.9000 - precision: 0.9206 - recall: 0.8657 - f1_score: 0.8923\n",
            "Epoch 133: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.3042 - accuracy: 0.9000 - precision: 0.9206 - recall: 0.8657 - f1_score: 0.8923 - val_loss: 0.7085 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 134/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.8786 - precision: 0.9167 - recall: 0.8209 - f1_score: 0.8661\n",
            "Epoch 134: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.3143 - accuracy: 0.8786 - precision: 0.9167 - recall: 0.8209 - f1_score: 0.8661 - val_loss: 0.7469 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 135/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.9000 - precision: 0.9344 - recall: 0.8507 - f1_score: 0.8906\n",
            "Epoch 135: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2617 - accuracy: 0.9000 - precision: 0.9344 - recall: 0.8507 - f1_score: 0.8906 - val_loss: 0.8685 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 136/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.8643 - precision: 0.9286 - recall: 0.7761 - f1_score: 0.8455\n",
            "Epoch 136: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.3391 - accuracy: 0.8643 - precision: 0.9286 - recall: 0.7761 - f1_score: 0.8455 - val_loss: 0.9082 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 137/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3553 - accuracy: 0.8500 - precision: 0.9107 - recall: 0.7612 - f1_score: 0.8293\n",
            "Epoch 137: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3553 - accuracy: 0.8500 - precision: 0.9107 - recall: 0.7612 - f1_score: 0.8293 - val_loss: 0.8329 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 138/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.8714 - precision: 0.9153 - recall: 0.8060 - f1_score: 0.8571\n",
            "Epoch 138: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.3572 - accuracy: 0.8714 - precision: 0.9153 - recall: 0.8060 - f1_score: 0.8571 - val_loss: 0.7965 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 1.0000e-05\n",
            "Epoch 139/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2724 - accuracy: 0.8929 - precision: 0.9483 - recall: 0.8209 - f1_score: 0.8800\n",
            "Epoch 139: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2724 - accuracy: 0.8929 - precision: 0.9483 - recall: 0.8209 - f1_score: 0.8800 - val_loss: 0.8073 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 1.0000e-05\n",
            "Epoch 140/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.9071 - precision: 0.9821 - recall: 0.8209 - f1_score: 0.8943\n",
            "Epoch 140: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.2705 - accuracy: 0.9071 - precision: 0.9821 - recall: 0.8209 - f1_score: 0.8943 - val_loss: 0.8272 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 141/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.8786 - precision: 0.9167 - recall: 0.8209 - f1_score: 0.8661\n",
            "Epoch 141: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.3079 - accuracy: 0.8786 - precision: 0.9167 - recall: 0.8209 - f1_score: 0.8661 - val_loss: 0.8634 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 142/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.8286 - precision: 0.9057 - recall: 0.7164 - f1_score: 0.8000\n",
            "Epoch 142: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2945 - accuracy: 0.8286 - precision: 0.9057 - recall: 0.7164 - f1_score: 0.8000 - val_loss: 0.8007 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 143/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.8857 - precision: 0.9474 - recall: 0.8060 - f1_score: 0.8710\n",
            "Epoch 143: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 135ms/step - loss: 0.2866 - accuracy: 0.8857 - precision: 0.9474 - recall: 0.8060 - f1_score: 0.8710 - val_loss: 0.7839 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 144/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.8643 - precision: 0.9615 - recall: 0.7463 - f1_score: 0.8403\n",
            "Epoch 144: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.3244 - accuracy: 0.8643 - precision: 0.9615 - recall: 0.7463 - f1_score: 0.8403 - val_loss: 0.8775 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 145/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.9000 - precision: 0.9649 - recall: 0.8209 - f1_score: 0.8871\n",
            "Epoch 145: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3123 - accuracy: 0.9000 - precision: 0.9649 - recall: 0.8209 - f1_score: 0.8871 - val_loss: 0.9059 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 146/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.8929 - precision: 0.9333 - recall: 0.8358 - f1_score: 0.8819\n",
            "Epoch 146: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.3357 - accuracy: 0.8929 - precision: 0.9333 - recall: 0.8358 - f1_score: 0.8819 - val_loss: 0.8792 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 147/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.8571 - precision: 0.9434 - recall: 0.7463 - f1_score: 0.8333\n",
            "Epoch 147: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.2941 - accuracy: 0.8571 - precision: 0.9434 - recall: 0.7463 - f1_score: 0.8333 - val_loss: 0.8834 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 148/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.8786 - precision: 0.9310 - recall: 0.8060 - f1_score: 0.8640\n",
            "Epoch 148: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3096 - accuracy: 0.8786 - precision: 0.9310 - recall: 0.8060 - f1_score: 0.8640 - val_loss: 0.9284 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 149/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.8857 - precision: 0.9474 - recall: 0.8060 - f1_score: 0.8710\n",
            "Epoch 149: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.2763 - accuracy: 0.8857 - precision: 0.9474 - recall: 0.8060 - f1_score: 0.8710 - val_loss: 1.0947 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 150/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.8643 - precision: 0.9286 - recall: 0.7761 - f1_score: 0.8455\n",
            "Epoch 150: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.3108 - accuracy: 0.8643 - precision: 0.9286 - recall: 0.7761 - f1_score: 0.8455 - val_loss: 1.2773 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 151/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.8857 - precision: 0.9474 - recall: 0.8060 - f1_score: 0.8710\n",
            "Epoch 151: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.3226 - accuracy: 0.8857 - precision: 0.9474 - recall: 0.8060 - f1_score: 0.8710 - val_loss: 1.1692 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 152/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.8857 - precision: 0.9180 - recall: 0.8358 - f1_score: 0.8750\n",
            "Epoch 152: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.2938 - accuracy: 0.8857 - precision: 0.9180 - recall: 0.8358 - f1_score: 0.8750 - val_loss: 1.0675 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 153/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.8786 - precision: 0.9032 - recall: 0.8358 - f1_score: 0.8682\n",
            "Epoch 153: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.2710 - accuracy: 0.8786 - precision: 0.9032 - recall: 0.8358 - f1_score: 0.8682 - val_loss: 1.0016 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 154/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.8714 - precision: 0.9153 - recall: 0.8060 - f1_score: 0.8571\n",
            "Epoch 154: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.3035 - accuracy: 0.8714 - precision: 0.9153 - recall: 0.8060 - f1_score: 0.8571 - val_loss: 1.0834 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 155/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8714 - precision: 0.9623 - recall: 0.7612 - f1_score: 0.8500\n",
            "Epoch 155: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.3068 - accuracy: 0.8714 - precision: 0.9623 - recall: 0.7612 - f1_score: 0.8500 - val_loss: 1.0735 - val_accuracy: 0.7000 - val_precision: 0.8333 - val_recall: 0.5882 - val_f1_score: 0.6897 - lr: 1.0000e-05\n",
            "Epoch 156/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.8857 - precision: 0.9636 - recall: 0.7910 - f1_score: 0.8689\n",
            "Epoch 156: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.3038 - accuracy: 0.8857 - precision: 0.9636 - recall: 0.7910 - f1_score: 0.8689 - val_loss: 1.1192 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 157/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.8786 - precision: 0.9464 - recall: 0.7910 - f1_score: 0.8618\n",
            "Epoch 157: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.2959 - accuracy: 0.8786 - precision: 0.9464 - recall: 0.7910 - f1_score: 0.8618 - val_loss: 1.0771 - val_accuracy: 0.7000 - val_precision: 0.8333 - val_recall: 0.5882 - val_f1_score: 0.6897 - lr: 1.0000e-05\n",
            "Epoch 158/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.8714 - precision: 0.9455 - recall: 0.7761 - f1_score: 0.8525\n",
            "Epoch 158: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.2781 - accuracy: 0.8714 - precision: 0.9455 - recall: 0.7761 - f1_score: 0.8525 - val_loss: 1.0071 - val_accuracy: 0.7333 - val_precision: 0.9091 - val_recall: 0.5882 - val_f1_score: 0.7143 - lr: 1.0000e-05\n",
            "Epoch 159/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.9071 - precision: 0.9655 - recall: 0.8358 - f1_score: 0.8960\n",
            "Epoch 159: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.2637 - accuracy: 0.9071 - precision: 0.9655 - recall: 0.8358 - f1_score: 0.8960 - val_loss: 0.9669 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 160/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.8786 - precision: 0.9310 - recall: 0.8060 - f1_score: 0.8640\n",
            "Epoch 160: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2562 - accuracy: 0.8786 - precision: 0.9310 - recall: 0.8060 - f1_score: 0.8640 - val_loss: 0.9721 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 161/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.8929 - precision: 0.9333 - recall: 0.8358 - f1_score: 0.8819\n",
            "Epoch 161: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.3000 - accuracy: 0.8929 - precision: 0.9333 - recall: 0.8358 - f1_score: 0.8819 - val_loss: 0.9021 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 162/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.8714 - precision: 0.9623 - recall: 0.7612 - f1_score: 0.8500\n",
            "Epoch 162: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.2907 - accuracy: 0.8714 - precision: 0.9623 - recall: 0.7612 - f1_score: 0.8500 - val_loss: 0.7956 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 163/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8429 - precision: 0.8571 - recall: 0.8060 - f1_score: 0.8308\n",
            "Epoch 163: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.2982 - accuracy: 0.8429 - precision: 0.8571 - recall: 0.8060 - f1_score: 0.8308 - val_loss: 0.8119 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 164/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2841 - accuracy: 0.8786 - precision: 0.9310 - recall: 0.8060 - f1_score: 0.8640\n",
            "Epoch 164: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 134ms/step - loss: 0.2841 - accuracy: 0.8786 - precision: 0.9310 - recall: 0.8060 - f1_score: 0.8640 - val_loss: 0.9749 - val_accuracy: 0.7333 - val_precision: 0.9091 - val_recall: 0.5882 - val_f1_score: 0.7143 - lr: 1.0000e-05\n",
            "Epoch 165/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2939 - accuracy: 0.8786 - precision: 0.9464 - recall: 0.7910 - f1_score: 0.8618\n",
            "Epoch 165: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.2939 - accuracy: 0.8786 - precision: 0.9464 - recall: 0.7910 - f1_score: 0.8618 - val_loss: 1.0921 - val_accuracy: 0.7333 - val_precision: 0.9091 - val_recall: 0.5882 - val_f1_score: 0.7143 - lr: 1.0000e-05\n",
            "Epoch 166/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.8857 - precision: 0.9811 - recall: 0.7761 - f1_score: 0.8667\n",
            "Epoch 166: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.2698 - accuracy: 0.8857 - precision: 0.9811 - recall: 0.7761 - f1_score: 0.8667 - val_loss: 1.1046 - val_accuracy: 0.7333 - val_precision: 0.9091 - val_recall: 0.5882 - val_f1_score: 0.7143 - lr: 1.0000e-05\n",
            "Epoch 167/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2402 - accuracy: 0.9000 - precision: 0.9649 - recall: 0.8209 - f1_score: 0.8871\n",
            "Epoch 167: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.2402 - accuracy: 0.9000 - precision: 0.9649 - recall: 0.8209 - f1_score: 0.8871 - val_loss: 1.0582 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 168/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.8857 - precision: 0.9322 - recall: 0.8209 - f1_score: 0.8730\n",
            "Epoch 168: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2346 - accuracy: 0.8857 - precision: 0.9322 - recall: 0.8209 - f1_score: 0.8730 - val_loss: 1.0830 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 169/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.8357 - precision: 0.8929 - recall: 0.7463 - f1_score: 0.8130\n",
            "Epoch 169: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.2813 - accuracy: 0.8357 - precision: 0.8929 - recall: 0.7463 - f1_score: 0.8130 - val_loss: 0.9465 - val_accuracy: 0.8000 - val_precision: 0.8667 - val_recall: 0.7647 - val_f1_score: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 170/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2746 - accuracy: 0.9000 - precision: 1.0000 - recall: 0.7910 - f1_score: 0.8833\n",
            "Epoch 170: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.2746 - accuracy: 0.9000 - precision: 1.0000 - recall: 0.7910 - f1_score: 0.8833 - val_loss: 0.8354 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 171/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.8643 - precision: 0.9138 - recall: 0.7910 - f1_score: 0.8480\n",
            "Epoch 171: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.3183 - accuracy: 0.8643 - precision: 0.9138 - recall: 0.7910 - f1_score: 0.8480 - val_loss: 0.8589 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 172/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.8643 - precision: 0.9000 - recall: 0.8060 - f1_score: 0.8504\n",
            "Epoch 172: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.3188 - accuracy: 0.8643 - precision: 0.9000 - recall: 0.8060 - f1_score: 0.8504 - val_loss: 0.9115 - val_accuracy: 0.7333 - val_precision: 0.8462 - val_recall: 0.6471 - val_f1_score: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 173/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2545 - accuracy: 0.9071 - precision: 1.0000 - recall: 0.8060 - f1_score: 0.8926\n",
            "Epoch 173: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.2545 - accuracy: 0.9071 - precision: 1.0000 - recall: 0.8060 - f1_score: 0.8926 - val_loss: 0.9359 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 174/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.8643 - precision: 0.9286 - recall: 0.7761 - f1_score: 0.8455\n",
            "Epoch 174: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.3056 - accuracy: 0.8643 - precision: 0.9286 - recall: 0.7761 - f1_score: 0.8455 - val_loss: 0.9754 - val_accuracy: 0.7667 - val_precision: 0.8571 - val_recall: 0.7059 - val_f1_score: 0.7742 - lr: 1.0000e-05\n",
            "Epoch 174: early stopping\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.5158 - accuracy: 0.7333 - precision: 0.8333 - recall: 0.6250 - f1_score: 0.7143\n",
            "\n",
            "############# Fold n°7 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.5076 - accuracy: 0.5706 - precision: 0.5625 - recall: 0.8090 - f1_score: 0.6636\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 6s 109ms/step - loss: 2.5076 - accuracy: 0.5706 - precision: 0.5625 - recall: 0.8090 - f1_score: 0.6636 - val_loss: 2.2383 - val_accuracy: 0.4000 - val_precision: 0.2941 - val_recall: 0.4545 - val_f1_score: 0.3571 - lr: 1.0000e-04\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.9856 - accuracy: 0.6214 - precision: 0.6562 - recall: 0.5753 - f1_score: 0.6131\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 1.9856 - accuracy: 0.6214 - precision: 0.6562 - recall: 0.5753 - f1_score: 0.6131 - val_loss: 1.7609 - val_accuracy: 0.6333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.6096 - accuracy: 0.5643 - precision: 0.6111 - recall: 0.4521 - f1_score: 0.5197\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 1.6096 - accuracy: 0.5643 - precision: 0.6111 - recall: 0.4521 - f1_score: 0.5197 - val_loss: 1.4398 - val_accuracy: 0.3667 - val_precision: 0.3333 - val_recall: 0.7273 - val_f1_score: 0.4571 - lr: 1.0000e-04\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.3139 - accuracy: 0.5357 - precision: 0.5606 - recall: 0.5068 - f1_score: 0.5324\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 1.3139 - accuracy: 0.5357 - precision: 0.5606 - recall: 0.5068 - f1_score: 0.5324 - val_loss: 1.2209 - val_accuracy: 0.4000 - val_precision: 0.3793 - val_recall: 1.0000 - val_f1_score: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.1364 - accuracy: 0.6000 - precision: 0.5876 - recall: 0.7808 - f1_score: 0.6706\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 1.1364 - accuracy: 0.6000 - precision: 0.5876 - recall: 0.7808 - f1_score: 0.6706 - val_loss: 1.1046 - val_accuracy: 0.3667 - val_precision: 0.3462 - val_recall: 0.8182 - val_f1_score: 0.4865 - lr: 1.0000e-04\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0801 - accuracy: 0.6643 - precision: 0.6354 - recall: 0.8356 - f1_score: 0.7219\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 1.0801 - accuracy: 0.6643 - precision: 0.6354 - recall: 0.8356 - f1_score: 0.7219 - val_loss: 1.0679 - val_accuracy: 0.5667 - val_precision: 0.4167 - val_recall: 0.4545 - val_f1_score: 0.4348 - lr: 1.0000e-04\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0191 - accuracy: 0.6286 - precision: 0.6154 - recall: 0.7671 - f1_score: 0.6829\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 1.0191 - accuracy: 0.6286 - precision: 0.6154 - recall: 0.7671 - f1_score: 0.6829 - val_loss: 1.0149 - val_accuracy: 0.5667 - val_precision: 0.4286 - val_recall: 0.5455 - val_f1_score: 0.4800 - lr: 1.0000e-04\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9652 - accuracy: 0.5000 - precision: 0.5333 - recall: 0.3288 - f1_score: 0.4068\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.9652 - accuracy: 0.5000 - precision: 0.5333 - recall: 0.3288 - f1_score: 0.4068 - val_loss: 0.9185 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.0909 - val_f1_score: 0.1667 - lr: 1.0000e-04\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9175 - accuracy: 0.5429 - precision: 0.5918 - recall: 0.3973 - f1_score: 0.4754\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.9175 - accuracy: 0.5429 - precision: 0.5918 - recall: 0.3973 - f1_score: 0.4754 - val_loss: 0.9166 - val_accuracy: 0.4000 - val_precision: 0.3478 - val_recall: 0.7273 - val_f1_score: 0.4706 - lr: 1.0000e-04\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8882 - accuracy: 0.5000 - precision: 0.5149 - recall: 0.7123 - f1_score: 0.5977\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.8882 - accuracy: 0.5000 - precision: 0.5149 - recall: 0.7123 - f1_score: 0.5977 - val_loss: 0.8944 - val_accuracy: 0.3667 - val_precision: 0.3182 - val_recall: 0.6364 - val_f1_score: 0.4242 - lr: 1.0000e-04\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8465 - accuracy: 0.5714 - precision: 0.5915 - recall: 0.5753 - f1_score: 0.5833\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.8465 - accuracy: 0.5714 - precision: 0.5915 - recall: 0.5753 - f1_score: 0.5833 - val_loss: 0.8502 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7946 - accuracy: 0.6357 - precision: 0.6774 - recall: 0.5753 - f1_score: 0.6222\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.7946 - accuracy: 0.6357 - precision: 0.6774 - recall: 0.5753 - f1_score: 0.6222 - val_loss: 0.9406 - val_accuracy: 0.3667 - val_precision: 0.3182 - val_recall: 0.6364 - val_f1_score: 0.4242 - lr: 1.0000e-04\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7616 - accuracy: 0.6929 - precision: 0.6829 - recall: 0.7671 - f1_score: 0.7226\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.7616 - accuracy: 0.6929 - precision: 0.6829 - recall: 0.7671 - f1_score: 0.7226 - val_loss: 0.7816 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.3636 - val_f1_score: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7555 - accuracy: 0.6500 - precision: 0.6622 - recall: 0.6712 - f1_score: 0.6667\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.7555 - accuracy: 0.6500 - precision: 0.6622 - recall: 0.6712 - f1_score: 0.6667 - val_loss: 0.8719 - val_accuracy: 0.5667 - val_precision: 0.4375 - val_recall: 0.6364 - val_f1_score: 0.5185 - lr: 1.0000e-04\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.6714 - precision: 0.7143 - recall: 0.6164 - f1_score: 0.6618\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.6871 - accuracy: 0.6714 - precision: 0.7143 - recall: 0.6164 - f1_score: 0.6618 - val_loss: 0.9430 - val_accuracy: 0.5333 - val_precision: 0.4118 - val_recall: 0.6364 - val_f1_score: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6513 - accuracy: 0.7500 - precision: 0.7436 - recall: 0.7945 - f1_score: 0.7682\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.6513 - accuracy: 0.7500 - precision: 0.7436 - recall: 0.7945 - f1_score: 0.7682 - val_loss: 0.7072 - val_accuracy: 0.7000 - val_precision: 0.6000 - val_recall: 0.5455 - val_f1_score: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.8000 - precision: 0.8169 - recall: 0.7945 - f1_score: 0.8056\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.6108 - accuracy: 0.8000 - precision: 0.8169 - recall: 0.7945 - f1_score: 0.8056 - val_loss: 0.7465 - val_accuracy: 0.8000 - val_precision: 1.0000 - val_recall: 0.4545 - val_f1_score: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6498 - accuracy: 0.7929 - precision: 0.8143 - recall: 0.7808 - f1_score: 0.7972\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.6498 - accuracy: 0.7929 - precision: 0.8143 - recall: 0.7808 - f1_score: 0.7972 - val_loss: 0.7617 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-04\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.8429 - precision: 0.8592 - recall: 0.8356 - f1_score: 0.8472\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.5842 - accuracy: 0.8429 - precision: 0.8592 - recall: 0.8356 - f1_score: 0.8472 - val_loss: 0.7084 - val_accuracy: 0.7667 - val_precision: 0.8333 - val_recall: 0.4545 - val_f1_score: 0.5882 - lr: 1.0000e-04\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.7857 - precision: 0.8209 - recall: 0.7534 - f1_score: 0.7857\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.6129 - accuracy: 0.7857 - precision: 0.8209 - recall: 0.7534 - f1_score: 0.7857 - val_loss: 0.7104 - val_accuracy: 0.8000 - val_precision: 0.7778 - val_recall: 0.6364 - val_f1_score: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.7857 - precision: 0.7792 - recall: 0.8219 - f1_score: 0.8000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.5739 - accuracy: 0.7857 - precision: 0.7792 - recall: 0.8219 - f1_score: 0.8000 - val_loss: 0.6959 - val_accuracy: 0.7333 - val_precision: 0.6667 - val_recall: 0.5455 - val_f1_score: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5793 - accuracy: 0.8214 - precision: 0.8429 - recall: 0.8082 - f1_score: 0.8252\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.5793 - accuracy: 0.8214 - precision: 0.8429 - recall: 0.8082 - f1_score: 0.8252 - val_loss: 0.8516 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5793 - accuracy: 0.8214 - precision: 0.8529 - recall: 0.7945 - f1_score: 0.8227\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.5793 - accuracy: 0.8214 - precision: 0.8529 - recall: 0.7945 - f1_score: 0.8227 - val_loss: 0.7540 - val_accuracy: 0.7667 - val_precision: 0.7500 - val_recall: 0.5455 - val_f1_score: 0.6316 - lr: 1.0000e-04\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5195 - accuracy: 0.8500 - precision: 0.8824 - recall: 0.8219 - f1_score: 0.8511\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.5195 - accuracy: 0.8500 - precision: 0.8824 - recall: 0.8219 - f1_score: 0.8511 - val_loss: 0.8198 - val_accuracy: 0.7667 - val_precision: 0.7500 - val_recall: 0.5455 - val_f1_score: 0.6316 - lr: 1.0000e-04\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5689 - accuracy: 0.8357 - precision: 0.8788 - recall: 0.7945 - f1_score: 0.8345\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.5689 - accuracy: 0.8357 - precision: 0.8788 - recall: 0.7945 - f1_score: 0.8345 - val_loss: 0.7992 - val_accuracy: 0.7333 - val_precision: 0.6364 - val_recall: 0.6364 - val_f1_score: 0.6364 - lr: 1.0000e-04\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4715 - accuracy: 0.8857 - precision: 0.8904 - recall: 0.8904 - f1_score: 0.8904\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.4715 - accuracy: 0.8857 - precision: 0.8904 - recall: 0.8904 - f1_score: 0.8904 - val_loss: 0.9500 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.5455 - val_f1_score: 0.7059 - lr: 1.0000e-04\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.8571 - precision: 0.8841 - recall: 0.8356 - f1_score: 0.8592\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.5551 - accuracy: 0.8571 - precision: 0.8841 - recall: 0.8356 - f1_score: 0.8592 - val_loss: 0.8140 - val_accuracy: 0.7333 - val_precision: 0.6154 - val_recall: 0.7273 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.8429 - precision: 0.8592 - recall: 0.8356 - f1_score: 0.8472\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.5089 - accuracy: 0.8429 - precision: 0.8592 - recall: 0.8356 - f1_score: 0.8472 - val_loss: 0.7941 - val_accuracy: 0.7000 - val_precision: 0.5833 - val_recall: 0.6364 - val_f1_score: 0.6087 - lr: 1.0000e-04\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.8357 - precision: 0.8571 - recall: 0.8219 - f1_score: 0.8392\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.5225 - accuracy: 0.8357 - precision: 0.8571 - recall: 0.8219 - f1_score: 0.8392 - val_loss: 0.9726 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-04\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.8571 - precision: 0.8630 - recall: 0.8630 - f1_score: 0.8630\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.4944 - accuracy: 0.8571 - precision: 0.8630 - recall: 0.8630 - f1_score: 0.8630 - val_loss: 0.8041 - val_accuracy: 0.7667 - val_precision: 0.7000 - val_recall: 0.6364 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.8571 - precision: 0.9344 - recall: 0.7808 - f1_score: 0.8507\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.5197 - accuracy: 0.8571 - precision: 0.9344 - recall: 0.7808 - f1_score: 0.8507 - val_loss: 1.0664 - val_accuracy: 0.6000 - val_precision: 0.4667 - val_recall: 0.6364 - val_f1_score: 0.5385 - lr: 1.0000e-04\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.9000 - precision: 0.8734 - recall: 0.9452 - f1_score: 0.9079\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.4748 - accuracy: 0.9000 - precision: 0.8734 - recall: 0.9452 - f1_score: 0.9079 - val_loss: 0.8403 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.8286 - precision: 0.8451 - recall: 0.8219 - f1_score: 0.8333\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.5498 - accuracy: 0.8286 - precision: 0.8451 - recall: 0.8219 - f1_score: 0.8333 - val_loss: 0.9891 - val_accuracy: 0.6000 - val_precision: 0.4667 - val_recall: 0.6364 - val_f1_score: 0.5385 - lr: 1.0000e-04\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.9071 - precision: 0.9167 - recall: 0.9041 - f1_score: 0.9103\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.4869 - accuracy: 0.9071 - precision: 0.9167 - recall: 0.9041 - f1_score: 0.9103 - val_loss: 1.1453 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-04\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.8571 - precision: 0.8442 - recall: 0.8904 - f1_score: 0.8667\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.5386 - accuracy: 0.8571 - precision: 0.8442 - recall: 0.8904 - f1_score: 0.8667 - val_loss: 0.9470 - val_accuracy: 0.6000 - val_precision: 0.4667 - val_recall: 0.6364 - val_f1_score: 0.5385 - lr: 1.0000e-04\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5128 - accuracy: 0.8643 - precision: 0.8462 - recall: 0.9041 - f1_score: 0.8742\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.5128 - accuracy: 0.8643 - precision: 0.8462 - recall: 0.9041 - f1_score: 0.8742 - val_loss: 0.7876 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.8357 - precision: 0.8289 - recall: 0.8630 - f1_score: 0.8456\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.5417 - accuracy: 0.8357 - precision: 0.8289 - recall: 0.8630 - f1_score: 0.8456 - val_loss: 0.9694 - val_accuracy: 0.6000 - val_precision: 0.4706 - val_recall: 0.7273 - val_f1_score: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.8571 - precision: 0.8442 - recall: 0.8904 - f1_score: 0.8667\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.4848 - accuracy: 0.8571 - precision: 0.8442 - recall: 0.8904 - f1_score: 0.8667 - val_loss: 1.1727 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.6364 - val_f1_score: 0.5833 - lr: 1.0000e-04\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5095 - accuracy: 0.8286 - precision: 0.8182 - recall: 0.8630 - f1_score: 0.8400\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 126ms/step - loss: 0.5095 - accuracy: 0.8286 - precision: 0.8182 - recall: 0.8630 - f1_score: 0.8400 - val_loss: 0.9652 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-04\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.8643 - precision: 0.8857 - recall: 0.8493 - f1_score: 0.8671\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.4689 - accuracy: 0.8643 - precision: 0.8857 - recall: 0.8493 - f1_score: 0.8671 - val_loss: 0.6937 - val_accuracy: 0.7667 - val_precision: 0.6667 - val_recall: 0.7273 - val_f1_score: 0.6957 - lr: 1.0000e-04\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.8929 - precision: 0.8919 - recall: 0.9041 - f1_score: 0.8980\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.4394 - accuracy: 0.8929 - precision: 0.8919 - recall: 0.9041 - f1_score: 0.8980 - val_loss: 0.9834 - val_accuracy: 0.7667 - val_precision: 0.6667 - val_recall: 0.7273 - val_f1_score: 0.6957 - lr: 1.0000e-04\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.9000 - precision: 0.9155 - recall: 0.8904 - f1_score: 0.9028\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.4190 - accuracy: 0.9000 - precision: 0.9155 - recall: 0.8904 - f1_score: 0.9028 - val_loss: 1.2736 - val_accuracy: 0.7333 - val_precision: 0.6154 - val_recall: 0.7273 - val_f1_score: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.8643 - precision: 0.8553 - recall: 0.8904 - f1_score: 0.8725\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.4412 - accuracy: 0.8643 - precision: 0.8553 - recall: 0.8904 - f1_score: 0.8725 - val_loss: 1.3506 - val_accuracy: 0.7667 - val_precision: 0.6667 - val_recall: 0.7273 - val_f1_score: 0.6957 - lr: 5.0000e-05\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.8571 - precision: 0.8442 - recall: 0.8904 - f1_score: 0.8667\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.5015 - accuracy: 0.8571 - precision: 0.8442 - recall: 0.8904 - f1_score: 0.8667 - val_loss: 1.1397 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 5.0000e-05\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3975 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.3975 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396 - val_loss: 1.0653 - val_accuracy: 0.7333 - val_precision: 0.6364 - val_recall: 0.6364 - val_f1_score: 0.6364 - lr: 5.0000e-05\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.8929 - precision: 0.8919 - recall: 0.9041 - f1_score: 0.8980\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.4186 - accuracy: 0.8929 - precision: 0.8919 - recall: 0.9041 - f1_score: 0.8980 - val_loss: 1.1585 - val_accuracy: 0.5667 - val_precision: 0.4375 - val_recall: 0.6364 - val_f1_score: 0.5185 - lr: 5.0000e-05\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.9071 - precision: 0.8750 - recall: 0.9589 - f1_score: 0.9150\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.4318 - accuracy: 0.9071 - precision: 0.8750 - recall: 0.9589 - f1_score: 0.9150 - val_loss: 1.3600 - val_accuracy: 0.5667 - val_precision: 0.4375 - val_recall: 0.6364 - val_f1_score: 0.5185 - lr: 5.0000e-05\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4706 - accuracy: 0.8714 - precision: 0.8481 - recall: 0.9178 - f1_score: 0.8816\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.4706 - accuracy: 0.8714 - precision: 0.8481 - recall: 0.9178 - f1_score: 0.8816 - val_loss: 1.2372 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 5.0000e-05\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.9214 - precision: 0.9306 - recall: 0.9178 - f1_score: 0.9241\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.3602 - accuracy: 0.9214 - precision: 0.9306 - recall: 0.9178 - f1_score: 0.9241 - val_loss: 1.0939 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.6364 - val_f1_score: 0.5833 - lr: 5.0000e-05\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.8857 - precision: 0.8608 - recall: 0.9315 - f1_score: 0.8947\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.3977 - accuracy: 0.8857 - precision: 0.8608 - recall: 0.9315 - f1_score: 0.8947 - val_loss: 1.2182 - val_accuracy: 0.7000 - val_precision: 0.5714 - val_recall: 0.7273 - val_f1_score: 0.6400 - lr: 5.0000e-05\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.9286 - precision: 0.9200 - recall: 0.9452 - f1_score: 0.9324\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.4111 - accuracy: 0.9286 - precision: 0.9200 - recall: 0.9452 - f1_score: 0.9324 - val_loss: 1.2972 - val_accuracy: 0.7000 - val_precision: 0.5714 - val_recall: 0.7273 - val_f1_score: 0.6400 - lr: 5.0000e-05\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.8857 - precision: 0.8519 - recall: 0.9452 - f1_score: 0.8961\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.3752 - accuracy: 0.8857 - precision: 0.8519 - recall: 0.9452 - f1_score: 0.8961 - val_loss: 1.3854 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.6364 - val_f1_score: 0.5833 - lr: 5.0000e-05\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.8929 - precision: 0.8919 - recall: 0.9041 - f1_score: 0.8980\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.4553 - accuracy: 0.8929 - precision: 0.8919 - recall: 0.9041 - f1_score: 0.8980 - val_loss: 1.2040 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.3391 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396 - val_loss: 1.0940 - val_accuracy: 0.7000 - val_precision: 0.5714 - val_recall: 0.7273 - val_f1_score: 0.6400 - lr: 5.0000e-05\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8857 - precision: 0.8701 - recall: 0.9178 - f1_score: 0.8933\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.3787 - accuracy: 0.8857 - precision: 0.8701 - recall: 0.9178 - f1_score: 0.8933 - val_loss: 0.9983 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.9214 - precision: 0.8875 - recall: 0.9726 - f1_score: 0.9281\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.3679 - accuracy: 0.9214 - precision: 0.8875 - recall: 0.9726 - f1_score: 0.9281 - val_loss: 1.0045 - val_accuracy: 0.7000 - val_precision: 0.5833 - val_recall: 0.6364 - val_f1_score: 0.6087 - lr: 5.0000e-05\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8786 - precision: 0.9000 - recall: 0.8630 - f1_score: 0.8811\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.3429 - accuracy: 0.8786 - precision: 0.9000 - recall: 0.8630 - f1_score: 0.8811 - val_loss: 1.1152 - val_accuracy: 0.7000 - val_precision: 0.5833 - val_recall: 0.6364 - val_f1_score: 0.6087 - lr: 2.5000e-05\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3433 - accuracy: 0.9071 - precision: 0.9054 - recall: 0.9178 - f1_score: 0.9116\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.3433 - accuracy: 0.9071 - precision: 0.9054 - recall: 0.9178 - f1_score: 0.9116 - val_loss: 1.2175 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 2.5000e-05\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.9286 - precision: 0.8987 - recall: 0.9726 - f1_score: 0.9342\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.2916 - accuracy: 0.9286 - precision: 0.8987 - recall: 0.9726 - f1_score: 0.9342 - val_loss: 1.3628 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 2.5000e-05\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.9429 - precision: 0.9452 - recall: 0.9452 - f1_score: 0.9452\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.3262 - accuracy: 0.9429 - precision: 0.9452 - recall: 0.9452 - f1_score: 0.9452 - val_loss: 1.3713 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 2.5000e-05\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.9143 - precision: 0.9178 - recall: 0.9178 - f1_score: 0.9178\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 97ms/step - loss: 0.3651 - accuracy: 0.9143 - precision: 0.9178 - recall: 0.9178 - f1_score: 0.9178 - val_loss: 1.3160 - val_accuracy: 0.7000 - val_precision: 0.5833 - val_recall: 0.6364 - val_f1_score: 0.6087 - lr: 2.5000e-05\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.8714 - precision: 0.8767 - recall: 0.8767 - f1_score: 0.8767\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.4436 - accuracy: 0.8714 - precision: 0.8767 - recall: 0.8767 - f1_score: 0.8767 - val_loss: 1.3207 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 2.5000e-05\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3525 - accuracy: 0.9143 - precision: 0.8861 - recall: 0.9589 - f1_score: 0.9211\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.3525 - accuracy: 0.9143 - precision: 0.8861 - recall: 0.9589 - f1_score: 0.9211 - val_loss: 1.2802 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.5455 - val_f1_score: 0.5217 - lr: 2.5000e-05\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.9071 - precision: 0.8571 - recall: 0.9863 - f1_score: 0.9172\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.3212 - accuracy: 0.9071 - precision: 0.8571 - recall: 0.9863 - f1_score: 0.9172 - val_loss: 1.1448 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.6364 - val_f1_score: 0.5833 - lr: 2.5000e-05\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.8929 - precision: 0.8816 - recall: 0.9178 - f1_score: 0.8993\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.3634 - accuracy: 0.8929 - precision: 0.8816 - recall: 0.9178 - f1_score: 0.8993 - val_loss: 1.0626 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.6364 - val_f1_score: 0.5833 - lr: 2.5000e-05\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.9071 - precision: 0.8947 - recall: 0.9315 - f1_score: 0.9128\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.3209 - accuracy: 0.9071 - precision: 0.8947 - recall: 0.9315 - f1_score: 0.9128 - val_loss: 1.1409 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.9071 - precision: 0.8947 - recall: 0.9315 - f1_score: 0.9128\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.3091 - accuracy: 0.9071 - precision: 0.8947 - recall: 0.9315 - f1_score: 0.9128 - val_loss: 1.4170 - val_accuracy: 0.5667 - val_precision: 0.4286 - val_recall: 0.5455 - val_f1_score: 0.4800 - lr: 2.5000e-05\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8643 - precision: 0.8553 - recall: 0.8904 - f1_score: 0.8725\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.3607 - accuracy: 0.8643 - precision: 0.8553 - recall: 0.8904 - f1_score: 0.8725 - val_loss: 1.5024 - val_accuracy: 0.5667 - val_precision: 0.4286 - val_recall: 0.5455 - val_f1_score: 0.4800 - lr: 2.5000e-05\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.9000 - precision: 0.8554 - recall: 0.9726 - f1_score: 0.9103\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.3560 - accuracy: 0.9000 - precision: 0.8554 - recall: 0.9726 - f1_score: 0.9103 - val_loss: 1.1193 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 2.5000e-05\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.2842 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396 - val_loss: 1.0011 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.6364 - val_f1_score: 0.5833 - lr: 2.5000e-05\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8857 - precision: 0.8608 - recall: 0.9315 - f1_score: 0.8947\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.3372 - accuracy: 0.8857 - precision: 0.8608 - recall: 0.9315 - f1_score: 0.8947 - val_loss: 1.0288 - val_accuracy: 0.7000 - val_precision: 0.5833 - val_recall: 0.6364 - val_f1_score: 0.6087 - lr: 2.5000e-05\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.9071 - precision: 0.9167 - recall: 0.9041 - f1_score: 0.9103\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.3443 - accuracy: 0.9071 - precision: 0.9167 - recall: 0.9041 - f1_score: 0.9103 - val_loss: 1.0855 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.6364 - val_f1_score: 0.5833 - lr: 1.2500e-05\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.9214 - precision: 0.9429 - recall: 0.9041 - f1_score: 0.9231\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.3459 - accuracy: 0.9214 - precision: 0.9429 - recall: 0.9041 - f1_score: 0.9231 - val_loss: 1.0975 - val_accuracy: 0.7000 - val_precision: 0.5714 - val_recall: 0.7273 - val_f1_score: 0.6400 - lr: 1.2500e-05\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2567 - accuracy: 0.9571 - precision: 0.9351 - recall: 0.9863 - f1_score: 0.9600\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2567 - accuracy: 0.9571 - precision: 0.9351 - recall: 0.9863 - f1_score: 0.9600 - val_loss: 1.1861 - val_accuracy: 0.7000 - val_precision: 0.5625 - val_recall: 0.8182 - val_f1_score: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3073 - accuracy: 0.9214 - precision: 0.8875 - recall: 0.9726 - f1_score: 0.9281\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.3073 - accuracy: 0.9214 - precision: 0.8875 - recall: 0.9726 - f1_score: 0.9281 - val_loss: 1.2298 - val_accuracy: 0.7000 - val_precision: 0.5625 - val_recall: 0.8182 - val_f1_score: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8929 - precision: 0.8452 - recall: 0.9726 - f1_score: 0.9045\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.3383 - accuracy: 0.8929 - precision: 0.8452 - recall: 0.9726 - f1_score: 0.9045 - val_loss: 1.2451 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.5455 - val_f1_score: 0.5217 - lr: 1.2500e-05\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2663 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.2663 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396 - val_loss: 1.4258 - val_accuracy: 0.6000 - val_precision: 0.4545 - val_recall: 0.4545 - val_f1_score: 0.4545 - lr: 1.2500e-05\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.9214 - precision: 0.9189 - recall: 0.9315 - f1_score: 0.9252\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.3122 - accuracy: 0.9214 - precision: 0.9189 - recall: 0.9315 - f1_score: 0.9252 - val_loss: 1.4431 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.5455 - val_f1_score: 0.5217 - lr: 1.2500e-05\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.9214 - precision: 0.8974 - recall: 0.9589 - f1_score: 0.9272\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2833 - accuracy: 0.9214 - precision: 0.8974 - recall: 0.9589 - f1_score: 0.9272 - val_loss: 1.3837 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.2500e-05\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.9286 - precision: 0.9091 - recall: 0.9589 - f1_score: 0.9333\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2985 - accuracy: 0.9286 - precision: 0.9091 - recall: 0.9589 - f1_score: 0.9333 - val_loss: 1.4097 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.2500e-05\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.9500 - precision: 0.9231 - recall: 0.9863 - f1_score: 0.9536\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.2964 - accuracy: 0.9500 - precision: 0.9231 - recall: 0.9863 - f1_score: 0.9536 - val_loss: 1.4416 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.2500e-05\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.9286 - precision: 0.9091 - recall: 0.9589 - f1_score: 0.9333\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.2853 - accuracy: 0.9286 - precision: 0.9091 - recall: 0.9589 - f1_score: 0.9333 - val_loss: 1.5477 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.2500e-05\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.9214 - precision: 0.9189 - recall: 0.9315 - f1_score: 0.9252\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.2850 - accuracy: 0.9214 - precision: 0.9189 - recall: 0.9315 - f1_score: 0.9252 - val_loss: 1.4178 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.2500e-05\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.9571 - precision: 0.9351 - recall: 0.9863 - f1_score: 0.9600\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.3191 - accuracy: 0.9571 - precision: 0.9351 - recall: 0.9863 - f1_score: 0.9600 - val_loss: 1.3993 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.2500e-05\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.9071 - precision: 0.8571 - recall: 0.9863 - f1_score: 0.9172\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.2848 - accuracy: 0.9071 - precision: 0.8571 - recall: 0.9863 - f1_score: 0.9172 - val_loss: 1.3357 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.2500e-05\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.9429 - precision: 0.9114 - recall: 0.9863 - f1_score: 0.9474\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2809 - accuracy: 0.9429 - precision: 0.9114 - recall: 0.9863 - f1_score: 0.9474 - val_loss: 1.3399 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 1.2500e-05\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.9000 - precision: 0.9275 - recall: 0.8767 - f1_score: 0.9014\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.3221 - accuracy: 0.9000 - precision: 0.9275 - recall: 0.8767 - f1_score: 0.9014 - val_loss: 1.3572 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.5455 - val_f1_score: 0.5455 - lr: 1.0000e-05\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.9286 - precision: 0.9315 - recall: 0.9315 - f1_score: 0.9315\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.2710 - accuracy: 0.9286 - precision: 0.9315 - recall: 0.9315 - f1_score: 0.9315 - val_loss: 1.3974 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.9429 - precision: 0.9221 - recall: 0.9726 - f1_score: 0.9467\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2770 - accuracy: 0.9429 - precision: 0.9221 - recall: 0.9726 - f1_score: 0.9467 - val_loss: 1.4799 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.9357 - precision: 0.9000 - recall: 0.9863 - f1_score: 0.9412\n",
            "Epoch 90: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2752 - accuracy: 0.9357 - precision: 0.9000 - recall: 0.9863 - f1_score: 0.9412 - val_loss: 1.5807 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9786 - precision: 0.9605 - recall: 1.0000 - f1_score: 0.9799\n",
            "Epoch 91: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.2072 - accuracy: 0.9786 - precision: 0.9605 - recall: 1.0000 - f1_score: 0.9799 - val_loss: 1.7048 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.9500 - precision: 0.9459 - recall: 0.9589 - f1_score: 0.9524\n",
            "Epoch 92: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2389 - accuracy: 0.9500 - precision: 0.9459 - recall: 0.9589 - f1_score: 0.9524 - val_loss: 1.7891 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.9214 - precision: 0.9189 - recall: 0.9315 - f1_score: 0.9252\n",
            "Epoch 93: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.3278 - accuracy: 0.9214 - precision: 0.9189 - recall: 0.9315 - f1_score: 0.9252 - val_loss: 1.6785 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2695 - accuracy: 0.9357 - precision: 0.8902 - recall: 1.0000 - f1_score: 0.9419\n",
            "Epoch 94: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2695 - accuracy: 0.9357 - precision: 0.8902 - recall: 1.0000 - f1_score: 0.9419 - val_loss: 1.5834 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9429 - precision: 0.9012 - recall: 1.0000 - f1_score: 0.9481\n",
            "Epoch 95: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.2665 - accuracy: 0.9429 - precision: 0.9012 - recall: 1.0000 - f1_score: 0.9481 - val_loss: 1.4434 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9500 - precision: 0.9231 - recall: 0.9863 - f1_score: 0.9536\n",
            "Epoch 96: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.2528 - accuracy: 0.9500 - precision: 0.9231 - recall: 0.9863 - f1_score: 0.9536 - val_loss: 1.3732 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.9357 - precision: 0.9324 - recall: 0.9452 - f1_score: 0.9388\n",
            "Epoch 97: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.2585 - accuracy: 0.9357 - precision: 0.9324 - recall: 0.9452 - f1_score: 0.9388 - val_loss: 1.3474 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.9571 - precision: 0.9589 - recall: 0.9589 - f1_score: 0.9589\n",
            "Epoch 98: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.2468 - accuracy: 0.9571 - precision: 0.9589 - recall: 0.9589 - f1_score: 0.9589 - val_loss: 1.3394 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9357 - precision: 0.9000 - recall: 0.9863 - f1_score: 0.9412\n",
            "Epoch 99: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2405 - accuracy: 0.9357 - precision: 0.9000 - recall: 0.9863 - f1_score: 0.9412 - val_loss: 1.4269 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2725 - accuracy: 0.9357 - precision: 0.9324 - recall: 0.9452 - f1_score: 0.9388\n",
            "Epoch 100: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.2725 - accuracy: 0.9357 - precision: 0.9324 - recall: 0.9452 - f1_score: 0.9388 - val_loss: 1.5167 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.9643 - precision: 0.9474 - recall: 0.9863 - f1_score: 0.9664\n",
            "Epoch 101: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2265 - accuracy: 0.9643 - precision: 0.9474 - recall: 0.9863 - f1_score: 0.9664 - val_loss: 1.5959 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9500 - precision: 0.9583 - recall: 0.9452 - f1_score: 0.9517\n",
            "Epoch 102: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2330 - accuracy: 0.9500 - precision: 0.9583 - recall: 0.9452 - f1_score: 0.9517 - val_loss: 1.6210 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.9500 - precision: 0.9231 - recall: 0.9863 - f1_score: 0.9536\n",
            "Epoch 103: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2400 - accuracy: 0.9500 - precision: 0.9231 - recall: 0.9863 - f1_score: 0.9536 - val_loss: 1.5502 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.9571 - precision: 0.9351 - recall: 0.9863 - f1_score: 0.9600\n",
            "Epoch 104: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2825 - accuracy: 0.9571 - precision: 0.9351 - recall: 0.9863 - f1_score: 0.9600 - val_loss: 1.5367 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2594 - accuracy: 0.9500 - precision: 0.9231 - recall: 0.9863 - f1_score: 0.9536\n",
            "Epoch 105: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.2594 - accuracy: 0.9500 - precision: 0.9231 - recall: 0.9863 - f1_score: 0.9536 - val_loss: 1.4306 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2905 - accuracy: 0.9214 - precision: 0.9306 - recall: 0.9178 - f1_score: 0.9241\n",
            "Epoch 106: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.2905 - accuracy: 0.9214 - precision: 0.9306 - recall: 0.9178 - f1_score: 0.9241 - val_loss: 1.3740 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2277 - accuracy: 0.9571 - precision: 0.9589 - recall: 0.9589 - f1_score: 0.9589\n",
            "Epoch 107: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.2277 - accuracy: 0.9571 - precision: 0.9589 - recall: 0.9589 - f1_score: 0.9589 - val_loss: 1.3619 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.9429 - precision: 0.9221 - recall: 0.9726 - f1_score: 0.9467\n",
            "Epoch 108: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.2748 - accuracy: 0.9429 - precision: 0.9221 - recall: 0.9726 - f1_score: 0.9467 - val_loss: 1.4135 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.9286 - precision: 0.9091 - recall: 0.9589 - f1_score: 0.9333\n",
            "Epoch 109: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.3068 - accuracy: 0.9286 - precision: 0.9091 - recall: 0.9589 - f1_score: 0.9333 - val_loss: 1.4642 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.9000 - precision: 0.9041 - recall: 0.9041 - f1_score: 0.9041\n",
            "Epoch 110: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2831 - accuracy: 0.9000 - precision: 0.9041 - recall: 0.9041 - f1_score: 0.9041 - val_loss: 1.5553 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9571 - precision: 0.9467 - recall: 0.9726 - f1_score: 0.9595\n",
            "Epoch 111: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2199 - accuracy: 0.9571 - precision: 0.9467 - recall: 0.9726 - f1_score: 0.9595 - val_loss: 1.6852 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.6364 - val_f1_score: 0.5833 - lr: 1.0000e-05\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404\n",
            "Epoch 112: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.2835 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404 - val_loss: 1.7913 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.5455 - val_f1_score: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.9429 - precision: 0.9333 - recall: 0.9589 - f1_score: 0.9459\n",
            "Epoch 113: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2655 - accuracy: 0.9429 - precision: 0.9333 - recall: 0.9589 - f1_score: 0.9459 - val_loss: 1.7413 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.9286 - precision: 0.9200 - recall: 0.9452 - f1_score: 0.9324\n",
            "Epoch 114: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2738 - accuracy: 0.9286 - precision: 0.9200 - recall: 0.9452 - f1_score: 0.9324 - val_loss: 1.5671 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9500 - precision: 0.9459 - recall: 0.9589 - f1_score: 0.9524\n",
            "Epoch 115: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2221 - accuracy: 0.9500 - precision: 0.9459 - recall: 0.9589 - f1_score: 0.9524 - val_loss: 1.4939 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9429 - precision: 0.9333 - recall: 0.9589 - f1_score: 0.9459\n",
            "Epoch 116: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.2302 - accuracy: 0.9429 - precision: 0.9333 - recall: 0.9589 - f1_score: 0.9459 - val_loss: 1.4884 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404\n",
            "Epoch 117: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.2557 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404 - val_loss: 1.4942 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9357 - precision: 0.9444 - recall: 0.9315 - f1_score: 0.9379\n",
            "Epoch 118: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2437 - accuracy: 0.9357 - precision: 0.9444 - recall: 0.9315 - f1_score: 0.9379 - val_loss: 1.5004 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9643 - precision: 0.9595 - recall: 0.9726 - f1_score: 0.9660\n",
            "Epoch 119: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.2182 - accuracy: 0.9643 - precision: 0.9595 - recall: 0.9726 - f1_score: 0.9660 - val_loss: 1.5909 - val_accuracy: 0.7000 - val_precision: 0.5625 - val_recall: 0.8182 - val_f1_score: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9500 - precision: 0.9459 - recall: 0.9589 - f1_score: 0.9524\n",
            "Epoch 120: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2199 - accuracy: 0.9500 - precision: 0.9459 - recall: 0.9589 - f1_score: 0.9524 - val_loss: 1.6156 - val_accuracy: 0.7000 - val_precision: 0.5625 - val_recall: 0.8182 - val_f1_score: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404\n",
            "Epoch 121: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2566 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404 - val_loss: 1.6072 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396\n",
            "Epoch 122: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.3278 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396 - val_loss: 1.5854 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9786 - precision: 0.9730 - recall: 0.9863 - f1_score: 0.9796\n",
            "Epoch 123: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.1798 - accuracy: 0.9786 - precision: 0.9730 - recall: 0.9863 - f1_score: 0.9796 - val_loss: 1.7669 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.9429 - precision: 0.9452 - recall: 0.9452 - f1_score: 0.9452\n",
            "Epoch 124: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.2673 - accuracy: 0.9429 - precision: 0.9452 - recall: 0.9452 - f1_score: 0.9452 - val_loss: 1.6920 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9286 - precision: 0.8889 - recall: 0.9863 - f1_score: 0.9351\n",
            "Epoch 125: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2461 - accuracy: 0.9286 - precision: 0.8889 - recall: 0.9863 - f1_score: 0.9351 - val_loss: 1.6622 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9571 - precision: 0.9467 - recall: 0.9726 - f1_score: 0.9595\n",
            "Epoch 126: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2007 - accuracy: 0.9571 - precision: 0.9467 - recall: 0.9726 - f1_score: 0.9595 - val_loss: 1.5631 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.9500 - precision: 0.9583 - recall: 0.9452 - f1_score: 0.9517\n",
            "Epoch 127: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.2053 - accuracy: 0.9500 - precision: 0.9583 - recall: 0.9452 - f1_score: 0.9517 - val_loss: 1.6813 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 128/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9571 - precision: 0.9241 - recall: 1.0000 - f1_score: 0.9605\n",
            "Epoch 128: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.2213 - accuracy: 0.9571 - precision: 0.9241 - recall: 1.0000 - f1_score: 0.9605 - val_loss: 1.7156 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 129/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.9429 - precision: 0.9012 - recall: 1.0000 - f1_score: 0.9481\n",
            "Epoch 129: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2691 - accuracy: 0.9429 - precision: 0.9012 - recall: 1.0000 - f1_score: 0.9481 - val_loss: 1.6630 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 130/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.9429 - precision: 0.9452 - recall: 0.9452 - f1_score: 0.9452\n",
            "Epoch 130: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.2496 - accuracy: 0.9429 - precision: 0.9452 - recall: 0.9452 - f1_score: 0.9452 - val_loss: 1.6587 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 131/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9500 - precision: 0.9342 - recall: 0.9726 - f1_score: 0.9530\n",
            "Epoch 131: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.2612 - accuracy: 0.9500 - precision: 0.9342 - recall: 0.9726 - f1_score: 0.9530 - val_loss: 1.7633 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 132/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396\n",
            "Epoch 132: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2127 - accuracy: 0.9357 - precision: 0.9211 - recall: 0.9589 - f1_score: 0.9396 - val_loss: 1.8937 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 133/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404\n",
            "Epoch 133: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 135ms/step - loss: 0.2346 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404 - val_loss: 1.9048 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 134/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9429 - precision: 0.9114 - recall: 0.9863 - f1_score: 0.9474\n",
            "Epoch 134: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2325 - accuracy: 0.9429 - precision: 0.9114 - recall: 0.9863 - f1_score: 0.9474 - val_loss: 1.9941 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 135/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9571 - precision: 0.9351 - recall: 0.9863 - f1_score: 0.9600\n",
            "Epoch 135: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.2213 - accuracy: 0.9571 - precision: 0.9351 - recall: 0.9863 - f1_score: 0.9600 - val_loss: 2.1561 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.6364 - val_f1_score: 0.5600 - lr: 1.0000e-05\n",
            "Epoch 136/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.9357 - precision: 0.9000 - recall: 0.9863 - f1_score: 0.9412\n",
            "Epoch 136: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.2130 - accuracy: 0.9357 - precision: 0.9000 - recall: 0.9863 - f1_score: 0.9412 - val_loss: 2.2765 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 137/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.9714 - precision: 0.9600 - recall: 0.9863 - f1_score: 0.9730\n",
            "Epoch 137: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.1893 - accuracy: 0.9714 - precision: 0.9600 - recall: 0.9863 - f1_score: 0.9730 - val_loss: 2.4916 - val_accuracy: 0.6333 - val_precision: 0.5000 - val_recall: 0.5455 - val_f1_score: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 138/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9500 - precision: 0.9459 - recall: 0.9589 - f1_score: 0.9524\n",
            "Epoch 138: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.2165 - accuracy: 0.9500 - precision: 0.9459 - recall: 0.9589 - f1_score: 0.9524 - val_loss: 2.4364 - val_accuracy: 0.6000 - val_precision: 0.4615 - val_recall: 0.5455 - val_f1_score: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 139/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404\n",
            "Epoch 139: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.2444 - accuracy: 0.9357 - precision: 0.9103 - recall: 0.9726 - f1_score: 0.9404 - val_loss: 2.1731 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 140/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9571 - precision: 0.9467 - recall: 0.9726 - f1_score: 0.9595\n",
            "Epoch 140: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 0.2055 - accuracy: 0.9571 - precision: 0.9467 - recall: 0.9726 - f1_score: 0.9595 - val_loss: 2.0032 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.7273 - val_f1_score: 0.6154 - lr: 1.0000e-05\n",
            "Epoch 140: early stopping\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 1.2040 - accuracy: 0.7000 - precision: 0.6842 - recall: 0.8125 - f1_score: 0.7429\n",
            "\n",
            "############# Fold n°8 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.4801 - accuracy: 0.5294 - precision: 0.5217 - recall: 0.4337 - f1_score: 0.4737\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 6s 110ms/step - loss: 2.4801 - accuracy: 0.5294 - precision: 0.5217 - recall: 0.4337 - f1_score: 0.4737 - val_loss: 2.1848 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.9423 - accuracy: 0.5143 - precision: 0.4667 - recall: 0.1045 - f1_score: 0.1707\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 1.9423 - accuracy: 0.5143 - precision: 0.4667 - recall: 0.1045 - f1_score: 0.1707 - val_loss: 1.7041 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.5183 - accuracy: 0.5286 - precision: 0.5217 - recall: 0.1791 - f1_score: 0.2667\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 1.5183 - accuracy: 0.5286 - precision: 0.5217 - recall: 0.1791 - f1_score: 0.2667 - val_loss: 1.3484 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.2269 - accuracy: 0.5214 - precision: 0.5000 - recall: 0.1045 - f1_score: 0.1728\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 1.2269 - accuracy: 0.5214 - precision: 0.5000 - recall: 0.1045 - f1_score: 0.1728 - val_loss: 1.1222 - val_accuracy: 0.4333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0606 - accuracy: 0.5143 - precision: 0.4286 - recall: 0.0448 - f1_score: 0.0811\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 1.0606 - accuracy: 0.5143 - precision: 0.4286 - recall: 0.0448 - f1_score: 0.0811 - val_loss: 1.0212 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.1176 - val_f1_score: 0.2105 - lr: 1.0000e-04\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0175 - accuracy: 0.5429 - precision: 0.5349 - recall: 0.3433 - f1_score: 0.4182\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 1.0175 - accuracy: 0.5429 - precision: 0.5349 - recall: 0.3433 - f1_score: 0.4182 - val_loss: 1.0166 - val_accuracy: 0.6333 - val_precision: 0.6875 - val_recall: 0.6471 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9870 - accuracy: 0.5500 - precision: 0.5323 - recall: 0.4925 - f1_score: 0.5116\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.9870 - accuracy: 0.5500 - precision: 0.5323 - recall: 0.4925 - f1_score: 0.5116 - val_loss: 0.9495 - val_accuracy: 0.5333 - val_precision: 1.0000 - val_recall: 0.1765 - val_f1_score: 0.3000 - lr: 1.0000e-04\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8874 - accuracy: 0.5857 - precision: 0.5652 - recall: 0.5821 - f1_score: 0.5735\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.8874 - accuracy: 0.5857 - precision: 0.5652 - recall: 0.5821 - f1_score: 0.5735 - val_loss: 0.8477 - val_accuracy: 0.5000 - val_precision: 0.5500 - val_recall: 0.6471 - val_f1_score: 0.5946 - lr: 1.0000e-04\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8627 - accuracy: 0.5071 - precision: 0.4833 - recall: 0.4328 - f1_score: 0.4567\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.8627 - accuracy: 0.5071 - precision: 0.4833 - recall: 0.4328 - f1_score: 0.4567 - val_loss: 0.8303 - val_accuracy: 0.6667 - val_precision: 0.7692 - val_recall: 0.5882 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8244 - accuracy: 0.6286 - precision: 0.6154 - recall: 0.5970 - f1_score: 0.6061\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.8244 - accuracy: 0.6286 - precision: 0.6154 - recall: 0.5970 - f1_score: 0.6061 - val_loss: 0.7965 - val_accuracy: 0.6333 - val_precision: 0.6667 - val_recall: 0.7059 - val_f1_score: 0.6857 - lr: 1.0000e-04\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8166 - accuracy: 0.6429 - precision: 0.6000 - recall: 0.7612 - f1_score: 0.6711\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.8166 - accuracy: 0.6429 - precision: 0.6000 - recall: 0.7612 - f1_score: 0.6711 - val_loss: 0.8202 - val_accuracy: 0.6667 - val_precision: 0.8182 - val_recall: 0.5294 - val_f1_score: 0.6429 - lr: 1.0000e-04\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8091 - accuracy: 0.6286 - precision: 0.6829 - recall: 0.4179 - f1_score: 0.5185\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.8091 - accuracy: 0.6286 - precision: 0.6829 - recall: 0.4179 - f1_score: 0.5185 - val_loss: 0.8302 - val_accuracy: 0.6000 - val_precision: 0.7778 - val_recall: 0.4118 - val_f1_score: 0.5385 - lr: 1.0000e-04\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7903 - accuracy: 0.6714 - precision: 0.6780 - recall: 0.5970 - f1_score: 0.6349\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.7903 - accuracy: 0.6714 - precision: 0.6780 - recall: 0.5970 - f1_score: 0.6349 - val_loss: 0.8212 - val_accuracy: 0.6667 - val_precision: 0.7692 - val_recall: 0.5882 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7926 - accuracy: 0.6500 - precision: 0.6552 - recall: 0.5672 - f1_score: 0.6080\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.7926 - accuracy: 0.6500 - precision: 0.6552 - recall: 0.5672 - f1_score: 0.6080 - val_loss: 0.8230 - val_accuracy: 0.6333 - val_precision: 0.8000 - val_recall: 0.4706 - val_f1_score: 0.5926 - lr: 1.0000e-04\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7641 - accuracy: 0.6714 - precision: 0.6909 - recall: 0.5672 - f1_score: 0.6230\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.7641 - accuracy: 0.6714 - precision: 0.6909 - recall: 0.5672 - f1_score: 0.6230 - val_loss: 0.8254 - val_accuracy: 0.6333 - val_precision: 0.8000 - val_recall: 0.4706 - val_f1_score: 0.5926 - lr: 1.0000e-04\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7842 - accuracy: 0.6786 - precision: 0.7115 - recall: 0.5522 - f1_score: 0.6218\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.7842 - accuracy: 0.6786 - precision: 0.7115 - recall: 0.5522 - f1_score: 0.6218 - val_loss: 0.8006 - val_accuracy: 0.6333 - val_precision: 0.8000 - val_recall: 0.4706 - val_f1_score: 0.5926 - lr: 1.0000e-04\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7548 - accuracy: 0.6786 - precision: 0.6897 - recall: 0.5970 - f1_score: 0.6400\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.7548 - accuracy: 0.6786 - precision: 0.6897 - recall: 0.5970 - f1_score: 0.6400 - val_loss: 0.8148 - val_accuracy: 0.6667 - val_precision: 0.8182 - val_recall: 0.5294 - val_f1_score: 0.6429 - lr: 1.0000e-04\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7187 - accuracy: 0.7214 - precision: 0.7692 - recall: 0.5970 - f1_score: 0.6723\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.7187 - accuracy: 0.7214 - precision: 0.7692 - recall: 0.5970 - f1_score: 0.6723 - val_loss: 0.8590 - val_accuracy: 0.6667 - val_precision: 0.7692 - val_recall: 0.5882 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7590 - accuracy: 0.6500 - precision: 0.6500 - recall: 0.5821 - f1_score: 0.6142\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.7590 - accuracy: 0.6500 - precision: 0.6500 - recall: 0.5821 - f1_score: 0.6142 - val_loss: 0.8245 - val_accuracy: 0.6000 - val_precision: 0.7778 - val_recall: 0.4118 - val_f1_score: 0.5385 - lr: 1.0000e-04\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7607 - accuracy: 0.6714 - precision: 0.7234 - recall: 0.5075 - f1_score: 0.5965\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.7607 - accuracy: 0.6714 - precision: 0.7234 - recall: 0.5075 - f1_score: 0.5965 - val_loss: 0.8208 - val_accuracy: 0.6333 - val_precision: 0.8000 - val_recall: 0.4706 - val_f1_score: 0.5926 - lr: 1.0000e-04\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7595 - accuracy: 0.7071 - precision: 0.6970 - recall: 0.6866 - f1_score: 0.6917\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.7595 - accuracy: 0.7071 - precision: 0.6970 - recall: 0.6866 - f1_score: 0.6917 - val_loss: 0.7458 - val_accuracy: 0.7000 - val_precision: 0.7857 - val_recall: 0.6471 - val_f1_score: 0.7097 - lr: 1.0000e-04\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7432 - accuracy: 0.6857 - precision: 0.6667 - recall: 0.6866 - f1_score: 0.6765\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.7432 - accuracy: 0.6857 - precision: 0.6667 - recall: 0.6866 - f1_score: 0.6765 - val_loss: 0.7685 - val_accuracy: 0.6667 - val_precision: 0.8182 - val_recall: 0.5294 - val_f1_score: 0.6429 - lr: 1.0000e-04\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.7071 - precision: 0.7826 - recall: 0.5373 - f1_score: 0.6372\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.7153 - accuracy: 0.7071 - precision: 0.7826 - recall: 0.5373 - f1_score: 0.6372 - val_loss: 0.8371 - val_accuracy: 0.7000 - val_precision: 0.9000 - val_recall: 0.5294 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.7000 - precision: 0.7273 - recall: 0.5970 - f1_score: 0.6557\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.6871 - accuracy: 0.7000 - precision: 0.7273 - recall: 0.5970 - f1_score: 0.6557 - val_loss: 0.7776 - val_accuracy: 0.6667 - val_precision: 0.7692 - val_recall: 0.5882 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.7286 - precision: 0.7636 - recall: 0.6269 - f1_score: 0.6885\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.6964 - accuracy: 0.7286 - precision: 0.7636 - recall: 0.6269 - f1_score: 0.6885 - val_loss: 0.7901 - val_accuracy: 0.7000 - val_precision: 0.9000 - val_recall: 0.5294 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.7643 - precision: 0.7576 - recall: 0.7463 - f1_score: 0.7519\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.6932 - accuracy: 0.7643 - precision: 0.7576 - recall: 0.7463 - f1_score: 0.7519 - val_loss: 0.7339 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 1.0000e-04\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6409 - accuracy: 0.8000 - precision: 0.8305 - recall: 0.7313 - f1_score: 0.7778\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.6409 - accuracy: 0.8000 - precision: 0.8305 - recall: 0.7313 - f1_score: 0.7778 - val_loss: 0.7979 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 1.0000e-04\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.7643 - precision: 0.7429 - recall: 0.7761 - f1_score: 0.7591\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.6947 - accuracy: 0.7643 - precision: 0.7429 - recall: 0.7761 - f1_score: 0.7591 - val_loss: 0.6835 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6527 - accuracy: 0.7714 - precision: 0.8302 - recall: 0.6567 - f1_score: 0.7333\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.6527 - accuracy: 0.7714 - precision: 0.8302 - recall: 0.6567 - f1_score: 0.7333 - val_loss: 0.7828 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 1.0000e-04\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6220 - accuracy: 0.8286 - precision: 0.8413 - recall: 0.7910 - f1_score: 0.8154\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.6220 - accuracy: 0.8286 - precision: 0.8413 - recall: 0.7910 - f1_score: 0.8154 - val_loss: 0.7194 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.8214 - precision: 0.7917 - recall: 0.8507 - f1_score: 0.8201\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.6265 - accuracy: 0.8214 - precision: 0.7917 - recall: 0.8507 - f1_score: 0.8201 - val_loss: 0.8823 - val_accuracy: 0.7333 - val_precision: 0.9091 - val_recall: 0.5882 - val_f1_score: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.8143 - precision: 0.8475 - recall: 0.7463 - f1_score: 0.7937\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.6086 - accuracy: 0.8143 - precision: 0.8475 - recall: 0.7463 - f1_score: 0.7937 - val_loss: 0.7992 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.8571 - precision: 0.8219 - recall: 0.8955 - f1_score: 0.8571\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 0.5448 - accuracy: 0.8571 - precision: 0.8219 - recall: 0.8955 - f1_score: 0.8571 - val_loss: 0.9049 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 1.0000e-04\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.8429 - precision: 0.8814 - recall: 0.7761 - f1_score: 0.8254\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.5620 - accuracy: 0.8429 - precision: 0.8814 - recall: 0.7761 - f1_score: 0.8254 - val_loss: 0.8912 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5950 - accuracy: 0.8214 - precision: 0.8000 - recall: 0.8358 - f1_score: 0.8175\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.5950 - accuracy: 0.8214 - precision: 0.8000 - recall: 0.8358 - f1_score: 0.8175 - val_loss: 1.0102 - val_accuracy: 0.7333 - val_precision: 0.9091 - val_recall: 0.5882 - val_f1_score: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.8214 - precision: 0.8281 - recall: 0.7910 - f1_score: 0.8092\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.6360 - accuracy: 0.8214 - precision: 0.8281 - recall: 0.7910 - f1_score: 0.8092 - val_loss: 0.7426 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5699 - accuracy: 0.8429 - precision: 0.8947 - recall: 0.7612 - f1_score: 0.8226\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.5699 - accuracy: 0.8429 - precision: 0.8947 - recall: 0.7612 - f1_score: 0.8226 - val_loss: 0.9089 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.8786 - precision: 0.8472 - recall: 0.9104 - f1_score: 0.8777\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.5600 - accuracy: 0.8786 - precision: 0.8472 - recall: 0.9104 - f1_score: 0.8777 - val_loss: 0.9414 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5713 - accuracy: 0.8500 - precision: 0.8485 - recall: 0.8358 - f1_score: 0.8421\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.5713 - accuracy: 0.8500 - precision: 0.8485 - recall: 0.8358 - f1_score: 0.8421 - val_loss: 0.7909 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5526 - accuracy: 0.8500 - precision: 0.8485 - recall: 0.8358 - f1_score: 0.8421\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.5526 - accuracy: 0.8500 - precision: 0.8485 - recall: 0.8358 - f1_score: 0.8421 - val_loss: 0.8813 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 1.0000e-04\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.8714 - precision: 0.8889 - recall: 0.8358 - f1_score: 0.8615\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.5236 - accuracy: 0.8714 - precision: 0.8889 - recall: 0.8358 - f1_score: 0.8615 - val_loss: 1.0001 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.8714 - precision: 0.8889 - recall: 0.8358 - f1_score: 0.8615\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.5361 - accuracy: 0.8714 - precision: 0.8889 - recall: 0.8358 - f1_score: 0.8615 - val_loss: 0.9877 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.9071 - precision: 0.8971 - recall: 0.9104 - f1_score: 0.9037\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.4970 - accuracy: 0.9071 - precision: 0.8971 - recall: 0.9104 - f1_score: 0.9037 - val_loss: 0.9442 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5020 - accuracy: 0.9000 - precision: 0.9077 - recall: 0.8806 - f1_score: 0.8939\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.5020 - accuracy: 0.9000 - precision: 0.9077 - recall: 0.8806 - f1_score: 0.8939 - val_loss: 0.8112 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 5.0000e-05\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.8929 - precision: 0.8611 - recall: 0.9254 - f1_score: 0.8921\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.5309 - accuracy: 0.8929 - precision: 0.8611 - recall: 0.9254 - f1_score: 0.8921 - val_loss: 0.8386 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 5.0000e-05\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.8429 - precision: 0.8358 - recall: 0.8358 - f1_score: 0.8358\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.5623 - accuracy: 0.8429 - precision: 0.8358 - recall: 0.8358 - f1_score: 0.8358 - val_loss: 0.7351 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 5.0000e-05\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.8929 - precision: 0.8714 - recall: 0.9104 - f1_score: 0.8905\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.4991 - accuracy: 0.8929 - precision: 0.8714 - recall: 0.9104 - f1_score: 0.8905 - val_loss: 0.9275 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 5.0000e-05\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.9143 - precision: 0.9508 - recall: 0.8657 - f1_score: 0.9062\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.4184 - accuracy: 0.9143 - precision: 0.9508 - recall: 0.8657 - f1_score: 0.9062 - val_loss: 1.0840 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 5.0000e-05\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.9071 - precision: 0.9355 - recall: 0.8657 - f1_score: 0.8992\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.4363 - accuracy: 0.9071 - precision: 0.9355 - recall: 0.8657 - f1_score: 0.8992 - val_loss: 1.0886 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 5.0000e-05\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.8714 - precision: 0.8356 - recall: 0.9104 - f1_score: 0.8714\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.4966 - accuracy: 0.8714 - precision: 0.8356 - recall: 0.9104 - f1_score: 0.8714 - val_loss: 0.8877 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 5.0000e-05\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.9286 - precision: 0.9524 - recall: 0.8955 - f1_score: 0.9231\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.4055 - accuracy: 0.9286 - precision: 0.9524 - recall: 0.8955 - f1_score: 0.9231 - val_loss: 0.9579 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 5.0000e-05\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.9286 - precision: 0.9254 - recall: 0.9254 - f1_score: 0.9254\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.4174 - accuracy: 0.9286 - precision: 0.9254 - recall: 0.9254 - f1_score: 0.9254 - val_loss: 0.8422 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 5.0000e-05\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.9143 - precision: 0.9231 - recall: 0.8955 - f1_score: 0.9091\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.4232 - accuracy: 0.9143 - precision: 0.9231 - recall: 0.8955 - f1_score: 0.9091 - val_loss: 0.7007 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 5.0000e-05\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.9357 - precision: 0.9028 - recall: 0.9701 - f1_score: 0.9353\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.4026 - accuracy: 0.9357 - precision: 0.9028 - recall: 0.9701 - f1_score: 0.9353 - val_loss: 0.8592 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 5.0000e-05\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4273 - accuracy: 0.9214 - precision: 0.9375 - recall: 0.8955 - f1_score: 0.9160\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.4273 - accuracy: 0.9214 - precision: 0.9375 - recall: 0.8955 - f1_score: 0.9160 - val_loss: 0.9641 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 5.0000e-05\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.9214 - precision: 0.9242 - recall: 0.9104 - f1_score: 0.9173\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.4071 - accuracy: 0.9214 - precision: 0.9242 - recall: 0.9104 - f1_score: 0.9173 - val_loss: 1.0779 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 5.0000e-05\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3791 - accuracy: 0.9357 - precision: 0.9265 - recall: 0.9403 - f1_score: 0.9333\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.3791 - accuracy: 0.9357 - precision: 0.9265 - recall: 0.9403 - f1_score: 0.9333 - val_loss: 1.1498 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 5.0000e-05\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.9214 - precision: 0.9118 - recall: 0.9254 - f1_score: 0.9185\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.4319 - accuracy: 0.9214 - precision: 0.9118 - recall: 0.9254 - f1_score: 0.9185 - val_loss: 0.9381 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 5.0000e-05\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.9143 - precision: 0.9104 - recall: 0.9104 - f1_score: 0.9104\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.4242 - accuracy: 0.9143 - precision: 0.9104 - recall: 0.9104 - f1_score: 0.9104 - val_loss: 1.0236 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 5.0000e-05\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.9214 - precision: 0.9242 - recall: 0.9104 - f1_score: 0.9173\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.4011 - accuracy: 0.9214 - precision: 0.9242 - recall: 0.9104 - f1_score: 0.9173 - val_loss: 0.8797 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.3524 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565 - val_loss: 0.8711 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.9357 - precision: 0.9265 - recall: 0.9403 - f1_score: 0.9333\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.3671 - accuracy: 0.9357 - precision: 0.9265 - recall: 0.9403 - f1_score: 0.9333 - val_loss: 0.9156 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.9357 - precision: 0.9265 - recall: 0.9403 - f1_score: 0.9333\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.3810 - accuracy: 0.9357 - precision: 0.9265 - recall: 0.9403 - f1_score: 0.9333 - val_loss: 0.8893 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.9429 - precision: 0.9538 - recall: 0.9254 - f1_score: 0.9394\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.3506 - accuracy: 0.9429 - precision: 0.9538 - recall: 0.9254 - f1_score: 0.9394 - val_loss: 0.9082 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.9286 - precision: 0.9014 - recall: 0.9552 - f1_score: 0.9275\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.4309 - accuracy: 0.9286 - precision: 0.9014 - recall: 0.9552 - f1_score: 0.9275 - val_loss: 0.9247 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.9357 - precision: 0.9531 - recall: 0.9104 - f1_score: 0.9313\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.3857 - accuracy: 0.9357 - precision: 0.9531 - recall: 0.9104 - f1_score: 0.9313 - val_loss: 0.9318 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 2.5000e-05\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4168 - accuracy: 0.9143 - precision: 0.9231 - recall: 0.8955 - f1_score: 0.9091\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.4168 - accuracy: 0.9143 - precision: 0.9231 - recall: 0.8955 - f1_score: 0.9091 - val_loss: 0.7605 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3709 - accuracy: 0.9286 - precision: 0.9014 - recall: 0.9552 - f1_score: 0.9275\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.3709 - accuracy: 0.9286 - precision: 0.9014 - recall: 0.9552 - f1_score: 0.9275 - val_loss: 0.8342 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.3131 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778 - val_loss: 1.0370 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.9500 - precision: 0.9545 - recall: 0.9403 - f1_score: 0.9474\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.3347 - accuracy: 0.9500 - precision: 0.9545 - recall: 0.9403 - f1_score: 0.9474 - val_loss: 1.1145 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.9500 - precision: 0.9688 - recall: 0.9254 - f1_score: 0.9466\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.3455 - accuracy: 0.9500 - precision: 0.9688 - recall: 0.9254 - f1_score: 0.9466 - val_loss: 1.0795 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.3038 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 1.0726 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.9500 - precision: 0.9412 - recall: 0.9552 - f1_score: 0.9481\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.3917 - accuracy: 0.9500 - precision: 0.9412 - recall: 0.9552 - f1_score: 0.9481 - val_loss: 1.2055 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 2.5000e-05\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.9143 - precision: 0.9661 - recall: 0.8507 - f1_score: 0.9048\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.4205 - accuracy: 0.9143 - precision: 0.9661 - recall: 0.8507 - f1_score: 0.9048 - val_loss: 0.8537 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.9571 - precision: 0.9178 - recall: 1.0000 - f1_score: 0.9571\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.3059 - accuracy: 0.9571 - precision: 0.9178 - recall: 1.0000 - f1_score: 0.9571 - val_loss: 0.8974 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 2.5000e-05\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.9214 - precision: 0.9000 - recall: 0.9403 - f1_score: 0.9197\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.3606 - accuracy: 0.9214 - precision: 0.9000 - recall: 0.9403 - f1_score: 0.9197 - val_loss: 1.0364 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 2.5000e-05\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.3215 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618 - val_loss: 1.2347 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 2.5000e-05\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.9357 - precision: 0.9531 - recall: 0.9104 - f1_score: 0.9313\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.3758 - accuracy: 0.9357 - precision: 0.9531 - recall: 0.9104 - f1_score: 0.9313 - val_loss: 0.9578 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 2.5000e-05\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.9429 - precision: 0.9041 - recall: 0.9851 - f1_score: 0.9429\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.3320 - accuracy: 0.9429 - precision: 0.9041 - recall: 0.9851 - f1_score: 0.9429 - val_loss: 0.9721 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 2.5000e-05\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.9429 - precision: 0.9538 - recall: 0.9254 - f1_score: 0.9394\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 0.3268 - accuracy: 0.9429 - precision: 0.9538 - recall: 0.9254 - f1_score: 0.9394 - val_loss: 1.2210 - val_accuracy: 0.7667 - val_precision: 0.9167 - val_recall: 0.6471 - val_f1_score: 0.7586 - lr: 2.5000e-05\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2898 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630 - val_loss: 1.1543 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.3537 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559 - val_loss: 1.0920 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.9500 - precision: 0.9412 - recall: 0.9552 - f1_score: 0.9481\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.3374 - accuracy: 0.9500 - precision: 0.9412 - recall: 0.9552 - f1_score: 0.9481 - val_loss: 0.9748 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 2.5000e-05\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.9357 - precision: 0.9531 - recall: 0.9104 - f1_score: 0.9313\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.3767 - accuracy: 0.9357 - precision: 0.9531 - recall: 0.9104 - f1_score: 0.9313 - val_loss: 0.7737 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.9500 - precision: 0.9412 - recall: 0.9552 - f1_score: 0.9481\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.3186 - accuracy: 0.9500 - precision: 0.9412 - recall: 0.9552 - f1_score: 0.9481 - val_loss: 0.7524 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.9500 - precision: 0.9286 - recall: 0.9701 - f1_score: 0.9489\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.3261 - accuracy: 0.9500 - precision: 0.9286 - recall: 0.9701 - f1_score: 0.9489 - val_loss: 0.8240 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.3334 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624 - val_loss: 0.8971 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2824 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630 - val_loss: 0.8127 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.3362 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 0.9794 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697\n",
            "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.2856 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697 - val_loss: 0.9147 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 2.5000e-05\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.8929 - precision: 0.8939 - recall: 0.8806 - f1_score: 0.8872\n",
            "Epoch 91: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.3933 - accuracy: 0.8929 - precision: 0.8939 - recall: 0.8806 - f1_score: 0.8872 - val_loss: 0.9292 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.2500e-05\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2843 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630\n",
            "Epoch 92: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.2843 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630 - val_loss: 0.9769 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.2500e-05\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.9571 - precision: 0.9692 - recall: 0.9403 - f1_score: 0.9545\n",
            "Epoch 93: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.2839 - accuracy: 0.9571 - precision: 0.9692 - recall: 0.9403 - f1_score: 0.9545 - val_loss: 0.9597 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778\n",
            "Epoch 94: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.3222 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778 - val_loss: 0.9849 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706\n",
            "Epoch 95: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.2717 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706 - val_loss: 0.9179 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2937 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552\n",
            "Epoch 96: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.2937 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552 - val_loss: 0.8260 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.9500 - precision: 0.9545 - recall: 0.9403 - f1_score: 0.9474\n",
            "Epoch 97: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2864 - accuracy: 0.9500 - precision: 0.9545 - recall: 0.9403 - f1_score: 0.9474 - val_loss: 0.7898 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778\n",
            "Epoch 98: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2503 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778 - val_loss: 0.8802 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697\n",
            "Epoch 99: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.2640 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697 - val_loss: 0.9322 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 100: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2378 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 0.8746 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2800 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778\n",
            "Epoch 101: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2800 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778 - val_loss: 0.8674 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552\n",
            "Epoch 102: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.3059 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552 - val_loss: 0.9950 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.2500e-05\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 103: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2324 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 1.0345 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.2500e-05\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.9571 - precision: 0.9841 - recall: 0.9254 - f1_score: 0.9538\n",
            "Epoch 104: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2837 - accuracy: 0.9571 - precision: 0.9841 - recall: 0.9254 - f1_score: 0.9538 - val_loss: 0.9717 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.2500e-05\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.9500 - precision: 0.9167 - recall: 0.9851 - f1_score: 0.9496\n",
            "Epoch 105: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.3357 - accuracy: 0.9500 - precision: 0.9167 - recall: 0.9851 - f1_score: 0.9496 - val_loss: 0.8995 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.2500e-05\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.9571 - precision: 0.9692 - recall: 0.9403 - f1_score: 0.9545\n",
            "Epoch 106: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 138ms/step - loss: 0.3254 - accuracy: 0.9571 - precision: 0.9692 - recall: 0.9403 - f1_score: 0.9545 - val_loss: 0.8701 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.9429 - precision: 0.9275 - recall: 0.9552 - f1_score: 0.9412\n",
            "Epoch 107: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2922 - accuracy: 0.9429 - precision: 0.9275 - recall: 0.9552 - f1_score: 0.9412 - val_loss: 0.8030 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552\n",
            "Epoch 108: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2772 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552 - val_loss: 0.7716 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778\n",
            "Epoch 109: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.2611 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778 - val_loss: 0.7862 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565\n",
            "Epoch 110: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2769 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565 - val_loss: 0.8510 - val_accuracy: 0.8667 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.8824 - lr: 1.0000e-05\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565\n",
            "Epoch 111: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.3118 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565 - val_loss: 0.9117 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552\n",
            "Epoch 112: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 0.2834 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552 - val_loss: 0.8988 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 113: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.2475 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 0.7881 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.9500 - precision: 0.9286 - recall: 0.9701 - f1_score: 0.9489\n",
            "Epoch 114: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2626 - accuracy: 0.9500 - precision: 0.9286 - recall: 0.9701 - f1_score: 0.9489 - val_loss: 0.6996 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.9429 - precision: 0.9155 - recall: 0.9701 - f1_score: 0.9420\n",
            "Epoch 115: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 0.3215 - accuracy: 0.9429 - precision: 0.9155 - recall: 0.9701 - f1_score: 0.9420 - val_loss: 0.7655 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697\n",
            "Epoch 116: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2586 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697 - val_loss: 0.8449 - val_accuracy: 0.8000 - val_precision: 0.9231 - val_recall: 0.7059 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697\n",
            "Epoch 117: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2504 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697 - val_loss: 0.7153 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630\n",
            "Epoch 118: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.2812 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630 - val_loss: 0.6874 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559\n",
            "Epoch 119: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.3174 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559 - val_loss: 0.7327 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 120: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2292 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 0.8011 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.9357 - precision: 0.9677 - recall: 0.8955 - f1_score: 0.9302\n",
            "Epoch 121: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.2768 - accuracy: 0.9357 - precision: 0.9677 - recall: 0.8955 - f1_score: 0.9302 - val_loss: 0.7476 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565\n",
            "Epoch 122: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.2593 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565 - val_loss: 0.6679 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2663 - accuracy: 0.9643 - precision: 0.9306 - recall: 1.0000 - f1_score: 0.9640\n",
            "Epoch 123: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2663 - accuracy: 0.9643 - precision: 0.9306 - recall: 1.0000 - f1_score: 0.9640 - val_loss: 0.6532 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9403 - f1_score: 0.9692\n",
            "Epoch 124: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.2565 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9403 - f1_score: 0.9692 - val_loss: 0.6882 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9403 - f1_score: 0.9692\n",
            "Epoch 125: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.2595 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9403 - f1_score: 0.9692 - val_loss: 0.6673 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.9714 - precision: 0.9437 - recall: 1.0000 - f1_score: 0.9710\n",
            "Epoch 126: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2596 - accuracy: 0.9714 - precision: 0.9437 - recall: 1.0000 - f1_score: 0.9710 - val_loss: 0.7495 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2309 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926\n",
            "Epoch 127: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2309 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926 - val_loss: 0.8842 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 128/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925\n",
            "Epoch 128: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.2496 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925 - val_loss: 0.8902 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 129/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 129: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2344 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 0.8676 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 130/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.9357 - precision: 0.9028 - recall: 0.9701 - f1_score: 0.9353\n",
            "Epoch 130: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.2929 - accuracy: 0.9357 - precision: 0.9028 - recall: 0.9701 - f1_score: 0.9353 - val_loss: 0.9170 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 131/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853\n",
            "Epoch 131: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.2199 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853 - val_loss: 1.0316 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 132/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9552 - f1_score: 0.9771\n",
            "Epoch 132: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2202 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9552 - f1_score: 0.9771 - val_loss: 1.1046 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 133/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774\n",
            "Epoch 133: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2311 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774 - val_loss: 1.0213 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 134/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9714 - precision: 0.9437 - recall: 1.0000 - f1_score: 0.9710\n",
            "Epoch 134: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2178 - accuracy: 0.9714 - precision: 0.9437 - recall: 1.0000 - f1_score: 0.9710 - val_loss: 0.9449 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 135/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618\n",
            "Epoch 135: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2525 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618 - val_loss: 0.9298 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 136/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618\n",
            "Epoch 136: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 129ms/step - loss: 0.2541 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618 - val_loss: 0.8377 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 137/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624\n",
            "Epoch 137: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2311 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624 - val_loss: 0.8734 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 138/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.9500 - precision: 0.9167 - recall: 0.9851 - f1_score: 0.9496\n",
            "Epoch 138: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2918 - accuracy: 0.9500 - precision: 0.9167 - recall: 0.9851 - f1_score: 0.9496 - val_loss: 0.9167 - val_accuracy: 0.8667 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.8824 - lr: 1.0000e-05\n",
            "Epoch 139/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 139: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.2149 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 0.9480 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 140/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 140: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2621 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 0.9656 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 141/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.9500 - precision: 1.0000 - recall: 0.8955 - f1_score: 0.9449\n",
            "Epoch 141: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.3060 - accuracy: 0.9500 - precision: 1.0000 - recall: 0.8955 - f1_score: 0.9449 - val_loss: 0.7860 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 142/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926\n",
            "Epoch 142: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2166 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926 - val_loss: 0.6765 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 143/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2538 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706\n",
            "Epoch 143: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 0.2538 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706 - val_loss: 0.7239 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 144/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853\n",
            "Epoch 144: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2175 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853 - val_loss: 0.8103 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 145/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.9429 - precision: 0.9155 - recall: 0.9701 - f1_score: 0.9420\n",
            "Epoch 145: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2797 - accuracy: 0.9429 - precision: 0.9155 - recall: 0.9701 - f1_score: 0.9420 - val_loss: 0.8866 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 146/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.9571 - precision: 1.0000 - recall: 0.9104 - f1_score: 0.9531\n",
            "Epoch 146: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 127ms/step - loss: 0.2479 - accuracy: 0.9571 - precision: 1.0000 - recall: 0.9104 - f1_score: 0.9531 - val_loss: 0.9501 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 147/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624\n",
            "Epoch 147: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2331 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624 - val_loss: 0.8974 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 148/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781\n",
            "Epoch 148: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2579 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781 - val_loss: 0.8369 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 149/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9714 - precision: 0.9437 - recall: 1.0000 - f1_score: 0.9710\n",
            "Epoch 149: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 135ms/step - loss: 0.2322 - accuracy: 0.9714 - precision: 0.9437 - recall: 1.0000 - f1_score: 0.9710 - val_loss: 0.8146 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 150/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9701 - f1_score: 0.9848\n",
            "Epoch 150: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2235 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9701 - f1_score: 0.9848 - val_loss: 0.8389 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 151/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.9500 - precision: 0.9286 - recall: 0.9701 - f1_score: 0.9489\n",
            "Epoch 151: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2517 - accuracy: 0.9500 - precision: 0.9286 - recall: 0.9701 - f1_score: 0.9489 - val_loss: 0.7960 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 152/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 152: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 0.2620 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 0.7907 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 153/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706\n",
            "Epoch 153: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.2199 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706 - val_loss: 0.8802 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 154/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853\n",
            "Epoch 154: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.1999 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853 - val_loss: 1.0513 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.0000e-05\n",
            "Epoch 155/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1876 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 155: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.1876 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 1.1338 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 156/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9571 - precision: 0.9692 - recall: 0.9403 - f1_score: 0.9545\n",
            "Epoch 156: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2465 - accuracy: 0.9571 - precision: 0.9692 - recall: 0.9403 - f1_score: 0.9545 - val_loss: 0.9903 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 157/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781\n",
            "Epoch 157: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2299 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781 - val_loss: 0.9264 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 158/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 158: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.1931 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 1.0151 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 159/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9643 - precision: 1.0000 - recall: 0.9254 - f1_score: 0.9612\n",
            "Epoch 159: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 134ms/step - loss: 0.2602 - accuracy: 0.9643 - precision: 1.0000 - recall: 0.9254 - f1_score: 0.9612 - val_loss: 1.0498 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 160/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774\n",
            "Epoch 160: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2314 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774 - val_loss: 0.9342 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 161/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2281 - accuracy: 0.9714 - precision: 0.9437 - recall: 1.0000 - f1_score: 0.9710\n",
            "Epoch 161: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2281 - accuracy: 0.9714 - precision: 0.9437 - recall: 1.0000 - f1_score: 0.9710 - val_loss: 0.9636 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 162/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 162: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.2260 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 0.9614 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 163/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 163: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2761 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 0.8319 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 164/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630\n",
            "Epoch 164: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2486 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630 - val_loss: 0.7702 - val_accuracy: 0.8667 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.8824 - lr: 1.0000e-05\n",
            "Epoch 165/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559\n",
            "Epoch 165: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.2323 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559 - val_loss: 0.8343 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 166/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 166: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2178 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 0.9466 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 167/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774\n",
            "Epoch 167: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2151 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774 - val_loss: 0.8888 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 168/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778\n",
            "Epoch 168: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.2849 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778 - val_loss: 0.8663 - val_accuracy: 0.8667 - val_precision: 0.8824 - val_recall: 0.8824 - val_f1_score: 0.8824 - lr: 1.0000e-05\n",
            "Epoch 169/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565\n",
            "Epoch 169: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.2749 - accuracy: 0.9571 - precision: 0.9296 - recall: 0.9851 - f1_score: 0.9565 - val_loss: 0.8150 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 170/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925\n",
            "Epoch 170: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.1864 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925 - val_loss: 0.8657 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 171/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697\n",
            "Epoch 171: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.2347 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697 - val_loss: 0.9212 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 172/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853\n",
            "Epoch 172: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.1906 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853 - val_loss: 0.9551 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 173/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630\n",
            "Epoch 173: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2346 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630 - val_loss: 0.9161 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 174/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618\n",
            "Epoch 174: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.2407 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618 - val_loss: 0.8345 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 175/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697\n",
            "Epoch 175: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2171 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697 - val_loss: 0.8087 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 176/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 176: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2011 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 0.8372 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 177/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559\n",
            "Epoch 177: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.2912 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559 - val_loss: 0.7508 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 178/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926\n",
            "Epoch 178: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.1919 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926 - val_loss: 0.6668 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 179/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624\n",
            "Epoch 179: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.2440 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624 - val_loss: 0.6879 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 180/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2399 - accuracy: 0.9500 - precision: 0.9167 - recall: 0.9851 - f1_score: 0.9496\n",
            "Epoch 180: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2399 - accuracy: 0.9500 - precision: 0.9167 - recall: 0.9851 - f1_score: 0.9496 - val_loss: 0.7323 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 181/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706\n",
            "Epoch 181: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2272 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706 - val_loss: 0.8487 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 182/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9552 - f1_score: 0.9771\n",
            "Epoch 182: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2001 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9552 - f1_score: 0.9771 - val_loss: 0.9750 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 183/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774\n",
            "Epoch 183: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.2021 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774 - val_loss: 0.9375 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 184/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701\n",
            "Epoch 184: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.2176 - accuracy: 0.9714 - precision: 0.9701 - recall: 0.9701 - f1_score: 0.9701 - val_loss: 0.8638 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 185/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926\n",
            "Epoch 185: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2005 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926 - val_loss: 0.8414 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 186/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774\n",
            "Epoch 186: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.2060 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774 - val_loss: 0.9449 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 187/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552\n",
            "Epoch 187: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.2715 - accuracy: 0.9571 - precision: 0.9552 - recall: 0.9552 - f1_score: 0.9552 - val_loss: 0.9664 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 188/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.9500 - precision: 0.9286 - recall: 0.9701 - f1_score: 0.9489\n",
            "Epoch 188: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.2916 - accuracy: 0.9500 - precision: 0.9286 - recall: 0.9701 - f1_score: 0.9489 - val_loss: 0.9825 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 189/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697\n",
            "Epoch 189: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.2066 - accuracy: 0.9714 - precision: 0.9846 - recall: 0.9552 - f1_score: 0.9697 - val_loss: 0.9370 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 190/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9571 - precision: 0.9841 - recall: 0.9254 - f1_score: 0.9538\n",
            "Epoch 190: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.2385 - accuracy: 0.9571 - precision: 0.9841 - recall: 0.9254 - f1_score: 0.9538 - val_loss: 0.7787 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 191/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 191: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.1978 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 0.6943 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 192/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781\n",
            "Epoch 192: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.1994 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781 - val_loss: 0.6922 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 193/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.9429 - precision: 0.9275 - recall: 0.9552 - f1_score: 0.9412\n",
            "Epoch 193: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.2380 - accuracy: 0.9429 - precision: 0.9275 - recall: 0.9552 - f1_score: 0.9412 - val_loss: 0.7957 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 194/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926\n",
            "Epoch 194: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.1949 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926 - val_loss: 0.8611 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 195/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2391 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618\n",
            "Epoch 195: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2391 - accuracy: 0.9643 - precision: 0.9844 - recall: 0.9403 - f1_score: 0.9618 - val_loss: 0.8671 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 196/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781\n",
            "Epoch 196: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.2129 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781 - val_loss: 0.8905 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 197/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774\n",
            "Epoch 197: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.1970 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774 - val_loss: 0.9355 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 198/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778\n",
            "Epoch 198: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.1917 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778 - val_loss: 0.8940 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 199/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853\n",
            "Epoch 199: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.1896 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853 - val_loss: 1.0344 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 200/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774\n",
            "Epoch 200: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.2115 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774 - val_loss: 0.9795 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 201/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774\n",
            "Epoch 201: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.2050 - accuracy: 0.9786 - precision: 0.9848 - recall: 0.9701 - f1_score: 0.9774 - val_loss: 0.8968 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 202/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706\n",
            "Epoch 202: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2183 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706 - val_loss: 0.8549 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 203/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 203: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.1784 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 0.8026 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 204/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926\n",
            "Epoch 204: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.1792 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926 - val_loss: 0.7727 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 205/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 205: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.1770 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8461 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 206/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778\n",
            "Epoch 206: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.2126 - accuracy: 0.9786 - precision: 0.9706 - recall: 0.9851 - f1_score: 0.9778 - val_loss: 0.8618 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 207/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9500 - precision: 0.9839 - recall: 0.9104 - f1_score: 0.9457\n",
            "Epoch 207: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.2349 - accuracy: 0.9500 - precision: 0.9839 - recall: 0.9104 - f1_score: 0.9457 - val_loss: 0.8068 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 208/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853\n",
            "Epoch 208: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.1899 - accuracy: 0.9857 - precision: 0.9710 - recall: 1.0000 - f1_score: 0.9853 - val_loss: 0.8083 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 209/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706\n",
            "Epoch 209: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.2349 - accuracy: 0.9714 - precision: 0.9565 - recall: 0.9851 - f1_score: 0.9706 - val_loss: 0.7421 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 210/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.9571 - precision: 0.9178 - recall: 1.0000 - f1_score: 0.9571\n",
            "Epoch 210: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.2547 - accuracy: 0.9571 - precision: 0.9178 - recall: 1.0000 - f1_score: 0.9571 - val_loss: 0.7228 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 211/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624\n",
            "Epoch 211: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.2045 - accuracy: 0.9643 - precision: 0.9697 - recall: 0.9552 - f1_score: 0.9624 - val_loss: 0.7594 - val_accuracy: 0.8333 - val_precision: 0.9286 - val_recall: 0.7647 - val_f1_score: 0.8387 - lr: 1.0000e-05\n",
            "Epoch 212/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925\n",
            "Epoch 212: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1735 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925 - val_loss: 0.6907 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 213/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559\n",
            "Epoch 213: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.2371 - accuracy: 0.9571 - precision: 0.9420 - recall: 0.9701 - f1_score: 0.9559 - val_loss: 0.7240 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 214/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 214: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.1832 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 0.8143 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 215/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925\n",
            "Epoch 215: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.1749 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925 - val_loss: 0.8733 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 216/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 216: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.1694 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.9138 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 217/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926\n",
            "Epoch 217: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.1734 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926 - val_loss: 0.9016 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 218/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630\n",
            "Epoch 218: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.2327 - accuracy: 0.9643 - precision: 0.9559 - recall: 0.9701 - f1_score: 0.9630 - val_loss: 0.9186 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 219/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925\n",
            "Epoch 219: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.1759 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9851 - f1_score: 0.9925 - val_loss: 0.8534 - val_accuracy: 0.9333 - val_precision: 0.9412 - val_recall: 0.9412 - val_f1_score: 0.9412 - lr: 1.0000e-05\n",
            "Epoch 220/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926\n",
            "Epoch 220: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.2196 - accuracy: 0.9929 - precision: 0.9853 - recall: 1.0000 - f1_score: 0.9926 - val_loss: 0.9071 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 221/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851\n",
            "Epoch 221: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.2167 - accuracy: 0.9857 - precision: 0.9851 - recall: 0.9851 - f1_score: 0.9851 - val_loss: 1.0053 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.8235 - val_f1_score: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 222/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.9643 - precision: 0.9429 - recall: 0.9851 - f1_score: 0.9635\n",
            "Epoch 222: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2376 - accuracy: 0.9643 - precision: 0.9429 - recall: 0.9851 - f1_score: 0.9635 - val_loss: 0.8743 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 223/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2088 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781\n",
            "Epoch 223: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2088 - accuracy: 0.9786 - precision: 0.9571 - recall: 1.0000 - f1_score: 0.9781 - val_loss: 0.7448 - val_accuracy: 0.9000 - val_precision: 0.9375 - val_recall: 0.8824 - val_f1_score: 0.9091 - lr: 1.0000e-05\n",
            "Epoch 223: early stopping\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.9871 - accuracy: 0.8333 - precision: 0.9231 - recall: 0.7500 - f1_score: 0.8276\n",
            "\n",
            "############# Fold n°9 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.5304 - accuracy: 0.5412 - precision: 0.5376 - recall: 0.5882 - f1_score: 0.5618\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 6s 122ms/step - loss: 2.5304 - accuracy: 0.5412 - precision: 0.5376 - recall: 0.5882 - f1_score: 0.5618 - val_loss: 2.2611 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.0315 - accuracy: 0.4929 - precision: 0.4762 - recall: 0.2899 - f1_score: 0.3604\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 2.0315 - accuracy: 0.4929 - precision: 0.4762 - recall: 0.2899 - f1_score: 0.3604 - val_loss: 1.7956 - val_accuracy: 0.6333 - val_precision: 0.8333 - val_recall: 0.3333 - val_f1_score: 0.4762 - lr: 1.0000e-04\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.6101 - accuracy: 0.5786 - precision: 0.5714 - recall: 0.5797 - f1_score: 0.5755\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 1.6101 - accuracy: 0.5786 - precision: 0.5714 - recall: 0.5797 - f1_score: 0.5755 - val_loss: 1.4272 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.3128 - accuracy: 0.5429 - precision: 0.5532 - recall: 0.3768 - f1_score: 0.4483\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 1.3128 - accuracy: 0.5429 - precision: 0.5532 - recall: 0.3768 - f1_score: 0.4483 - val_loss: 1.1964 - val_accuracy: 0.5333 - val_precision: 0.5185 - val_recall: 0.9333 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.1302 - accuracy: 0.5714 - precision: 0.5421 - recall: 0.8406 - f1_score: 0.6591\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 1.1302 - accuracy: 0.5714 - precision: 0.5421 - recall: 0.8406 - f1_score: 0.6591 - val_loss: 1.0667 - val_accuracy: 0.6667 - val_precision: 0.7273 - val_recall: 0.5333 - val_f1_score: 0.6154 - lr: 1.0000e-04\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0379 - accuracy: 0.6714 - precision: 0.6769 - recall: 0.6377 - f1_score: 0.6567\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 1.0379 - accuracy: 0.6714 - precision: 0.6769 - recall: 0.6377 - f1_score: 0.6567 - val_loss: 1.0278 - val_accuracy: 0.6333 - val_precision: 0.6667 - val_recall: 0.5333 - val_f1_score: 0.5926 - lr: 1.0000e-04\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9679 - accuracy: 0.6643 - precision: 0.6964 - recall: 0.5652 - f1_score: 0.6240\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.9679 - accuracy: 0.6643 - precision: 0.6964 - recall: 0.5652 - f1_score: 0.6240 - val_loss: 0.9818 - val_accuracy: 0.5667 - val_precision: 0.5714 - val_recall: 0.5333 - val_f1_score: 0.5517 - lr: 1.0000e-04\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9317 - accuracy: 0.6429 - precision: 0.6667 - recall: 0.5507 - f1_score: 0.6032\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.9317 - accuracy: 0.6429 - precision: 0.6667 - recall: 0.5507 - f1_score: 0.6032 - val_loss: 0.8826 - val_accuracy: 0.6667 - val_precision: 0.6923 - val_recall: 0.6000 - val_f1_score: 0.6429 - lr: 1.0000e-04\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8533 - accuracy: 0.6929 - precision: 0.6970 - recall: 0.6667 - f1_score: 0.6815\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 0.8533 - accuracy: 0.6929 - precision: 0.6970 - recall: 0.6667 - f1_score: 0.6815 - val_loss: 0.8264 - val_accuracy: 0.7000 - val_precision: 0.7500 - val_recall: 0.6000 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7758 - accuracy: 0.7357 - precision: 0.7667 - recall: 0.6667 - f1_score: 0.7132\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.7758 - accuracy: 0.7357 - precision: 0.7667 - recall: 0.6667 - f1_score: 0.7132 - val_loss: 0.7802 - val_accuracy: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_f1_score: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7473 - accuracy: 0.7357 - precision: 0.7759 - recall: 0.6522 - f1_score: 0.7087\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.7473 - accuracy: 0.7357 - precision: 0.7759 - recall: 0.6522 - f1_score: 0.7087 - val_loss: 0.7505 - val_accuracy: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_f1_score: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6867 - accuracy: 0.7357 - precision: 0.8077 - recall: 0.6087 - f1_score: 0.6942\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.6867 - accuracy: 0.7357 - precision: 0.8077 - recall: 0.6087 - f1_score: 0.6942 - val_loss: 0.7487 - val_accuracy: 0.7000 - val_precision: 0.6667 - val_recall: 0.8000 - val_f1_score: 0.7273 - lr: 1.0000e-04\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.8000 - precision: 0.8060 - recall: 0.7826 - f1_score: 0.7941\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.6773 - accuracy: 0.8000 - precision: 0.8060 - recall: 0.7826 - f1_score: 0.7941 - val_loss: 0.6874 - val_accuracy: 0.7667 - val_precision: 0.8333 - val_recall: 0.6667 - val_f1_score: 0.7407 - lr: 1.0000e-04\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6432 - accuracy: 0.8357 - precision: 0.8382 - recall: 0.8261 - f1_score: 0.8321\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.6432 - accuracy: 0.8357 - precision: 0.8382 - recall: 0.8261 - f1_score: 0.8321 - val_loss: 0.7900 - val_accuracy: 0.6667 - val_precision: 0.8571 - val_recall: 0.4000 - val_f1_score: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.8214 - precision: 0.8548 - recall: 0.7681 - f1_score: 0.8092\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.6050 - accuracy: 0.8214 - precision: 0.8548 - recall: 0.7681 - f1_score: 0.8092 - val_loss: 0.6457 - val_accuracy: 0.8000 - val_precision: 0.8462 - val_recall: 0.7333 - val_f1_score: 0.7857 - lr: 1.0000e-04\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5877 - accuracy: 0.8500 - precision: 0.8636 - recall: 0.8261 - f1_score: 0.8444\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.5877 - accuracy: 0.8500 - precision: 0.8636 - recall: 0.8261 - f1_score: 0.8444 - val_loss: 0.6822 - val_accuracy: 0.7667 - val_precision: 0.8333 - val_recall: 0.6667 - val_f1_score: 0.7407 - lr: 1.0000e-04\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.8929 - precision: 0.9500 - recall: 0.8261 - f1_score: 0.8837\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.5003 - accuracy: 0.8929 - precision: 0.9500 - recall: 0.8261 - f1_score: 0.8837 - val_loss: 0.6338 - val_accuracy: 0.8333 - val_precision: 0.8125 - val_recall: 0.8667 - val_f1_score: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.9000 - precision: 0.9104 - recall: 0.8841 - f1_score: 0.8971\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.4972 - accuracy: 0.9000 - precision: 0.9104 - recall: 0.8841 - f1_score: 0.8971 - val_loss: 0.9069 - val_accuracy: 0.7333 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4967 - accuracy: 0.9071 - precision: 0.9118 - recall: 0.8986 - f1_score: 0.9051\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.4967 - accuracy: 0.9071 - precision: 0.9118 - recall: 0.8986 - f1_score: 0.9051 - val_loss: 0.8056 - val_accuracy: 0.8000 - val_precision: 0.8462 - val_recall: 0.7333 - val_f1_score: 0.7857 - lr: 1.0000e-04\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.9071 - precision: 0.9242 - recall: 0.8841 - f1_score: 0.9037\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.5635 - accuracy: 0.9071 - precision: 0.9242 - recall: 0.8841 - f1_score: 0.9037 - val_loss: 0.5808 - val_accuracy: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.9000 - precision: 0.8873 - recall: 0.9130 - f1_score: 0.9000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.5136 - accuracy: 0.9000 - precision: 0.8873 - recall: 0.9130 - f1_score: 0.9000 - val_loss: 0.8230 - val_accuracy: 0.7667 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200 - lr: 1.0000e-04\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5403 - accuracy: 0.8857 - precision: 0.8732 - recall: 0.8986 - f1_score: 0.8857\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.5403 - accuracy: 0.8857 - precision: 0.8732 - recall: 0.8986 - f1_score: 0.8857 - val_loss: 0.5726 - val_accuracy: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_f1_score: 0.8966 - lr: 1.0000e-04\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.9357 - precision: 0.9545 - recall: 0.9130 - f1_score: 0.9333\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.4573 - accuracy: 0.9357 - precision: 0.9545 - recall: 0.9130 - f1_score: 0.9333 - val_loss: 0.6559 - val_accuracy: 0.8000 - val_precision: 0.9091 - val_recall: 0.6667 - val_f1_score: 0.7692 - lr: 1.0000e-04\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4420 - accuracy: 0.9286 - precision: 0.9275 - recall: 0.9275 - f1_score: 0.9275\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.4420 - accuracy: 0.9286 - precision: 0.9275 - recall: 0.9275 - f1_score: 0.9275 - val_loss: 1.0104 - val_accuracy: 0.7333 - val_precision: 1.0000 - val_recall: 0.4667 - val_f1_score: 0.6364 - lr: 1.0000e-04\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.9000 - precision: 0.9104 - recall: 0.8841 - f1_score: 0.8971\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.5143 - accuracy: 0.9000 - precision: 0.9104 - recall: 0.8841 - f1_score: 0.8971 - val_loss: 0.8922 - val_accuracy: 0.7333 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.9143 - precision: 0.8904 - recall: 0.9420 - f1_score: 0.9155\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.4388 - accuracy: 0.9143 - precision: 0.8904 - recall: 0.9420 - f1_score: 0.9155 - val_loss: 0.4864 - val_accuracy: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_f1_score: 0.8966 - lr: 1.0000e-04\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.9643 - precision: 0.9706 - recall: 0.9565 - f1_score: 0.9635\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.3859 - accuracy: 0.9643 - precision: 0.9706 - recall: 0.9565 - f1_score: 0.9635 - val_loss: 0.8463 - val_accuracy: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_f1_score: 0.6957 - lr: 1.0000e-04\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.9500 - precision: 0.9429 - recall: 0.9565 - f1_score: 0.9496\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.5114 - accuracy: 0.9500 - precision: 0.9429 - recall: 0.9565 - f1_score: 0.9496 - val_loss: 0.9924 - val_accuracy: 0.7667 - val_precision: 1.0000 - val_recall: 0.5333 - val_f1_score: 0.6957 - lr: 1.0000e-04\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.9143 - precision: 0.9254 - recall: 0.8986 - f1_score: 0.9118\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.5280 - accuracy: 0.9143 - precision: 0.9254 - recall: 0.8986 - f1_score: 0.9118 - val_loss: 0.5371 - val_accuracy: 0.8667 - val_precision: 0.9231 - val_recall: 0.8000 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.9214 - precision: 0.9143 - recall: 0.9275 - f1_score: 0.9209\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.4388 - accuracy: 0.9214 - precision: 0.9143 - recall: 0.9275 - f1_score: 0.9209 - val_loss: 0.5881 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-04\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.9500 - precision: 0.9429 - recall: 0.9565 - f1_score: 0.9496\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.4279 - accuracy: 0.9500 - precision: 0.9429 - recall: 0.9565 - f1_score: 0.9496 - val_loss: 0.5481 - val_accuracy: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_f1_score: 0.8966 - lr: 1.0000e-04\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.9429 - precision: 0.9420 - recall: 0.9420 - f1_score: 0.9420\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.4451 - accuracy: 0.9429 - precision: 0.9420 - recall: 0.9420 - f1_score: 0.9420 - val_loss: 0.5518 - val_accuracy: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148 - lr: 1.0000e-04\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.9714 - precision: 0.9851 - recall: 0.9565 - f1_score: 0.9706\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.3505 - accuracy: 0.9714 - precision: 0.9851 - recall: 0.9565 - f1_score: 0.9706 - val_loss: 0.5412 - val_accuracy: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_f1_score: 0.8966 - lr: 1.0000e-04\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.3428 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710 - val_loss: 0.4400 - val_accuracy: 0.9667 - val_precision: 0.9375 - val_recall: 1.0000 - val_f1_score: 0.9677 - lr: 1.0000e-04\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.9429 - precision: 0.9552 - recall: 0.9275 - f1_score: 0.9412\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.3970 - accuracy: 0.9429 - precision: 0.9552 - recall: 0.9275 - f1_score: 0.9412 - val_loss: 0.5914 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.9571 - precision: 0.9701 - recall: 0.9420 - f1_score: 0.9559\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.3767 - accuracy: 0.9571 - precision: 0.9701 - recall: 0.9420 - f1_score: 0.9559 - val_loss: 0.5895 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.9286 - precision: 0.9155 - recall: 0.9420 - f1_score: 0.9286\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.3775 - accuracy: 0.9286 - precision: 0.9155 - recall: 0.9420 - f1_score: 0.9286 - val_loss: 0.6316 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.3411 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710 - val_loss: 0.5653 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.9786 - precision: 0.9714 - recall: 0.9855 - f1_score: 0.9784\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.3055 - accuracy: 0.9786 - precision: 0.9714 - recall: 0.9855 - f1_score: 0.9784 - val_loss: 0.8141 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.3263 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710 - val_loss: 0.5624 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.9571 - precision: 0.9846 - recall: 0.9275 - f1_score: 0.9552\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.2944 - accuracy: 0.9571 - precision: 0.9846 - recall: 0.9275 - f1_score: 0.9552 - val_loss: 0.5212 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-04\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.9571 - precision: 0.9565 - recall: 0.9565 - f1_score: 0.9565\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.2934 - accuracy: 0.9571 - precision: 0.9565 - recall: 0.9565 - f1_score: 0.9565 - val_loss: 0.5534 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3078 - accuracy: 0.9643 - precision: 0.9444 - recall: 0.9855 - f1_score: 0.9645\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.3078 - accuracy: 0.9643 - precision: 0.9444 - recall: 0.9855 - f1_score: 0.9645 - val_loss: 0.4374 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-04\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.9500 - precision: 0.9559 - recall: 0.9420 - f1_score: 0.9489\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.3077 - accuracy: 0.9500 - precision: 0.9559 - recall: 0.9420 - f1_score: 0.9489 - val_loss: 0.5300 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-04\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.9429 - precision: 0.9420 - recall: 0.9420 - f1_score: 0.9420\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.3322 - accuracy: 0.9429 - precision: 0.9420 - recall: 0.9420 - f1_score: 0.9420 - val_loss: 0.3561 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.9429 - precision: 0.9296 - recall: 0.9565 - f1_score: 0.9429\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.3114 - accuracy: 0.9429 - precision: 0.9296 - recall: 0.9565 - f1_score: 0.9429 - val_loss: 0.2990 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.9786 - precision: 0.9853 - recall: 0.9710 - f1_score: 0.9781\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.2767 - accuracy: 0.9786 - precision: 0.9853 - recall: 0.9710 - f1_score: 0.9781 - val_loss: 0.2798 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-04\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.9643 - precision: 0.9571 - recall: 0.9710 - f1_score: 0.9640\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2720 - accuracy: 0.9643 - precision: 0.9571 - recall: 0.9710 - f1_score: 0.9640 - val_loss: 0.2660 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-04\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.9500 - precision: 0.9697 - recall: 0.9275 - f1_score: 0.9481\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.4146 - accuracy: 0.9500 - precision: 0.9697 - recall: 0.9275 - f1_score: 0.9481 - val_loss: 0.3583 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-04\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.9571 - precision: 0.9565 - recall: 0.9565 - f1_score: 0.9565\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.3038 - accuracy: 0.9571 - precision: 0.9565 - recall: 0.9565 - f1_score: 0.9565 - val_loss: 0.4156 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 5.0000e-05\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2351 - accuracy: 0.9643 - precision: 0.9706 - recall: 0.9565 - f1_score: 0.9635\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.2351 - accuracy: 0.9643 - precision: 0.9706 - recall: 0.9565 - f1_score: 0.9635 - val_loss: 0.4453 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 5.0000e-05\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.2294 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 0.4485 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 5.0000e-05\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.9643 - precision: 0.9571 - recall: 0.9710 - f1_score: 0.9640\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.2641 - accuracy: 0.9643 - precision: 0.9571 - recall: 0.9710 - f1_score: 0.9640 - val_loss: 0.4210 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 5.0000e-05\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.2235 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710 - val_loss: 0.4972 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 5.0000e-05\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.9714 - precision: 0.9851 - recall: 0.9565 - f1_score: 0.9706\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.2492 - accuracy: 0.9714 - precision: 0.9851 - recall: 0.9565 - f1_score: 0.9706 - val_loss: 0.4548 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 5.0000e-05\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.2164 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710 - val_loss: 0.3448 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 5.0000e-05\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.9571 - precision: 0.9315 - recall: 0.9855 - f1_score: 0.9577\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.2708 - accuracy: 0.9571 - precision: 0.9315 - recall: 0.9855 - f1_score: 0.9577 - val_loss: 0.2429 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 5.0000e-05\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.9643 - precision: 1.0000 - recall: 0.9275 - f1_score: 0.9624\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2355 - accuracy: 0.9643 - precision: 1.0000 - recall: 0.9275 - f1_score: 0.9624 - val_loss: 0.2769 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 5.0000e-05\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.2282 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.2752 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 5.0000e-05\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1793 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.5571 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 5.0000e-05\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.9643 - precision: 0.9706 - recall: 0.9565 - f1_score: 0.9635\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2233 - accuracy: 0.9643 - precision: 0.9706 - recall: 0.9565 - f1_score: 0.9635 - val_loss: 0.3649 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 5.0000e-05\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.9643 - precision: 0.9571 - recall: 0.9710 - f1_score: 0.9640\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.2100 - accuracy: 0.9643 - precision: 0.9571 - recall: 0.9710 - f1_score: 0.9640 - val_loss: 0.4350 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 5.0000e-05\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9643 - precision: 0.9848 - recall: 0.9420 - f1_score: 0.9630\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.2182 - accuracy: 0.9643 - precision: 0.9848 - recall: 0.9420 - f1_score: 0.9630 - val_loss: 0.3608 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 5.0000e-05\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1730 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 0.2524 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 5.0000e-05\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.1886 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.5102 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 2.5000e-05\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9420 - f1_score: 0.9701\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.1742 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9420 - f1_score: 0.9701 - val_loss: 0.2634 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 2.5000e-05\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1709 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.2614 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 2.5000e-05\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.1405 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7137 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 2.5000e-05\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.1484 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.6310 - val_accuracy: 0.8333 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148 - lr: 2.5000e-05\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.1255 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_f1_score: 0.8966 - lr: 2.5000e-05\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.1881 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 1.3221 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 2.5000e-05\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9565 - f1_score: 0.9778\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.1763 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9565 - f1_score: 0.9778 - val_loss: 0.5271 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 2.5000e-05\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.1303 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 2.5000e-05\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1433 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 0.4415 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 2.5000e-05\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 0.1238 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 2.5000e-05\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.1487 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 0.3140 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 2.5000e-05\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.1523 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.5299 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 2.5000e-05\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.1289 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.7911 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 2.5000e-05\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.1115 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_f1_score: 0.8966 - lr: 2.5000e-05\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.1231 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.4142 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 1.2500e-05\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.1320 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 0.3809 - val_accuracy: 0.9000 - val_precision: 0.9286 - val_recall: 0.8667 - val_f1_score: 0.8966 - lr: 1.2500e-05\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.1079 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.2500e-05\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.1622 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 0.6336 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.2500e-05\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.1616 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.4508 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.2500e-05\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 134ms/step - loss: 0.1217 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.6303 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.2500e-05\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.1192 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.5043 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.2500e-05\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1369 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.4650 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.2500e-05\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.1050 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5853 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.2500e-05\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.1049 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6506 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.2500e-05\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 90: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.1244 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 0.5378 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.2500e-05\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 91: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.1022 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.6081 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.2500e-05\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 92: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.1083 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.5819 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.2500e-05\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 93: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.1015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.2500e-05\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 94: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1042 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5115 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.2500e-05\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 95: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.0955 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7375 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 96: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1029 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5395 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 97: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.0928 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 98: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.0896 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5879 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 99: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0884 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7703 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 100: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0903 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 101: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.1074 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.4191 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 102: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0957 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.4863 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 103: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.0858 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 104: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0908 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.9992 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 105: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0950 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.7795 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 106: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.0856 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 107: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.0842 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 108: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.0967 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 1.0390 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 109: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.1032 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 0.8106 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 110: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.0848 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 111: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0888 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5256 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 112: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.0810 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 113: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.0824 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 114: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8134 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9565 - f1_score: 0.9778\n",
            "Epoch 115: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.1101 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9565 - f1_score: 0.9778 - val_loss: 0.4783 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 116: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 135ms/step - loss: 0.1157 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 0.3852 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9786 - precision: 0.9583 - recall: 1.0000 - f1_score: 0.9787\n",
            "Epoch 117: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.1035 - accuracy: 0.9786 - precision: 0.9583 - recall: 1.0000 - f1_score: 0.9787 - val_loss: 0.5157 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 118: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0793 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7769 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 119: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.0998 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 0.6898 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 120: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.0952 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.3706 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 121: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.1243 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.4802 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 122: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.0948 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 0.7874 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 123: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.0952 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.4350 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 124: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1288 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.2040 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9714 - precision: 0.9452 - recall: 1.0000 - f1_score: 0.9718\n",
            "Epoch 125: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.1689 - accuracy: 0.9714 - precision: 0.9452 - recall: 1.0000 - f1_score: 0.9718 - val_loss: 0.4226 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 126: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.0842 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.9191 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 127: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.1032 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 1.1787 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 128/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9420 - f1_score: 0.9701\n",
            "Epoch 128: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1430 - accuracy: 0.9714 - precision: 1.0000 - recall: 0.9420 - f1_score: 0.9701 - val_loss: 0.6997 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 129/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 129: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.0816 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 130/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 130: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1002 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.3243 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 131/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 131: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.1440 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.4967 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 132/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 132: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 127ms/step - loss: 0.0845 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8195 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 133/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 133: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1297 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 0.9892 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 134/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 134: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.0952 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.6307 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 135/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 135: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0882 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.4026 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 136/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 136: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0972 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.4671 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 137/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 137: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.0788 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 138/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 138: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.0795 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 1.0349 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 139/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 139: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0832 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 140/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 140: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.0795 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.3551 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 141/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 141: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.0945 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5370 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 142/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 142: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 143/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 143: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0874 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.4498 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 144/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 144: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.0881 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.3406 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 145/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 145: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0830 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5031 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 146/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 146: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 147/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 147: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.0744 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 148/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 148: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.0868 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.4800 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1_score: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 149/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9786 - precision: 0.9714 - recall: 0.9855 - f1_score: 0.9784\n",
            "Epoch 149: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.1145 - accuracy: 0.9786 - precision: 0.9714 - recall: 0.9855 - f1_score: 0.9784 - val_loss: 0.7095 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 150/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 150: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.1065 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 1.2122 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 151/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 151: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.1277 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 1.1977 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 152/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 152: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.0775 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6497 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 153/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 153: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0816 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.3803 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 154/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 154: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.0898 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.3908 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 155/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 155: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 156/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 156: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.0905 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 0.7974 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 157/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 157: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0944 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5113 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 158/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 158: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.0893 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.3465 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 159/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 159: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.0867 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.4506 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 160/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 160: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0858 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.7402 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 161/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 161: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.0714 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 1.0812 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 162/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 162: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 0.0851 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.6548 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 163/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 163: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.0759 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 164/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9714 - precision: 0.9452 - recall: 1.0000 - f1_score: 0.9718\n",
            "Epoch 164: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.1423 - accuracy: 0.9714 - precision: 0.9452 - recall: 1.0000 - f1_score: 0.9718 - val_loss: 0.2307 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 165/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 165: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 137ms/step - loss: 0.0827 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5252 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 166/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 166: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0685 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.9883 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 167/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 167: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0918 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 1.0408 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 168/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 168: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.0772 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6541 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 169/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 169: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.0685 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286 - lr: 1.0000e-05\n",
            "Epoch 170/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 170: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0789 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5994 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 171/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 171: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.0654 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8990 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 172/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 172: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0671 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.9108 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 173/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 173: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0706 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.5564 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 174/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 174: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 0.0792 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5595 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 175/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 175: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0973 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.7580 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 176/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 176: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0648 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5887 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 177/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 177: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.0676 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 178/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 178: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0647 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 179/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 179: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0689 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6566 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 180/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.0609 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 1.1155 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 181/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 181: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1053 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 0.7669 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 182/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 182: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0668 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.4255 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 183/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 183: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 0.0915 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.3550 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 184/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 184: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0645 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6603 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 185/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 185: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.0918 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 1.0351 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 186/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 135ms/step - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 187/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 187: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0645 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6359 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 188/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 188: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0690 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.6117 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 189/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 189: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6165 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 190/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 190: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.0635 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 191/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 191: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0699 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6217 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 192/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 192: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0580 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 193/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 193: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.0582 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 194/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 194: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0593 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 195/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9786 - precision: 0.9583 - recall: 1.0000 - f1_score: 0.9787\n",
            "Epoch 195: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.0952 - accuracy: 0.9786 - precision: 0.9583 - recall: 1.0000 - f1_score: 0.9787 - val_loss: 0.6568 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 196/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 196: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 137ms/step - loss: 0.0735 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 1.0709 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 197/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 197: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0875 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.8855 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 198/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 198: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0570 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6072 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 199/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 199: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 129ms/step - loss: 0.0583 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 200/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 200: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.0691 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.5868 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 201/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 201: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0610 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8808 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 202/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 202: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.0634 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.7878 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 203/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 203: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.0641 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6314 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 204/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 204: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0563 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 205/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 205: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.0726 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.5988 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 206/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 206: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.0636 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 207/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 207: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.0661 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.8722 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 208/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 208: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.0550 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 209/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 209: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.0772 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.4573 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 210/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 210: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0911 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 0.8571 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 211/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 211: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0596 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 1.2954 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 212/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9565 - f1_score: 0.9778\n",
            "Epoch 212: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.1235 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9565 - f1_score: 0.9778 - val_loss: 1.3468 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 213/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 213: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.1186 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 0.6956 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 214/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 214: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0734 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.3973 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 215/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9786 - precision: 0.9583 - recall: 1.0000 - f1_score: 0.9787\n",
            "Epoch 215: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.1203 - accuracy: 0.9786 - precision: 0.9583 - recall: 1.0000 - f1_score: 0.9787 - val_loss: 0.4520 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 216/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 216: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.0677 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8377 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 217/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 217: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0615 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 1.1816 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 218/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9565 - f1_score: 0.9778\n",
            "Epoch 218: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1298 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9565 - f1_score: 0.9778 - val_loss: 0.9442 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 219/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 219: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.0663 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 220/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 220: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0816 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 0.3644 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 221/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 221: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0674 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 0.3955 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655 - lr: 1.0000e-05\n",
            "Epoch 222/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 222: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 139ms/step - loss: 0.0610 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 223/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 223: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.0625 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.8267 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 224/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 224: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0768 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 0.7381 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462 - lr: 1.0000e-05\n",
            "Epoch 224: early stopping\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.1385 - accuracy: 0.9667 - precision: 1.0000 - recall: 0.9375 - f1_score: 0.9677\n",
            "\n",
            "############# Fold n°10 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.5016 - accuracy: 0.6118 - precision: 0.6180 - recall: 0.6322 - f1_score: 0.6250\n",
            "Epoch 1: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 7s 133ms/step - loss: 2.5016 - accuracy: 0.6118 - precision: 0.6180 - recall: 0.6322 - f1_score: 0.6250 - val_loss: 2.2338 - val_accuracy: 0.5333 - val_precision: 0.4545 - val_recall: 0.3846 - val_f1_score: 0.4167 - lr: 1.0000e-04\n",
            "Epoch 2/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 2.0067 - accuracy: 0.5643 - precision: 0.5490 - recall: 0.7887 - f1_score: 0.6474\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 2.0067 - accuracy: 0.5643 - precision: 0.5490 - recall: 0.7887 - f1_score: 0.6474 - val_loss: 1.7812 - val_accuracy: 0.4333 - val_precision: 0.4091 - val_recall: 0.6923 - val_f1_score: 0.5143 - lr: 1.0000e-04\n",
            "Epoch 3/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.5974 - accuracy: 0.5857 - precision: 0.5699 - recall: 0.7465 - f1_score: 0.6463\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 137ms/step - loss: 1.5974 - accuracy: 0.5857 - precision: 0.5699 - recall: 0.7465 - f1_score: 0.6463 - val_loss: 1.4309 - val_accuracy: 0.4667 - val_precision: 0.4286 - val_recall: 0.6923 - val_f1_score: 0.5294 - lr: 1.0000e-04\n",
            "Epoch 4/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.2882 - accuracy: 0.5857 - precision: 0.5802 - recall: 0.6620 - f1_score: 0.6184\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 1.2882 - accuracy: 0.5857 - precision: 0.5802 - recall: 0.6620 - f1_score: 0.6184 - val_loss: 1.2022 - val_accuracy: 0.4667 - val_precision: 0.4118 - val_recall: 0.5385 - val_f1_score: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 5/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.1323 - accuracy: 0.6143 - precision: 0.6349 - recall: 0.5634 - f1_score: 0.5970\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 1.1323 - accuracy: 0.6143 - precision: 0.6349 - recall: 0.5634 - f1_score: 0.5970 - val_loss: 1.0642 - val_accuracy: 0.6667 - val_precision: 0.7143 - val_recall: 0.3846 - val_f1_score: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 6/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0191 - accuracy: 0.6714 - precision: 0.6923 - recall: 0.6338 - f1_score: 0.6618\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 1.0191 - accuracy: 0.6714 - precision: 0.6923 - recall: 0.6338 - f1_score: 0.6618 - val_loss: 1.0729 - val_accuracy: 0.6667 - val_precision: 0.7143 - val_recall: 0.3846 - val_f1_score: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 7/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.0586 - accuracy: 0.6429 - precision: 0.6780 - recall: 0.5634 - f1_score: 0.6154\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 1.0586 - accuracy: 0.6429 - precision: 0.6780 - recall: 0.5634 - f1_score: 0.6154 - val_loss: 1.0092 - val_accuracy: 0.4667 - val_precision: 0.4000 - val_recall: 0.4615 - val_f1_score: 0.4286 - lr: 1.0000e-04\n",
            "Epoch 8/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.9150 - accuracy: 0.6429 - precision: 0.6329 - recall: 0.7042 - f1_score: 0.6667\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.9150 - accuracy: 0.6429 - precision: 0.6329 - recall: 0.7042 - f1_score: 0.6667 - val_loss: 0.9769 - val_accuracy: 0.5000 - val_precision: 0.4375 - val_recall: 0.5385 - val_f1_score: 0.4828 - lr: 1.0000e-04\n",
            "Epoch 9/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.8637 - accuracy: 0.6643 - precision: 0.7069 - recall: 0.5775 - f1_score: 0.6357\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 134ms/step - loss: 0.8637 - accuracy: 0.6643 - precision: 0.7069 - recall: 0.5775 - f1_score: 0.6357 - val_loss: 0.9455 - val_accuracy: 0.5333 - val_precision: 0.4615 - val_recall: 0.4615 - val_f1_score: 0.4615 - lr: 1.0000e-04\n",
            "Epoch 10/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7851 - accuracy: 0.7071 - precision: 0.7273 - recall: 0.6761 - f1_score: 0.7007\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.7851 - accuracy: 0.7071 - precision: 0.7273 - recall: 0.6761 - f1_score: 0.7007 - val_loss: 0.8863 - val_accuracy: 0.6667 - val_precision: 0.8000 - val_recall: 0.3077 - val_f1_score: 0.4444 - lr: 1.0000e-04\n",
            "Epoch 11/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7515 - accuracy: 0.7071 - precision: 0.7344 - recall: 0.6620 - f1_score: 0.6963\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.7515 - accuracy: 0.7071 - precision: 0.7344 - recall: 0.6620 - f1_score: 0.6963 - val_loss: 0.9331 - val_accuracy: 0.6333 - val_precision: 0.6250 - val_recall: 0.3846 - val_f1_score: 0.4762 - lr: 1.0000e-04\n",
            "Epoch 12/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.7571 - precision: 0.8364 - recall: 0.6479 - f1_score: 0.7302\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 136ms/step - loss: 0.7339 - accuracy: 0.7571 - precision: 0.8364 - recall: 0.6479 - f1_score: 0.7302 - val_loss: 0.9389 - val_accuracy: 0.6333 - val_precision: 0.6250 - val_recall: 0.3846 - val_f1_score: 0.4762 - lr: 1.0000e-04\n",
            "Epoch 13/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7636 - accuracy: 0.6857 - precision: 0.7143 - recall: 0.6338 - f1_score: 0.6716\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.7636 - accuracy: 0.6857 - precision: 0.7143 - recall: 0.6338 - f1_score: 0.6716 - val_loss: 0.8960 - val_accuracy: 0.6333 - val_precision: 0.6250 - val_recall: 0.3846 - val_f1_score: 0.4762 - lr: 1.0000e-04\n",
            "Epoch 14/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7300 - accuracy: 0.7429 - precision: 0.8070 - recall: 0.6479 - f1_score: 0.7188\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.7300 - accuracy: 0.7429 - precision: 0.8070 - recall: 0.6479 - f1_score: 0.7188 - val_loss: 0.9797 - val_accuracy: 0.5333 - val_precision: 0.4706 - val_recall: 0.6154 - val_f1_score: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 15/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7041 - accuracy: 0.7286 - precision: 0.7324 - recall: 0.7324 - f1_score: 0.7324\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.7041 - accuracy: 0.7286 - precision: 0.7324 - recall: 0.7324 - f1_score: 0.7324 - val_loss: 0.9767 - val_accuracy: 0.5000 - val_precision: 0.4444 - val_recall: 0.6154 - val_f1_score: 0.5161 - lr: 1.0000e-04\n",
            "Epoch 16/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.7304 - accuracy: 0.7714 - precision: 0.8305 - recall: 0.6901 - f1_score: 0.7538\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.7304 - accuracy: 0.7714 - precision: 0.8305 - recall: 0.6901 - f1_score: 0.7538 - val_loss: 0.8370 - val_accuracy: 0.6667 - val_precision: 0.6154 - val_recall: 0.6154 - val_f1_score: 0.6154 - lr: 1.0000e-04\n",
            "Epoch 17/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6199 - accuracy: 0.8429 - precision: 0.8551 - recall: 0.8310 - f1_score: 0.8429\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.6199 - accuracy: 0.8429 - precision: 0.8551 - recall: 0.8310 - f1_score: 0.8429 - val_loss: 0.8963 - val_accuracy: 0.7000 - val_precision: 0.6429 - val_recall: 0.6923 - val_f1_score: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 18/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.8286 - precision: 0.8406 - recall: 0.8169 - f1_score: 0.8286\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.6564 - accuracy: 0.8286 - precision: 0.8406 - recall: 0.8169 - f1_score: 0.8286 - val_loss: 0.8150 - val_accuracy: 0.6333 - val_precision: 0.5556 - val_recall: 0.7692 - val_f1_score: 0.6452 - lr: 1.0000e-04\n",
            "Epoch 19/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5968 - accuracy: 0.8571 - precision: 0.8696 - recall: 0.8451 - f1_score: 0.8571\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.5968 - accuracy: 0.8571 - precision: 0.8696 - recall: 0.8451 - f1_score: 0.8571 - val_loss: 0.7874 - val_accuracy: 0.7333 - val_precision: 0.6667 - val_recall: 0.7692 - val_f1_score: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 20/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5938 - accuracy: 0.8500 - precision: 0.8472 - recall: 0.8592 - f1_score: 0.8531\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.5938 - accuracy: 0.8500 - precision: 0.8472 - recall: 0.8592 - f1_score: 0.8531 - val_loss: 0.7772 - val_accuracy: 0.7000 - val_precision: 0.6111 - val_recall: 0.8462 - val_f1_score: 0.7097 - lr: 1.0000e-04\n",
            "Epoch 21/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.8786 - precision: 0.8750 - recall: 0.8873 - f1_score: 0.8811\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.5141 - accuracy: 0.8786 - precision: 0.8750 - recall: 0.8873 - f1_score: 0.8811 - val_loss: 0.6778 - val_accuracy: 0.7333 - val_precision: 0.6471 - val_recall: 0.8462 - val_f1_score: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 22/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4993 - accuracy: 0.8857 - precision: 0.8767 - recall: 0.9014 - f1_score: 0.8889\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.4993 - accuracy: 0.8857 - precision: 0.8767 - recall: 0.9014 - f1_score: 0.8889 - val_loss: 0.7045 - val_accuracy: 0.8000 - val_precision: 0.8889 - val_recall: 0.6154 - val_f1_score: 0.7273 - lr: 1.0000e-04\n",
            "Epoch 23/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.9214 - precision: 0.9545 - recall: 0.8873 - f1_score: 0.9197\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.5390 - accuracy: 0.9214 - precision: 0.9545 - recall: 0.8873 - f1_score: 0.9197 - val_loss: 0.5904 - val_accuracy: 0.8333 - val_precision: 0.7857 - val_recall: 0.8462 - val_f1_score: 0.8148 - lr: 1.0000e-04\n",
            "Epoch 24/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.8929 - precision: 0.8889 - recall: 0.9014 - f1_score: 0.8951\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.5194 - accuracy: 0.8929 - precision: 0.8889 - recall: 0.9014 - f1_score: 0.8951 - val_loss: 0.5360 - val_accuracy: 0.8333 - val_precision: 0.8333 - val_recall: 0.7692 - val_f1_score: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 25/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.9000 - precision: 0.9130 - recall: 0.8873 - f1_score: 0.9000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 127ms/step - loss: 0.5112 - accuracy: 0.9000 - precision: 0.9130 - recall: 0.8873 - f1_score: 0.9000 - val_loss: 0.7200 - val_accuracy: 0.8000 - val_precision: 0.7333 - val_recall: 0.8462 - val_f1_score: 0.7857 - lr: 1.0000e-04\n",
            "Epoch 26/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5151 - accuracy: 0.8857 - precision: 0.8986 - recall: 0.8732 - f1_score: 0.8857\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.5151 - accuracy: 0.8857 - precision: 0.8986 - recall: 0.8732 - f1_score: 0.8857 - val_loss: 0.7821 - val_accuracy: 0.7667 - val_precision: 0.6875 - val_recall: 0.8462 - val_f1_score: 0.7586 - lr: 1.0000e-04\n",
            "Epoch 27/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.9286 - precision: 0.9552 - recall: 0.9014 - f1_score: 0.9275\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.4150 - accuracy: 0.9286 - precision: 0.9552 - recall: 0.9014 - f1_score: 0.9275 - val_loss: 0.6359 - val_accuracy: 0.8667 - val_precision: 0.8462 - val_recall: 0.8462 - val_f1_score: 0.8462 - lr: 1.0000e-04\n",
            "Epoch 28/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.9429 - precision: 0.9315 - recall: 0.9577 - f1_score: 0.9444\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.4301 - accuracy: 0.9429 - precision: 0.9315 - recall: 0.9577 - f1_score: 0.9444 - val_loss: 0.4436 - val_accuracy: 0.8667 - val_precision: 0.8462 - val_recall: 0.8462 - val_f1_score: 0.8462 - lr: 1.0000e-04\n",
            "Epoch 29/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.9357 - precision: 0.9429 - recall: 0.9296 - f1_score: 0.9362\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.4418 - accuracy: 0.9357 - precision: 0.9429 - recall: 0.9296 - f1_score: 0.9362 - val_loss: 0.5479 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 30/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.8857 - precision: 0.8986 - recall: 0.8732 - f1_score: 0.8857\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.5671 - accuracy: 0.8857 - precision: 0.8986 - recall: 0.8732 - f1_score: 0.8857 - val_loss: 0.7173 - val_accuracy: 0.7667 - val_precision: 0.6875 - val_recall: 0.8462 - val_f1_score: 0.7586 - lr: 1.0000e-04\n",
            "Epoch 31/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.9143 - precision: 0.9041 - recall: 0.9296 - f1_score: 0.9167\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.4397 - accuracy: 0.9143 - precision: 0.9041 - recall: 0.9296 - f1_score: 0.9167 - val_loss: 0.5832 - val_accuracy: 0.8667 - val_precision: 0.8462 - val_recall: 0.8462 - val_f1_score: 0.8462 - lr: 1.0000e-04\n",
            "Epoch 32/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.9214 - precision: 0.9167 - recall: 0.9296 - f1_score: 0.9231\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.4371 - accuracy: 0.9214 - precision: 0.9167 - recall: 0.9296 - f1_score: 0.9231 - val_loss: 0.7379 - val_accuracy: 0.8000 - val_precision: 0.7333 - val_recall: 0.8462 - val_f1_score: 0.7857 - lr: 1.0000e-04\n",
            "Epoch 33/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.9357 - precision: 0.9559 - recall: 0.9155 - f1_score: 0.9353\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.4577 - accuracy: 0.9357 - precision: 0.9559 - recall: 0.9155 - f1_score: 0.9353 - val_loss: 0.5864 - val_accuracy: 0.9000 - val_precision: 0.9167 - val_recall: 0.8462 - val_f1_score: 0.8800 - lr: 1.0000e-04\n",
            "Epoch 34/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.9429 - precision: 0.9200 - recall: 0.9718 - f1_score: 0.9452\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 0.3979 - accuracy: 0.9429 - precision: 0.9200 - recall: 0.9718 - f1_score: 0.9452 - val_loss: 0.4736 - val_accuracy: 0.9000 - val_precision: 0.9167 - val_recall: 0.8462 - val_f1_score: 0.8800 - lr: 1.0000e-04\n",
            "Epoch 35/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.9429 - precision: 0.9315 - recall: 0.9577 - f1_score: 0.9444\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.4360 - accuracy: 0.9429 - precision: 0.9315 - recall: 0.9577 - f1_score: 0.9444 - val_loss: 0.4996 - val_accuracy: 0.9000 - val_precision: 0.8125 - val_recall: 1.0000 - val_f1_score: 0.8966 - lr: 1.0000e-04\n",
            "Epoch 36/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.9214 - precision: 0.9412 - recall: 0.9014 - f1_score: 0.9209\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.4518 - accuracy: 0.9214 - precision: 0.9412 - recall: 0.9014 - f1_score: 0.9209 - val_loss: 0.5213 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-04\n",
            "Epoch 37/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.9429 - precision: 0.9437 - recall: 0.9437 - f1_score: 0.9437\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.4872 - accuracy: 0.9429 - precision: 0.9437 - recall: 0.9437 - f1_score: 0.9437 - val_loss: 0.6513 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 38/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.9357 - precision: 0.9559 - recall: 0.9155 - f1_score: 0.9353\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.4600 - accuracy: 0.9357 - precision: 0.9559 - recall: 0.9155 - f1_score: 0.9353 - val_loss: 0.7438 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 39/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.9071 - precision: 0.8816 - recall: 0.9437 - f1_score: 0.9116\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.5281 - accuracy: 0.9071 - precision: 0.8816 - recall: 0.9437 - f1_score: 0.9116 - val_loss: 0.6843 - val_accuracy: 0.9000 - val_precision: 0.9167 - val_recall: 0.8462 - val_f1_score: 0.8800 - lr: 1.0000e-04\n",
            "Epoch 40/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5307 - accuracy: 0.9143 - precision: 0.9538 - recall: 0.8732 - f1_score: 0.9118\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.5307 - accuracy: 0.9143 - precision: 0.9538 - recall: 0.8732 - f1_score: 0.9118 - val_loss: 0.5826 - val_accuracy: 0.8000 - val_precision: 0.7333 - val_recall: 0.8462 - val_f1_score: 0.7857 - lr: 1.0000e-04\n",
            "Epoch 41/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.9429 - precision: 0.9315 - recall: 0.9577 - f1_score: 0.9444\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.4716 - accuracy: 0.9429 - precision: 0.9315 - recall: 0.9577 - f1_score: 0.9444 - val_loss: 0.5885 - val_accuracy: 0.8000 - val_precision: 0.7333 - val_recall: 0.8462 - val_f1_score: 0.7857 - lr: 1.0000e-04\n",
            "Epoch 42/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4178 - accuracy: 0.9429 - precision: 0.9437 - recall: 0.9437 - f1_score: 0.9437\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.4178 - accuracy: 0.9429 - precision: 0.9437 - recall: 0.9437 - f1_score: 0.9437 - val_loss: 0.5856 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 43/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.9571 - precision: 0.9710 - recall: 0.9437 - f1_score: 0.9571\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.4002 - accuracy: 0.9571 - precision: 0.9710 - recall: 0.9437 - f1_score: 0.9571 - val_loss: 0.6764 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 44/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3950 - accuracy: 0.9571 - precision: 0.9452 - recall: 0.9718 - f1_score: 0.9583\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.3950 - accuracy: 0.9571 - precision: 0.9452 - recall: 0.9718 - f1_score: 0.9583 - val_loss: 0.4424 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-04\n",
            "Epoch 45/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.9500 - precision: 0.9324 - recall: 0.9718 - f1_score: 0.9517\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.4605 - accuracy: 0.9500 - precision: 0.9324 - recall: 0.9718 - f1_score: 0.9517 - val_loss: 0.6479 - val_accuracy: 0.9000 - val_precision: 0.9167 - val_recall: 0.8462 - val_f1_score: 0.8800 - lr: 1.0000e-04\n",
            "Epoch 46/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.9429 - precision: 0.9315 - recall: 0.9577 - f1_score: 0.9444\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.4465 - accuracy: 0.9429 - precision: 0.9315 - recall: 0.9577 - f1_score: 0.9444 - val_loss: 0.7390 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 47/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.9357 - precision: 0.9697 - recall: 0.9014 - f1_score: 0.9343\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.4048 - accuracy: 0.9357 - precision: 0.9697 - recall: 0.9014 - f1_score: 0.9343 - val_loss: 0.6510 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 48/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.9357 - precision: 0.9306 - recall: 0.9437 - f1_score: 0.9371\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.4096 - accuracy: 0.9357 - precision: 0.9306 - recall: 0.9437 - f1_score: 0.9371 - val_loss: 0.5653 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 49/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.9643 - precision: 0.9583 - recall: 0.9718 - f1_score: 0.9650\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.3812 - accuracy: 0.9643 - precision: 0.9583 - recall: 0.9718 - f1_score: 0.9650 - val_loss: 0.6459 - val_accuracy: 0.8333 - val_precision: 0.7500 - val_recall: 0.9231 - val_f1_score: 0.8276 - lr: 1.0000e-04\n",
            "Epoch 50/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.9500 - precision: 0.9444 - recall: 0.9577 - f1_score: 0.9510\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.3911 - accuracy: 0.9500 - precision: 0.9444 - recall: 0.9577 - f1_score: 0.9510 - val_loss: 0.6925 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 51/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3529 - accuracy: 0.9714 - precision: 0.9589 - recall: 0.9859 - f1_score: 0.9722\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.3529 - accuracy: 0.9714 - precision: 0.9589 - recall: 0.9859 - f1_score: 0.9722 - val_loss: 0.5458 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 52/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.9571 - precision: 0.9333 - recall: 0.9859 - f1_score: 0.9589\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.3550 - accuracy: 0.9571 - precision: 0.9333 - recall: 0.9859 - f1_score: 0.9589 - val_loss: 0.4274 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 5.0000e-05\n",
            "Epoch 53/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.2819 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 5.0000e-05\n",
            "Epoch 54/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.9571 - precision: 0.9577 - recall: 0.9577 - f1_score: 0.9577\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 0.4021 - accuracy: 0.9571 - precision: 0.9577 - recall: 0.9577 - f1_score: 0.9577 - val_loss: 0.5637 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.7692 - val_f1_score: 0.8696 - lr: 5.0000e-05\n",
            "Epoch 55/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.9571 - precision: 0.9851 - recall: 0.9296 - f1_score: 0.9565\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.3926 - accuracy: 0.9571 - precision: 0.9851 - recall: 0.9296 - f1_score: 0.9565 - val_loss: 0.3989 - val_accuracy: 0.9667 - val_precision: 0.9286 - val_recall: 1.0000 - val_f1_score: 0.9630 - lr: 5.0000e-05\n",
            "Epoch 56/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.9714 - precision: 0.9855 - recall: 0.9577 - f1_score: 0.9714\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.3203 - accuracy: 0.9714 - precision: 0.9855 - recall: 0.9577 - f1_score: 0.9714 - val_loss: 0.3715 - val_accuracy: 0.9667 - val_precision: 0.9286 - val_recall: 1.0000 - val_f1_score: 0.9630 - lr: 5.0000e-05\n",
            "Epoch 57/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.2904 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790 - val_loss: 0.5112 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 5.0000e-05\n",
            "Epoch 58/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.2770 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5636 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 5.0000e-05\n",
            "Epoch 59/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.9357 - precision: 0.9306 - recall: 0.9437 - f1_score: 0.9371\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.3806 - accuracy: 0.9357 - precision: 0.9306 - recall: 0.9437 - f1_score: 0.9371 - val_loss: 0.6148 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 5.0000e-05\n",
            "Epoch 60/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2788 - accuracy: 0.9714 - precision: 0.9855 - recall: 0.9577 - f1_score: 0.9714\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.2788 - accuracy: 0.9714 - precision: 0.9855 - recall: 0.9577 - f1_score: 0.9714 - val_loss: 0.4523 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 5.0000e-05\n",
            "Epoch 61/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.9786 - precision: 0.9857 - recall: 0.9718 - f1_score: 0.9787\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.2699 - accuracy: 0.9786 - precision: 0.9857 - recall: 0.9718 - f1_score: 0.9787 - val_loss: 0.4247 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 5.0000e-05\n",
            "Epoch 62/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2423 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.4402 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 5.0000e-05\n",
            "Epoch 63/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.9714 - precision: 0.9718 - recall: 0.9718 - f1_score: 0.9718\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.2458 - accuracy: 0.9714 - precision: 0.9718 - recall: 0.9718 - f1_score: 0.9718 - val_loss: 0.4999 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 5.0000e-05\n",
            "Epoch 64/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.9500 - precision: 0.9706 - recall: 0.9296 - f1_score: 0.9496\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.2676 - accuracy: 0.9500 - precision: 0.9706 - recall: 0.9296 - f1_score: 0.9496 - val_loss: 0.6464 - val_accuracy: 0.8333 - val_precision: 0.7500 - val_recall: 0.9231 - val_f1_score: 0.8276 - lr: 5.0000e-05\n",
            "Epoch 65/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.9643 - precision: 0.9583 - recall: 0.9718 - f1_score: 0.9650\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.2693 - accuracy: 0.9643 - precision: 0.9583 - recall: 0.9718 - f1_score: 0.9650 - val_loss: 0.6874 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8462 - val_f1_score: 0.9167 - lr: 5.0000e-05\n",
            "Epoch 66/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.2164 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857 - val_loss: 0.4049 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 5.0000e-05\n",
            "Epoch 67/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9643 - precision: 0.9459 - recall: 0.9859 - f1_score: 0.9655\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2503 - accuracy: 0.9643 - precision: 0.9459 - recall: 0.9859 - f1_score: 0.9655 - val_loss: 0.4174 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 5.0000e-05\n",
            "Epoch 68/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.2225 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.5188 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 5.0000e-05\n",
            "Epoch 69/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2009 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.2009 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4320 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 5.0000e-05\n",
            "Epoch 70/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9714 - precision: 0.9718 - recall: 0.9718 - f1_score: 0.9718\n",
            "Epoch 70: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.2341 - accuracy: 0.9714 - precision: 0.9718 - recall: 0.9718 - f1_score: 0.9718 - val_loss: 0.4314 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 5.0000e-05\n",
            "Epoch 71/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.1767 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 2.5000e-05\n",
            "Epoch 72/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.9643 - precision: 0.9853 - recall: 0.9437 - f1_score: 0.9640\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2283 - accuracy: 0.9643 - precision: 0.9853 - recall: 0.9437 - f1_score: 0.9640 - val_loss: 0.4291 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 2.5000e-05\n",
            "Epoch 73/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.2245 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790 - val_loss: 0.5552 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 2.5000e-05\n",
            "Epoch 74/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.1871 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857 - val_loss: 0.4949 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 2.5000e-05\n",
            "Epoch 75/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9786 - precision: 0.9595 - recall: 1.0000 - f1_score: 0.9793\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.2278 - accuracy: 0.9786 - precision: 0.9595 - recall: 1.0000 - f1_score: 0.9793 - val_loss: 0.4858 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 2.5000e-05\n",
            "Epoch 76/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.1915 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790 - val_loss: 0.5258 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 2.5000e-05\n",
            "Epoch 77/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.1728 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5456 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 2.5000e-05\n",
            "Epoch 78/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9786 - precision: 0.9857 - recall: 0.9718 - f1_score: 0.9787\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.2007 - accuracy: 0.9786 - precision: 0.9857 - recall: 0.9718 - f1_score: 0.9787 - val_loss: 0.5707 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 2.5000e-05\n",
            "Epoch 79/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.9786 - precision: 0.9595 - recall: 1.0000 - f1_score: 0.9793\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.2300 - accuracy: 0.9786 - precision: 0.9595 - recall: 1.0000 - f1_score: 0.9793 - val_loss: 0.5253 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 2.5000e-05\n",
            "Epoch 80/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1805 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857 - val_loss: 0.7617 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8462 - val_f1_score: 0.9167 - lr: 2.5000e-05\n",
            "Epoch 81/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.9643 - precision: 0.9853 - recall: 0.9437 - f1_score: 0.9640\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 137ms/step - loss: 0.2448 - accuracy: 0.9643 - precision: 0.9853 - recall: 0.9437 - f1_score: 0.9640 - val_loss: 0.5077 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 2.5000e-05\n",
            "Epoch 82/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9714 - precision: 0.9589 - recall: 0.9859 - f1_score: 0.9722\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.2161 - accuracy: 0.9714 - precision: 0.9589 - recall: 0.9859 - f1_score: 0.9722 - val_loss: 0.4509 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 2.5000e-05\n",
            "Epoch 83/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9857 - precision: 0.9859 - recall: 0.9859 - f1_score: 0.9859\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.1668 - accuracy: 0.9857 - precision: 0.9859 - recall: 0.9859 - f1_score: 0.9859 - val_loss: 0.4230 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 2.5000e-05\n",
            "Epoch 84/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.2034 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790 - val_loss: 0.3861 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 2.5000e-05\n",
            "Epoch 85/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9577 - f1_score: 0.9784\n",
            "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.2078 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9577 - f1_score: 0.9784 - val_loss: 0.4167 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 2.5000e-05\n",
            "Epoch 86/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.1521 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.2500e-05\n",
            "Epoch 87/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.1875 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.3560 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.2500e-05\n",
            "Epoch 88/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 130ms/step - loss: 0.1487 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.2500e-05\n",
            "Epoch 89/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.1683 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857 - val_loss: 0.4861 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.2500e-05\n",
            "Epoch 90/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 90: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.1452 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.2500e-05\n",
            "Epoch 91/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 91: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.1563 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.5125 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.2500e-05\n",
            "Epoch 92/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 92: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.1403 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5673 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.2500e-05\n",
            "Epoch 93/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 93: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.1311 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.2500e-05\n",
            "Epoch 94/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 94: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.1421 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5470 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.2500e-05\n",
            "Epoch 95/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 95: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.1275 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5658 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.2500e-05\n",
            "Epoch 96/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 96: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.1288 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.2500e-05\n",
            "Epoch 97/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 97: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.1577 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.6443 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.2500e-05\n",
            "Epoch 98/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9577 - f1_score: 0.9784\n",
            "Epoch 98: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.1713 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9577 - f1_score: 0.9784 - val_loss: 0.6391 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.2500e-05\n",
            "Epoch 99/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 99: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1292 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5216 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.2500e-05\n",
            "Epoch 100/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9857 - precision: 0.9859 - recall: 0.9859 - f1_score: 0.9859\n",
            "Epoch 100: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.1383 - accuracy: 0.9857 - precision: 0.9859 - recall: 0.9859 - f1_score: 0.9859 - val_loss: 0.5318 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.2500e-05\n",
            "Epoch 101/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 101: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.1534 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4997 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 102/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857\n",
            "Epoch 102: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.1435 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857 - val_loss: 0.5564 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 103/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 103: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.1284 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.4998 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 104/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 104: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.1191 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 105/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 105: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.1279 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 106/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 106: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.1235 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5221 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 107/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790\n",
            "Epoch 107: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 135ms/step - loss: 0.1402 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790 - val_loss: 0.6149 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8462 - val_f1_score: 0.9167 - lr: 1.0000e-05\n",
            "Epoch 108/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9577 - f1_score: 0.9784\n",
            "Epoch 108: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.1451 - accuracy: 0.9786 - precision: 1.0000 - recall: 0.9577 - f1_score: 0.9784 - val_loss: 0.4807 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 109/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 109: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.1156 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 110/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 110: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 137ms/step - loss: 0.1299 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5617 - val_accuracy: 0.9000 - val_precision: 0.8125 - val_recall: 1.0000 - val_f1_score: 0.8966 - lr: 1.0000e-05\n",
            "Epoch 111/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 111: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.1304 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.4250 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 112/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 112: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1107 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 113/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 113: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.1185 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.3676 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 114/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 114: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.1118 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 115/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 115: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1275 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4279 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 116/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 116: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.1184 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5544 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 117/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 117: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 125ms/step - loss: 0.1159 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 118/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 118: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.1075 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 119/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 119: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1203 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.3835 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 120/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 120: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 131ms/step - loss: 0.1155 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4188 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 121/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 121: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 127ms/step - loss: 0.1096 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 122/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 122: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.1021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5657 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 123/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 123: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.1062 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5412 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 124/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 124: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.1229 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.5461 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 125/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 125: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.1029 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 126/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857\n",
            "Epoch 126: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.1394 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857 - val_loss: 0.6119 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 127/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 127: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.1021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 128/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 128: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.1621 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.5825 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 129/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 129: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.1080 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5604 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 130/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 130: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.1060 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5268 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 131/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 131: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0963 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 132/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 132: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 0.1303 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4614 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 133/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 133: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 0.1037 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.4864 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 134/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 134: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0935 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 135/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 135: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 0.0953 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 136/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 136: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0950 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 137/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 137: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1343 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5745 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 138/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 138: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.0967 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5436 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 139/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790\n",
            "Epoch 139: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 124ms/step - loss: 0.1209 - accuracy: 0.9786 - precision: 0.9722 - recall: 0.9859 - f1_score: 0.9790 - val_loss: 0.5632 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 140/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 140: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.1008 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.6039 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 141/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9857 - precision: 0.9859 - recall: 0.9859 - f1_score: 0.9859\n",
            "Epoch 141: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.1116 - accuracy: 0.9857 - precision: 0.9859 - recall: 0.9859 - f1_score: 0.9859 - val_loss: 0.5555 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 142/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 142: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.0897 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 143/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 143: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.0908 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 144/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 144: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.0961 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4426 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 145/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 145: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0911 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 146/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 146: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.0995 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.4284 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 147/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 147: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.0986 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4334 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 148/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 148: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.0957 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5019 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 149/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857\n",
            "Epoch 149: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.1114 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857 - val_loss: 0.4566 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 150/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 150: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.1054 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4246 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 151/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 151: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 0.1337 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.4307 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 152/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 152: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.0955 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5371 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 153/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 153: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.1238 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.4213 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 154/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 154: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.0857 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 155/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 155: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 0.0923 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 156/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 156: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0884 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 157/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 157: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 0.0976 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.4168 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 158/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 158: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0937 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5363 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 159/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 159: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.1106 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.4731 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 160/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 160: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 126ms/step - loss: 0.0870 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.6328 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 161/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 161: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.1014 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5793 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 162/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 162: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 0.0967 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.4407 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 163/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 163: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 136ms/step - loss: 0.0946 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5203 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 164/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 164: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 116ms/step - loss: 0.0930 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4406 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 165/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 165: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.1121 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5343 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 166/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857\n",
            "Epoch 166: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 0.1471 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9718 - f1_score: 0.9857 - val_loss: 0.5626 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 167/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 167: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.0903 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4137 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 168/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 168: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0841 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.8667 - val_precision: 0.8000 - val_recall: 0.9231 - val_f1_score: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 169/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 169: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 132ms/step - loss: 0.1033 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4115 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 170/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 170: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0808 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 171/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 171: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.0988 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5036 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 172/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 172: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.0869 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 173/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 173: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 114ms/step - loss: 0.0866 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 174/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 174: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0974 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.4424 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 175/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 175: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 127ms/step - loss: 0.0943 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5144 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 176/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 176: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 122ms/step - loss: 0.0812 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 177/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 177: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 112ms/step - loss: 0.1368 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5102 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 178/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 178: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 0.0928 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5388 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 179/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 179: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 129ms/step - loss: 0.0982 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5063 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 180/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 180: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 113ms/step - loss: 0.0897 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 181/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861\n",
            "Epoch 181: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 111ms/step - loss: 0.0970 - accuracy: 0.9857 - precision: 0.9726 - recall: 1.0000 - f1_score: 0.9861 - val_loss: 0.4912 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 182/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 182: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 139ms/step - loss: 0.0822 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 183/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 183: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 121ms/step - loss: 0.0817 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.9333 - val_precision: 0.9231 - val_recall: 0.9231 - val_f1_score: 0.9231 - lr: 1.0000e-05\n",
            "Epoch 184/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930\n",
            "Epoch 184: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 110ms/step - loss: 0.0864 - accuracy: 0.9929 - precision: 0.9861 - recall: 1.0000 - f1_score: 0.9930 - val_loss: 0.5713 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 185/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929\n",
            "Epoch 185: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 128ms/step - loss: 0.1230 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9859 - f1_score: 0.9929 - val_loss: 0.5388 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9231 - val_f1_score: 0.9600 - lr: 1.0000e-05\n",
            "Epoch 186/250\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 186: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 119ms/step - loss: 0.0794 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.9000 - val_precision: 0.8571 - val_recall: 0.9231 - val_f1_score: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 186: early stopping\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.1125 - accuracy: 0.9667 - precision: 0.9412 - recall: 1.0000 - f1_score: 0.9697\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a2771a2e8c59>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainModelNumpyKfoldAugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaselineWithRegularization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-86186c127ec4>\u001b[0m in \u001b[0;36mtrainModelNumpyKfoldAugment\u001b[0;34m(givenModel, modelName)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m#plot acc and loss in function of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0mplotCurvesKfolding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgivenModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mplotCurvesKfolding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgivenModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-7c436eb360a0>\u001b[0m in \u001b[0;36mplotCurvesKfolding\u001b[0;34m(histories, ModelName)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Résultats/Entrainement/Kfold_Accuracy_and_loss_{ModelName}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Need this if 'transparent=True', to reset colors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3341\u001b[0m                         ax.patch._cm_set(facecolor='none', edgecolor='none'))\n\u001b[1;32m   3342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3345\u001b[0m     def ginput(self, n=1, timeout=30, show_clicks=True,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2364\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2366\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2367\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2368\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2230\u001b[0m                 \"bbox_inches_restore\"}\n\u001b[1;32m   2231\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptional_kws\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m             print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n\u001b[0m\u001b[1;32m   2233\u001b[0m                 *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n\u001b[1;32m   2234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Let third-parties do as they see fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \"\"\"\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \"\"\"\n\u001b[1;32m    457\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         mpl.image.imsave(\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2426\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Résultats/Entrainement/Kfold_Accuracy_and_loss_baselineWithRegularization.png'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainModelNumpyKfoldAugment(baselineWithRegularization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Yo5yxwQxBi"
      },
      "source": [
        "LSTM + Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iypaxHqshS_h"
      },
      "outputs": [],
      "source": [
        "#trainModelNumpyKfoldAugment(get_2d_conv_LSTM_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lL51-1lhVNH"
      },
      "outputs": [],
      "source": [
        "#trainModelNumpyKfoldAugment(get_2d_conv_LSTM_atten_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbPoSDLkyKqi"
      },
      "source": [
        "## Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEDtpdt93Ka_"
      },
      "source": [
        "Testing pretrained model without use transfert learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWuizPLC3HQy",
        "outputId": "8ce82ba8-ccfd-4554-95a9-f71f92fc1885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model VGG16 as a resolution input img :  (224, 224)\n",
            "For the class tiger, the accuracy is 84.00%\n",
            "The mean probability score for the correct predictions is 80.55455088615417 %\n",
            "The most frequently confused animal is fountain\n",
            "\n",
            "For the class elephant, the accuracy is 95.00%\n",
            "The mean probability score for the correct predictions is 53.52769494056702 %\n",
            "The most frequently confused animal is Arabian_camel\n",
            "\n",
            "For the class fox, the accuracy is 28.00%\n",
            "The mean probability score for the correct predictions is 40.16676843166351 %\n",
            "The most frequently confused animal is cliff\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "TestingAlreadyTrainedModel(VGG16) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JdesMcgtegM"
      },
      "source": [
        "Transfer learning (check model here : https://keras.io/api/applications/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNr-gjxLyduU"
      },
      "source": [
        "Testing the first architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyQDvfDFx0A0",
        "outputId": "08bd9499-dffb-458f-898e-bab0c7d67ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les classes :  ['tiger', 'Tiger_negative_class']\n",
            "Nombres de données :  200\n",
            "Résolution des images :  (256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "my_path=\"Tiger-Fox-Elephant/\"\n",
        "my_classes=['tiger','Tiger_negative_class']\n",
        "X, y = create_dataset(my_path, my_classes)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15, random_state=SEED) # .15 pour kfold et .3 pour normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ0Q-F9ajvwV"
      },
      "outputs": [],
      "source": [
        "trainModelNumpyKfoldAugment(TLModelArchi_1, VGG16) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N3GuKsyhH3"
      },
      "source": [
        "Testing the second architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJeOrewu678k"
      },
      "outputs": [],
      "source": [
        "trainModelNumpyKfoldAugment(TLModelArchi_2, VGG16) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDcjerlTy2mm"
      },
      "source": [
        "Testing with all model trainable parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LMRZKNRN5QV",
        "outputId": "4326c699-bc80-4276-cc62-8dce472f8993"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "############# Fold n°1 #############\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 16.5938 - accuracy: 0.5143 - precision: 0.5065 - recall: 0.5652 - f1_score: 0.5342\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53333, saving model to Saved_Model/TLModelArchi_2TrainableVGG16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 20s 297ms/step - loss: 16.5938 - accuracy: 0.5143 - precision: 0.5065 - recall: 0.5652 - f1_score: 0.5342 - val_loss: 16.3521 - val_accuracy: 0.5333 - val_precision: 0.5333 - val_recall: 1.0000 - val_f1_score: 0.6957 - lr: 1.0000e-05\n",
            "Epoch 2/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 16.3794 - accuracy: 0.5929 - precision: 0.5909 - recall: 0.5652 - f1_score: 0.5778\n",
            "Epoch 2: val_accuracy improved from 0.53333 to 0.76667, saving model to Saved_Model/TLModelArchi_2TrainableVGG16.h5\n",
            "35/35 [==============================] - 4s 118ms/step - loss: 16.3794 - accuracy: 0.5929 - precision: 0.5909 - recall: 0.5652 - f1_score: 0.5778 - val_loss: 16.0633 - val_accuracy: 0.7667 - val_precision: 1.0000 - val_recall: 0.5625 - val_f1_score: 0.7200 - lr: 1.0000e-05\n",
            "Epoch 3/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 16.0520 - accuracy: 0.8071 - precision: 0.8281 - recall: 0.7681 - f1_score: 0.7970\n",
            "Epoch 3: val_accuracy improved from 0.76667 to 1.00000, saving model to Saved_Model/TLModelArchi_2TrainableVGG16.h5\n",
            "35/35 [==============================] - 4s 115ms/step - loss: 16.0520 - accuracy: 0.8071 - precision: 0.8281 - recall: 0.7681 - f1_score: 0.7970 - val_loss: 15.6527 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 4/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 15.7855 - accuracy: 0.8500 - precision: 0.8429 - recall: 0.8551 - f1_score: 0.8489\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 142ms/step - loss: 15.7855 - accuracy: 0.8500 - precision: 0.8429 - recall: 0.8551 - f1_score: 0.8489 - val_loss: 15.6239 - val_accuracy: 0.9000 - val_precision: 0.8421 - val_recall: 1.0000 - val_f1_score: 0.9143 - lr: 1.0000e-05\n",
            "Epoch 5/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 15.5692 - accuracy: 0.9286 - precision: 0.9041 - recall: 0.9565 - f1_score: 0.9296\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 15.5692 - accuracy: 0.9286 - precision: 0.9041 - recall: 0.9565 - f1_score: 0.9296 - val_loss: 15.3300 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 6/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 15.4415 - accuracy: 0.9429 - precision: 0.9296 - recall: 0.9565 - f1_score: 0.9429\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 15.4415 - accuracy: 0.9429 - precision: 0.9296 - recall: 0.9565 - f1_score: 0.9429 - val_loss: 15.1897 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 7/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 15.2009 - accuracy: 0.9786 - precision: 0.9853 - recall: 0.9710 - f1_score: 0.9781\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 15.2009 - accuracy: 0.9786 - precision: 0.9853 - recall: 0.9710 - f1_score: 0.9781 - val_loss: 15.0789 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9375 - val_f1_score: 0.9677 - lr: 1.0000e-05\n",
            "Epoch 8/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 15.0897 - accuracy: 0.9786 - precision: 0.9853 - recall: 0.9710 - f1_score: 0.9781\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 146ms/step - loss: 15.0897 - accuracy: 0.9786 - precision: 0.9853 - recall: 0.9710 - f1_score: 0.9781 - val_loss: 14.9514 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9375 - val_f1_score: 0.9677 - lr: 1.0000e-05\n",
            "Epoch 9/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.9426 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 14.9426 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710 - val_loss: 14.7886 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.7554 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 14.7554 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 14.6918 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9375 - val_f1_score: 0.9677 - lr: 1.0000e-05\n",
            "Epoch 11/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.7765 - accuracy: 0.9571 - precision: 0.9701 - recall: 0.9420 - f1_score: 0.9559\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 133ms/step - loss: 14.7765 - accuracy: 0.9571 - precision: 0.9701 - recall: 0.9420 - f1_score: 0.9559 - val_loss: 14.5377 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 12/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.6431 - accuracy: 0.9571 - precision: 0.9437 - recall: 0.9710 - f1_score: 0.9571\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 14.6431 - accuracy: 0.9571 - precision: 0.9437 - recall: 0.9710 - f1_score: 0.9571 - val_loss: 14.4800 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 13/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.4349 - accuracy: 0.9786 - precision: 0.9714 - recall: 0.9855 - f1_score: 0.9784\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 14.4349 - accuracy: 0.9786 - precision: 0.9714 - recall: 0.9855 - f1_score: 0.9784 - val_loss: 14.3218 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 14/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.3170 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 140ms/step - loss: 14.3170 - accuracy: 0.9714 - precision: 0.9710 - recall: 0.9710 - f1_score: 0.9710 - val_loss: 14.2639 - val_accuracy: 0.9667 - val_precision: 1.0000 - val_recall: 0.9375 - val_f1_score: 0.9677 - lr: 1.0000e-05\n",
            "Epoch 15/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.1868 - accuracy: 0.9786 - precision: 0.9853 - recall: 0.9710 - f1_score: 0.9781\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 117ms/step - loss: 14.1868 - accuracy: 0.9786 - precision: 0.9853 - recall: 0.9710 - f1_score: 0.9781 - val_loss: 14.6391 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8125 - val_f1_score: 0.8966 - lr: 1.0000e-05\n",
            "Epoch 16/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.1088 - accuracy: 0.9643 - precision: 0.9571 - recall: 0.9710 - f1_score: 0.9640\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 14.1088 - accuracy: 0.9643 - precision: 0.9571 - recall: 0.9710 - f1_score: 0.9640 - val_loss: 14.2834 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8750 - val_f1_score: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 17/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 14.0492 - accuracy: 0.9500 - precision: 0.9306 - recall: 0.9710 - f1_score: 0.9504\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 14.0492 - accuracy: 0.9500 - precision: 0.9306 - recall: 0.9710 - f1_score: 0.9504 - val_loss: 14.6937 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8125 - val_f1_score: 0.8966 - lr: 1.0000e-05\n",
            "Epoch 18/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 13.8866 - accuracy: 0.9429 - precision: 0.9296 - recall: 0.9565 - f1_score: 0.9429\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 142ms/step - loss: 13.8866 - accuracy: 0.9429 - precision: 0.9296 - recall: 0.9565 - f1_score: 0.9429 - val_loss: 13.7068 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 19/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 13.6955 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 13.6955 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 13.5796 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 20/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 13.5322 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 13.5322 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 13.4368 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 21/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 13.4403 - accuracy: 0.9786 - precision: 0.9583 - recall: 1.0000 - f1_score: 0.9787\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 6s 165ms/step - loss: 13.4403 - accuracy: 0.9786 - precision: 0.9583 - recall: 1.0000 - f1_score: 0.9787 - val_loss: 13.3118 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 22/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 13.2869 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 6s 158ms/step - loss: 13.2869 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 13.1941 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 23/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 13.1436 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 13.1436 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 13.0769 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 24/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 13.0651 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 13.0651 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 13.3050 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8750 - val_f1_score: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 25/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 13.2554 - accuracy: 0.9429 - precision: 0.9420 - recall: 0.9420 - f1_score: 0.9420\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 123ms/step - loss: 13.2554 - accuracy: 0.9429 - precision: 0.9420 - recall: 0.9420 - f1_score: 0.9420 - val_loss: 12.8722 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 26/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 12.8183 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 126ms/step - loss: 12.8183 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 12.8048 - val_accuracy: 0.9667 - val_precision: 0.9412 - val_recall: 1.0000 - val_f1_score: 0.9697 - lr: 1.0000e-05\n",
            "Epoch 27/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 12.7080 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 12.7080 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 12.6389 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 28/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 12.6432 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 12.6432 - accuracy: 0.9857 - precision: 0.9855 - recall: 0.9855 - f1_score: 0.9855 - val_loss: 12.5216 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 29/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 12.4755 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 5s 135ms/step - loss: 12.4755 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 12.4140 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 30/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 12.3877 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 12.3877 - accuracy: 0.9929 - precision: 0.9857 - recall: 1.0000 - f1_score: 0.9928 - val_loss: 12.8831 - val_accuracy: 0.9000 - val_precision: 1.0000 - val_recall: 0.8125 - val_f1_score: 0.8966 - lr: 1.0000e-05\n",
            "Epoch 31/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 12.3865 - accuracy: 0.9571 - precision: 0.9200 - recall: 1.0000 - f1_score: 0.9583\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 12.3865 - accuracy: 0.9571 - precision: 0.9200 - recall: 1.0000 - f1_score: 0.9583 - val_loss: 12.5421 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.8750 - val_f1_score: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 32/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 12.1621 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 128ms/step - loss: 12.1621 - accuracy: 0.9857 - precision: 1.0000 - recall: 0.9710 - f1_score: 0.9853 - val_loss: 12.0509 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 33/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 12.1180 - accuracy: 0.9714 - precision: 0.9577 - recall: 0.9855 - f1_score: 0.9714\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 120ms/step - loss: 12.1180 - accuracy: 0.9714 - precision: 0.9577 - recall: 0.9855 - f1_score: 0.9714 - val_loss: 11.9377 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 34/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 11.9162 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 108ms/step - loss: 11.9162 - accuracy: 0.9857 - precision: 0.9718 - recall: 1.0000 - f1_score: 0.9857 - val_loss: 11.8129 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 35/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 11.7753 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 11.7753 - accuracy: 0.9929 - precision: 1.0000 - recall: 0.9855 - f1_score: 0.9927 - val_loss: 11.6913 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 36/200\n",
            " 9/35 [======>.......................] - ETA: 3s - loss: 11.7055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000"
          ]
        }
      ],
      "source": [
        "trainModelNumpyKfoldAugment(TLModelArchi_2Trainable, VGG16) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE8rLQUSzT0i"
      },
      "source": [
        "VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2rZH6otqtarl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions\n",
        "TestingAlreadyTrainedModel(VGG19) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o0xEJvMD4e0_"
      },
      "outputs": [],
      "source": [
        "trainModelNumpyKfoldAugment(TLModelArchi_2, VGG19) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEORfjf5zbU8"
      },
      "source": [
        "ResNet50v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nl55ZSaCzVK5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "TestingAlreadyTrainedModel(ResNet50V2) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k_zeD_DDtaj4"
      },
      "outputs": [],
      "source": [
        "trainModelNumpyKfoldAugment(TLModelArchi_2, ResNet50V2) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oSG4EWK0WKo"
      },
      "source": [
        "EfficientNetV2L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0i1OmTzdmhVi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetV2L\n",
        "trainModelNumpyKfoldAugment(TLModelArchi_2, EfficientNetV2L) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKU-KmDE0Vyh"
      },
      "source": [
        "InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1sb7NQ7atafA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import InceptionV3 # Scale input pixels between -1 and 1.\n",
        "X = tf.keras.applications.mobilenet.preprocess_input(X)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15, random_state=SEED) # .15 pour kfold et .3 pour normal\n",
        "trainModelNumpyKfoldAugment(TLModelArchi_2, InceptionV3) # Add/Change the model Name for changing the pretaining model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SmGUOXAtl5z"
      },
      "source": [
        "## Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lg4TdDlF1Zqo",
        "outputId": "41e99704-d1cf-4669-b2ba-a44af1bb3118"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-24-4e0c91cc0719>\", line 3, in <cell line: 3>\n",
            "    X, y = create_dataset(my_path, my_classes)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 2, in create_dataset\n",
            "    X,y=create_X_y(my_path, my_classes, gray, onehot)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 30, in create_X_y\n",
            "    training_data=create_training_data(path_data, list_classes, gray)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 15, in create_training_data\n",
            "    for img in os.listdir(path):\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'Tiger-Fox-Elephant/tiger'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-24-4e0c91cc0719>\", line 3, in <cell line: 3>\n",
            "    X, y = create_dataset(my_path, my_classes)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 2, in create_dataset\n",
            "    X,y=create_X_y(my_path, my_classes, gray, onehot)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 30, in create_X_y\n",
            "    training_data=create_training_data(path_data, list_classes, gray)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 15, in create_training_data\n",
            "    for img in os.listdir(path):\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'Tiger-Fox-Elephant/tiger'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-24-4e0c91cc0719>\", line 3, in <cell line: 3>\n",
            "    X, y = create_dataset(my_path, my_classes)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 2, in create_dataset\n",
            "    X,y=create_X_y(my_path, my_classes, gray, onehot)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 30, in create_X_y\n",
            "    training_data=create_training_data(path_data, list_classes, gray)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 15, in create_training_data\n",
            "    for img in os.listdir(path):\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'Tiger-Fox-Elephant/tiger'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "my_path=\"Tiger-Fox-Elephant/\"\n",
        "my_classes=['tiger','Tiger_negative_class']\n",
        "X, y = create_dataset(my_path, my_classes)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15, random_state=SEED) # .15 pour kfold et .3 pour normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P7ZHgo_uEfk"
      },
      "outputs": [],
      "source": [
        "model = VGG16(include_top=False)\n",
        "\n",
        "n=1\n",
        "for layer in model.layers :\n",
        "  print(layer.name, n)\n",
        "  n+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6V9Wuq60j3wa",
        "outputId": "9e7bfc71-2180-49d4-e9df-7485efeeeb8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "############# Fold n°1 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 15.9705 - accuracy: 0.5353 - precision: 0.5395 - recall: 0.4824 - f1_score: 0.5093"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-25-d3a50aaa1f19>\", line 2, in <cell line: 2>\n",
            "    FineTuningKfoldingAugment(VGG16, fine_layer_tune)\n",
            "  File \"<ipython-input-16-529488907e07>\", line 62, in FineTuningKfoldingAugment\n",
            "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 513, in recursive_create_dir_v2\n",
            "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: Saved_Model; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-25-d3a50aaa1f19>\", line 2, in <cell line: 2>\n",
            "    FineTuningKfoldingAugment(VGG16, fine_layer_tune)\n",
            "  File \"<ipython-input-16-529488907e07>\", line 62, in FineTuningKfoldingAugment\n",
            "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 513, in recursive_create_dir_v2\n",
            "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: Saved_Model; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-25-d3a50aaa1f19>\", line 2, in <cell line: 2>\n",
            "    FineTuningKfoldingAugment(VGG16, fine_layer_tune)\n",
            "  File \"<ipython-input-16-529488907e07>\", line 62, in FineTuningKfoldingAugment\n",
            "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 513, in recursive_create_dir_v2\n",
            "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: Saved_Model; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "fine_layer_tune=[17, 15, 11] # Définit selon les blocks du model\n",
        "FineTuningKfoldingAugment(VGG16, fine_layer_tune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z9HjfhkTxzDx",
        "outputId": "c7bb3368-5242-42be-9113-a2aa264360da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_30 1\n",
            "rescaling_1 2\n",
            "stem_conv 3\n",
            "stem_bn 4\n",
            "stem_activation 5\n",
            "block1a_project_conv 6\n",
            "block1a_project_bn 7\n",
            "block1a_project_activation 8\n",
            "block1a_add 9\n",
            "block1b_project_conv 10\n",
            "block1b_project_bn 11\n",
            "block1b_project_activation 12\n",
            "block1b_drop 13\n",
            "block1b_add 14\n",
            "block1c_project_conv 15\n",
            "block1c_project_bn 16\n",
            "block1c_project_activation 17\n",
            "block1c_drop 18\n",
            "block1c_add 19\n",
            "block1d_project_conv 20\n",
            "block1d_project_bn 21\n",
            "block1d_project_activation 22\n",
            "block1d_drop 23\n",
            "block1d_add 24\n",
            "block2a_expand_conv 25\n",
            "block2a_expand_bn 26\n",
            "block2a_expand_activation 27\n",
            "block2a_project_conv 28\n",
            "block2a_project_bn 29\n",
            "block2b_expand_conv 30\n",
            "block2b_expand_bn 31\n",
            "block2b_expand_activation 32\n",
            "block2b_project_conv 33\n",
            "block2b_project_bn 34\n",
            "block2b_drop 35\n",
            "block2b_add 36\n",
            "block2c_expand_conv 37\n",
            "block2c_expand_bn 38\n",
            "block2c_expand_activation 39\n",
            "block2c_project_conv 40\n",
            "block2c_project_bn 41\n",
            "block2c_drop 42\n",
            "block2c_add 43\n",
            "block2d_expand_conv 44\n",
            "block2d_expand_bn 45\n",
            "block2d_expand_activation 46\n",
            "block2d_project_conv 47\n",
            "block2d_project_bn 48\n",
            "block2d_drop 49\n",
            "block2d_add 50\n",
            "block2e_expand_conv 51\n",
            "block2e_expand_bn 52\n",
            "block2e_expand_activation 53\n",
            "block2e_project_conv 54\n",
            "block2e_project_bn 55\n",
            "block2e_drop 56\n",
            "block2e_add 57\n",
            "block2f_expand_conv 58\n",
            "block2f_expand_bn 59\n",
            "block2f_expand_activation 60\n",
            "block2f_project_conv 61\n",
            "block2f_project_bn 62\n",
            "block2f_drop 63\n",
            "block2f_add 64\n",
            "block2g_expand_conv 65\n",
            "block2g_expand_bn 66\n",
            "block2g_expand_activation 67\n",
            "block2g_project_conv 68\n",
            "block2g_project_bn 69\n",
            "block2g_drop 70\n",
            "block2g_add 71\n",
            "block3a_expand_conv 72\n",
            "block3a_expand_bn 73\n",
            "block3a_expand_activation 74\n",
            "block3a_project_conv 75\n",
            "block3a_project_bn 76\n",
            "block3b_expand_conv 77\n",
            "block3b_expand_bn 78\n",
            "block3b_expand_activation 79\n",
            "block3b_project_conv 80\n",
            "block3b_project_bn 81\n",
            "block3b_drop 82\n",
            "block3b_add 83\n",
            "block3c_expand_conv 84\n",
            "block3c_expand_bn 85\n",
            "block3c_expand_activation 86\n",
            "block3c_project_conv 87\n",
            "block3c_project_bn 88\n",
            "block3c_drop 89\n",
            "block3c_add 90\n",
            "block3d_expand_conv 91\n",
            "block3d_expand_bn 92\n",
            "block3d_expand_activation 93\n",
            "block3d_project_conv 94\n",
            "block3d_project_bn 95\n",
            "block3d_drop 96\n",
            "block3d_add 97\n",
            "block3e_expand_conv 98\n",
            "block3e_expand_bn 99\n",
            "block3e_expand_activation 100\n",
            "block3e_project_conv 101\n",
            "block3e_project_bn 102\n",
            "block3e_drop 103\n",
            "block3e_add 104\n",
            "block3f_expand_conv 105\n",
            "block3f_expand_bn 106\n",
            "block3f_expand_activation 107\n",
            "block3f_project_conv 108\n",
            "block3f_project_bn 109\n",
            "block3f_drop 110\n",
            "block3f_add 111\n",
            "block3g_expand_conv 112\n",
            "block3g_expand_bn 113\n",
            "block3g_expand_activation 114\n",
            "block3g_project_conv 115\n",
            "block3g_project_bn 116\n",
            "block3g_drop 117\n",
            "block3g_add 118\n",
            "block4a_expand_conv 119\n",
            "block4a_expand_bn 120\n",
            "block4a_expand_activation 121\n",
            "block4a_dwconv2 122\n",
            "block4a_bn 123\n",
            "block4a_activation 124\n",
            "block4a_se_squeeze 125\n",
            "block4a_se_reshape 126\n",
            "block4a_se_reduce 127\n",
            "block4a_se_expand 128\n",
            "block4a_se_excite 129\n",
            "block4a_project_conv 130\n",
            "block4a_project_bn 131\n",
            "block4b_expand_conv 132\n",
            "block4b_expand_bn 133\n",
            "block4b_expand_activation 134\n",
            "block4b_dwconv2 135\n",
            "block4b_bn 136\n",
            "block4b_activation 137\n",
            "block4b_se_squeeze 138\n",
            "block4b_se_reshape 139\n",
            "block4b_se_reduce 140\n",
            "block4b_se_expand 141\n",
            "block4b_se_excite 142\n",
            "block4b_project_conv 143\n",
            "block4b_project_bn 144\n",
            "block4b_drop 145\n",
            "block4b_add 146\n",
            "block4c_expand_conv 147\n",
            "block4c_expand_bn 148\n",
            "block4c_expand_activation 149\n",
            "block4c_dwconv2 150\n",
            "block4c_bn 151\n",
            "block4c_activation 152\n",
            "block4c_se_squeeze 153\n",
            "block4c_se_reshape 154\n",
            "block4c_se_reduce 155\n",
            "block4c_se_expand 156\n",
            "block4c_se_excite 157\n",
            "block4c_project_conv 158\n",
            "block4c_project_bn 159\n",
            "block4c_drop 160\n",
            "block4c_add 161\n",
            "block4d_expand_conv 162\n",
            "block4d_expand_bn 163\n",
            "block4d_expand_activation 164\n",
            "block4d_dwconv2 165\n",
            "block4d_bn 166\n",
            "block4d_activation 167\n",
            "block4d_se_squeeze 168\n",
            "block4d_se_reshape 169\n",
            "block4d_se_reduce 170\n",
            "block4d_se_expand 171\n",
            "block4d_se_excite 172\n",
            "block4d_project_conv 173\n",
            "block4d_project_bn 174\n",
            "block4d_drop 175\n",
            "block4d_add 176\n",
            "block4e_expand_conv 177\n",
            "block4e_expand_bn 178\n",
            "block4e_expand_activation 179\n",
            "block4e_dwconv2 180\n",
            "block4e_bn 181\n",
            "block4e_activation 182\n",
            "block4e_se_squeeze 183\n",
            "block4e_se_reshape 184\n",
            "block4e_se_reduce 185\n",
            "block4e_se_expand 186\n",
            "block4e_se_excite 187\n",
            "block4e_project_conv 188\n",
            "block4e_project_bn 189\n",
            "block4e_drop 190\n",
            "block4e_add 191\n",
            "block4f_expand_conv 192\n",
            "block4f_expand_bn 193\n",
            "block4f_expand_activation 194\n",
            "block4f_dwconv2 195\n",
            "block4f_bn 196\n",
            "block4f_activation 197\n",
            "block4f_se_squeeze 198\n",
            "block4f_se_reshape 199\n",
            "block4f_se_reduce 200\n",
            "block4f_se_expand 201\n",
            "block4f_se_excite 202\n",
            "block4f_project_conv 203\n",
            "block4f_project_bn 204\n",
            "block4f_drop 205\n",
            "block4f_add 206\n",
            "block4g_expand_conv 207\n",
            "block4g_expand_bn 208\n",
            "block4g_expand_activation 209\n",
            "block4g_dwconv2 210\n",
            "block4g_bn 211\n",
            "block4g_activation 212\n",
            "block4g_se_squeeze 213\n",
            "block4g_se_reshape 214\n",
            "block4g_se_reduce 215\n",
            "block4g_se_expand 216\n",
            "block4g_se_excite 217\n",
            "block4g_project_conv 218\n",
            "block4g_project_bn 219\n",
            "block4g_drop 220\n",
            "block4g_add 221\n",
            "block4h_expand_conv 222\n",
            "block4h_expand_bn 223\n",
            "block4h_expand_activation 224\n",
            "block4h_dwconv2 225\n",
            "block4h_bn 226\n",
            "block4h_activation 227\n",
            "block4h_se_squeeze 228\n",
            "block4h_se_reshape 229\n",
            "block4h_se_reduce 230\n",
            "block4h_se_expand 231\n",
            "block4h_se_excite 232\n",
            "block4h_project_conv 233\n",
            "block4h_project_bn 234\n",
            "block4h_drop 235\n",
            "block4h_add 236\n",
            "block4i_expand_conv 237\n",
            "block4i_expand_bn 238\n",
            "block4i_expand_activation 239\n",
            "block4i_dwconv2 240\n",
            "block4i_bn 241\n",
            "block4i_activation 242\n",
            "block4i_se_squeeze 243\n",
            "block4i_se_reshape 244\n",
            "block4i_se_reduce 245\n",
            "block4i_se_expand 246\n",
            "block4i_se_excite 247\n",
            "block4i_project_conv 248\n",
            "block4i_project_bn 249\n",
            "block4i_drop 250\n",
            "block4i_add 251\n",
            "block4j_expand_conv 252\n",
            "block4j_expand_bn 253\n",
            "block4j_expand_activation 254\n",
            "block4j_dwconv2 255\n",
            "block4j_bn 256\n",
            "block4j_activation 257\n",
            "block4j_se_squeeze 258\n",
            "block4j_se_reshape 259\n",
            "block4j_se_reduce 260\n",
            "block4j_se_expand 261\n",
            "block4j_se_excite 262\n",
            "block4j_project_conv 263\n",
            "block4j_project_bn 264\n",
            "block4j_drop 265\n",
            "block4j_add 266\n",
            "block5a_expand_conv 267\n",
            "block5a_expand_bn 268\n",
            "block5a_expand_activation 269\n",
            "block5a_dwconv2 270\n",
            "block5a_bn 271\n",
            "block5a_activation 272\n",
            "block5a_se_squeeze 273\n",
            "block5a_se_reshape 274\n",
            "block5a_se_reduce 275\n",
            "block5a_se_expand 276\n",
            "block5a_se_excite 277\n",
            "block5a_project_conv 278\n",
            "block5a_project_bn 279\n",
            "block5b_expand_conv 280\n",
            "block5b_expand_bn 281\n",
            "block5b_expand_activation 282\n",
            "block5b_dwconv2 283\n",
            "block5b_bn 284\n",
            "block5b_activation 285\n",
            "block5b_se_squeeze 286\n",
            "block5b_se_reshape 287\n",
            "block5b_se_reduce 288\n",
            "block5b_se_expand 289\n",
            "block5b_se_excite 290\n",
            "block5b_project_conv 291\n",
            "block5b_project_bn 292\n",
            "block5b_drop 293\n",
            "block5b_add 294\n",
            "block5c_expand_conv 295\n",
            "block5c_expand_bn 296\n",
            "block5c_expand_activation 297\n",
            "block5c_dwconv2 298\n",
            "block5c_bn 299\n",
            "block5c_activation 300\n",
            "block5c_se_squeeze 301\n",
            "block5c_se_reshape 302\n",
            "block5c_se_reduce 303\n",
            "block5c_se_expand 304\n",
            "block5c_se_excite 305\n",
            "block5c_project_conv 306\n",
            "block5c_project_bn 307\n",
            "block5c_drop 308\n",
            "block5c_add 309\n",
            "block5d_expand_conv 310\n",
            "block5d_expand_bn 311\n",
            "block5d_expand_activation 312\n",
            "block5d_dwconv2 313\n",
            "block5d_bn 314\n",
            "block5d_activation 315\n",
            "block5d_se_squeeze 316\n",
            "block5d_se_reshape 317\n",
            "block5d_se_reduce 318\n",
            "block5d_se_expand 319\n",
            "block5d_se_excite 320\n",
            "block5d_project_conv 321\n",
            "block5d_project_bn 322\n",
            "block5d_drop 323\n",
            "block5d_add 324\n",
            "block5e_expand_conv 325\n",
            "block5e_expand_bn 326\n",
            "block5e_expand_activation 327\n",
            "block5e_dwconv2 328\n",
            "block5e_bn 329\n",
            "block5e_activation 330\n",
            "block5e_se_squeeze 331\n",
            "block5e_se_reshape 332\n",
            "block5e_se_reduce 333\n",
            "block5e_se_expand 334\n",
            "block5e_se_excite 335\n",
            "block5e_project_conv 336\n",
            "block5e_project_bn 337\n",
            "block5e_drop 338\n",
            "block5e_add 339\n",
            "block5f_expand_conv 340\n",
            "block5f_expand_bn 341\n",
            "block5f_expand_activation 342\n",
            "block5f_dwconv2 343\n",
            "block5f_bn 344\n",
            "block5f_activation 345\n",
            "block5f_se_squeeze 346\n",
            "block5f_se_reshape 347\n",
            "block5f_se_reduce 348\n",
            "block5f_se_expand 349\n",
            "block5f_se_excite 350\n",
            "block5f_project_conv 351\n",
            "block5f_project_bn 352\n",
            "block5f_drop 353\n",
            "block5f_add 354\n",
            "block5g_expand_conv 355\n",
            "block5g_expand_bn 356\n",
            "block5g_expand_activation 357\n",
            "block5g_dwconv2 358\n",
            "block5g_bn 359\n",
            "block5g_activation 360\n",
            "block5g_se_squeeze 361\n",
            "block5g_se_reshape 362\n",
            "block5g_se_reduce 363\n",
            "block5g_se_expand 364\n",
            "block5g_se_excite 365\n",
            "block5g_project_conv 366\n",
            "block5g_project_bn 367\n",
            "block5g_drop 368\n",
            "block5g_add 369\n",
            "block5h_expand_conv 370\n",
            "block5h_expand_bn 371\n",
            "block5h_expand_activation 372\n",
            "block5h_dwconv2 373\n",
            "block5h_bn 374\n",
            "block5h_activation 375\n",
            "block5h_se_squeeze 376\n",
            "block5h_se_reshape 377\n",
            "block5h_se_reduce 378\n",
            "block5h_se_expand 379\n",
            "block5h_se_excite 380\n",
            "block5h_project_conv 381\n",
            "block5h_project_bn 382\n",
            "block5h_drop 383\n",
            "block5h_add 384\n",
            "block5i_expand_conv 385\n",
            "block5i_expand_bn 386\n",
            "block5i_expand_activation 387\n",
            "block5i_dwconv2 388\n",
            "block5i_bn 389\n",
            "block5i_activation 390\n",
            "block5i_se_squeeze 391\n",
            "block5i_se_reshape 392\n",
            "block5i_se_reduce 393\n",
            "block5i_se_expand 394\n",
            "block5i_se_excite 395\n",
            "block5i_project_conv 396\n",
            "block5i_project_bn 397\n",
            "block5i_drop 398\n",
            "block5i_add 399\n",
            "block5j_expand_conv 400\n",
            "block5j_expand_bn 401\n",
            "block5j_expand_activation 402\n",
            "block5j_dwconv2 403\n",
            "block5j_bn 404\n",
            "block5j_activation 405\n",
            "block5j_se_squeeze 406\n",
            "block5j_se_reshape 407\n",
            "block5j_se_reduce 408\n",
            "block5j_se_expand 409\n",
            "block5j_se_excite 410\n",
            "block5j_project_conv 411\n",
            "block5j_project_bn 412\n",
            "block5j_drop 413\n",
            "block5j_add 414\n",
            "block5k_expand_conv 415\n",
            "block5k_expand_bn 416\n",
            "block5k_expand_activation 417\n",
            "block5k_dwconv2 418\n",
            "block5k_bn 419\n",
            "block5k_activation 420\n",
            "block5k_se_squeeze 421\n",
            "block5k_se_reshape 422\n",
            "block5k_se_reduce 423\n",
            "block5k_se_expand 424\n",
            "block5k_se_excite 425\n",
            "block5k_project_conv 426\n",
            "block5k_project_bn 427\n",
            "block5k_drop 428\n",
            "block5k_add 429\n",
            "block5l_expand_conv 430\n",
            "block5l_expand_bn 431\n",
            "block5l_expand_activation 432\n",
            "block5l_dwconv2 433\n",
            "block5l_bn 434\n",
            "block5l_activation 435\n",
            "block5l_se_squeeze 436\n",
            "block5l_se_reshape 437\n",
            "block5l_se_reduce 438\n",
            "block5l_se_expand 439\n",
            "block5l_se_excite 440\n",
            "block5l_project_conv 441\n",
            "block5l_project_bn 442\n",
            "block5l_drop 443\n",
            "block5l_add 444\n",
            "block5m_expand_conv 445\n",
            "block5m_expand_bn 446\n",
            "block5m_expand_activation 447\n",
            "block5m_dwconv2 448\n",
            "block5m_bn 449\n",
            "block5m_activation 450\n",
            "block5m_se_squeeze 451\n",
            "block5m_se_reshape 452\n",
            "block5m_se_reduce 453\n",
            "block5m_se_expand 454\n",
            "block5m_se_excite 455\n",
            "block5m_project_conv 456\n",
            "block5m_project_bn 457\n",
            "block5m_drop 458\n",
            "block5m_add 459\n",
            "block5n_expand_conv 460\n",
            "block5n_expand_bn 461\n",
            "block5n_expand_activation 462\n",
            "block5n_dwconv2 463\n",
            "block5n_bn 464\n",
            "block5n_activation 465\n",
            "block5n_se_squeeze 466\n",
            "block5n_se_reshape 467\n",
            "block5n_se_reduce 468\n",
            "block5n_se_expand 469\n",
            "block5n_se_excite 470\n",
            "block5n_project_conv 471\n",
            "block5n_project_bn 472\n",
            "block5n_drop 473\n",
            "block5n_add 474\n",
            "block5o_expand_conv 475\n",
            "block5o_expand_bn 476\n",
            "block5o_expand_activation 477\n",
            "block5o_dwconv2 478\n",
            "block5o_bn 479\n",
            "block5o_activation 480\n",
            "block5o_se_squeeze 481\n",
            "block5o_se_reshape 482\n",
            "block5o_se_reduce 483\n",
            "block5o_se_expand 484\n",
            "block5o_se_excite 485\n",
            "block5o_project_conv 486\n",
            "block5o_project_bn 487\n",
            "block5o_drop 488\n",
            "block5o_add 489\n",
            "block5p_expand_conv 490\n",
            "block5p_expand_bn 491\n",
            "block5p_expand_activation 492\n",
            "block5p_dwconv2 493\n",
            "block5p_bn 494\n",
            "block5p_activation 495\n",
            "block5p_se_squeeze 496\n",
            "block5p_se_reshape 497\n",
            "block5p_se_reduce 498\n",
            "block5p_se_expand 499\n",
            "block5p_se_excite 500\n",
            "block5p_project_conv 501\n",
            "block5p_project_bn 502\n",
            "block5p_drop 503\n",
            "block5p_add 504\n",
            "block5q_expand_conv 505\n",
            "block5q_expand_bn 506\n",
            "block5q_expand_activation 507\n",
            "block5q_dwconv2 508\n",
            "block5q_bn 509\n",
            "block5q_activation 510\n",
            "block5q_se_squeeze 511\n",
            "block5q_se_reshape 512\n",
            "block5q_se_reduce 513\n",
            "block5q_se_expand 514\n",
            "block5q_se_excite 515\n",
            "block5q_project_conv 516\n",
            "block5q_project_bn 517\n",
            "block5q_drop 518\n",
            "block5q_add 519\n",
            "block5r_expand_conv 520\n",
            "block5r_expand_bn 521\n",
            "block5r_expand_activation 522\n",
            "block5r_dwconv2 523\n",
            "block5r_bn 524\n",
            "block5r_activation 525\n",
            "block5r_se_squeeze 526\n",
            "block5r_se_reshape 527\n",
            "block5r_se_reduce 528\n",
            "block5r_se_expand 529\n",
            "block5r_se_excite 530\n",
            "block5r_project_conv 531\n",
            "block5r_project_bn 532\n",
            "block5r_drop 533\n",
            "block5r_add 534\n",
            "block5s_expand_conv 535\n",
            "block5s_expand_bn 536\n",
            "block5s_expand_activation 537\n",
            "block5s_dwconv2 538\n",
            "block5s_bn 539\n",
            "block5s_activation 540\n",
            "block5s_se_squeeze 541\n",
            "block5s_se_reshape 542\n",
            "block5s_se_reduce 543\n",
            "block5s_se_expand 544\n",
            "block5s_se_excite 545\n",
            "block5s_project_conv 546\n",
            "block5s_project_bn 547\n",
            "block5s_drop 548\n",
            "block5s_add 549\n",
            "block6a_expand_conv 550\n",
            "block6a_expand_bn 551\n",
            "block6a_expand_activation 552\n",
            "block6a_dwconv2 553\n",
            "block6a_bn 554\n",
            "block6a_activation 555\n",
            "block6a_se_squeeze 556\n",
            "block6a_se_reshape 557\n",
            "block6a_se_reduce 558\n",
            "block6a_se_expand 559\n",
            "block6a_se_excite 560\n",
            "block6a_project_conv 561\n",
            "block6a_project_bn 562\n",
            "block6b_expand_conv 563\n",
            "block6b_expand_bn 564\n",
            "block6b_expand_activation 565\n",
            "block6b_dwconv2 566\n",
            "block6b_bn 567\n",
            "block6b_activation 568\n",
            "block6b_se_squeeze 569\n",
            "block6b_se_reshape 570\n",
            "block6b_se_reduce 571\n",
            "block6b_se_expand 572\n",
            "block6b_se_excite 573\n",
            "block6b_project_conv 574\n",
            "block6b_project_bn 575\n",
            "block6b_drop 576\n",
            "block6b_add 577\n",
            "block6c_expand_conv 578\n",
            "block6c_expand_bn 579\n",
            "block6c_expand_activation 580\n",
            "block6c_dwconv2 581\n",
            "block6c_bn 582\n",
            "block6c_activation 583\n",
            "block6c_se_squeeze 584\n",
            "block6c_se_reshape 585\n",
            "block6c_se_reduce 586\n",
            "block6c_se_expand 587\n",
            "block6c_se_excite 588\n",
            "block6c_project_conv 589\n",
            "block6c_project_bn 590\n",
            "block6c_drop 591\n",
            "block6c_add 592\n",
            "block6d_expand_conv 593\n",
            "block6d_expand_bn 594\n",
            "block6d_expand_activation 595\n",
            "block6d_dwconv2 596\n",
            "block6d_bn 597\n",
            "block6d_activation 598\n",
            "block6d_se_squeeze 599\n",
            "block6d_se_reshape 600\n",
            "block6d_se_reduce 601\n",
            "block6d_se_expand 602\n",
            "block6d_se_excite 603\n",
            "block6d_project_conv 604\n",
            "block6d_project_bn 605\n",
            "block6d_drop 606\n",
            "block6d_add 607\n",
            "block6e_expand_conv 608\n",
            "block6e_expand_bn 609\n",
            "block6e_expand_activation 610\n",
            "block6e_dwconv2 611\n",
            "block6e_bn 612\n",
            "block6e_activation 613\n",
            "block6e_se_squeeze 614\n",
            "block6e_se_reshape 615\n",
            "block6e_se_reduce 616\n",
            "block6e_se_expand 617\n",
            "block6e_se_excite 618\n",
            "block6e_project_conv 619\n",
            "block6e_project_bn 620\n",
            "block6e_drop 621\n",
            "block6e_add 622\n",
            "block6f_expand_conv 623\n",
            "block6f_expand_bn 624\n",
            "block6f_expand_activation 625\n",
            "block6f_dwconv2 626\n",
            "block6f_bn 627\n",
            "block6f_activation 628\n",
            "block6f_se_squeeze 629\n",
            "block6f_se_reshape 630\n",
            "block6f_se_reduce 631\n",
            "block6f_se_expand 632\n",
            "block6f_se_excite 633\n",
            "block6f_project_conv 634\n",
            "block6f_project_bn 635\n",
            "block6f_drop 636\n",
            "block6f_add 637\n",
            "block6g_expand_conv 638\n",
            "block6g_expand_bn 639\n",
            "block6g_expand_activation 640\n",
            "block6g_dwconv2 641\n",
            "block6g_bn 642\n",
            "block6g_activation 643\n",
            "block6g_se_squeeze 644\n",
            "block6g_se_reshape 645\n",
            "block6g_se_reduce 646\n",
            "block6g_se_expand 647\n",
            "block6g_se_excite 648\n",
            "block6g_project_conv 649\n",
            "block6g_project_bn 650\n",
            "block6g_drop 651\n",
            "block6g_add 652\n",
            "block6h_expand_conv 653\n",
            "block6h_expand_bn 654\n",
            "block6h_expand_activation 655\n",
            "block6h_dwconv2 656\n",
            "block6h_bn 657\n",
            "block6h_activation 658\n",
            "block6h_se_squeeze 659\n",
            "block6h_se_reshape 660\n",
            "block6h_se_reduce 661\n",
            "block6h_se_expand 662\n",
            "block6h_se_excite 663\n",
            "block6h_project_conv 664\n",
            "block6h_project_bn 665\n",
            "block6h_drop 666\n",
            "block6h_add 667\n",
            "block6i_expand_conv 668\n",
            "block6i_expand_bn 669\n",
            "block6i_expand_activation 670\n",
            "block6i_dwconv2 671\n",
            "block6i_bn 672\n",
            "block6i_activation 673\n",
            "block6i_se_squeeze 674\n",
            "block6i_se_reshape 675\n",
            "block6i_se_reduce 676\n",
            "block6i_se_expand 677\n",
            "block6i_se_excite 678\n",
            "block6i_project_conv 679\n",
            "block6i_project_bn 680\n",
            "block6i_drop 681\n",
            "block6i_add 682\n",
            "block6j_expand_conv 683\n",
            "block6j_expand_bn 684\n",
            "block6j_expand_activation 685\n",
            "block6j_dwconv2 686\n",
            "block6j_bn 687\n",
            "block6j_activation 688\n",
            "block6j_se_squeeze 689\n",
            "block6j_se_reshape 690\n",
            "block6j_se_reduce 691\n",
            "block6j_se_expand 692\n",
            "block6j_se_excite 693\n",
            "block6j_project_conv 694\n",
            "block6j_project_bn 695\n",
            "block6j_drop 696\n",
            "block6j_add 697\n",
            "block6k_expand_conv 698\n",
            "block6k_expand_bn 699\n",
            "block6k_expand_activation 700\n",
            "block6k_dwconv2 701\n",
            "block6k_bn 702\n",
            "block6k_activation 703\n",
            "block6k_se_squeeze 704\n",
            "block6k_se_reshape 705\n",
            "block6k_se_reduce 706\n",
            "block6k_se_expand 707\n",
            "block6k_se_excite 708\n",
            "block6k_project_conv 709\n",
            "block6k_project_bn 710\n",
            "block6k_drop 711\n",
            "block6k_add 712\n",
            "block6l_expand_conv 713\n",
            "block6l_expand_bn 714\n",
            "block6l_expand_activation 715\n",
            "block6l_dwconv2 716\n",
            "block6l_bn 717\n",
            "block6l_activation 718\n",
            "block6l_se_squeeze 719\n",
            "block6l_se_reshape 720\n",
            "block6l_se_reduce 721\n",
            "block6l_se_expand 722\n",
            "block6l_se_excite 723\n",
            "block6l_project_conv 724\n",
            "block6l_project_bn 725\n",
            "block6l_drop 726\n",
            "block6l_add 727\n",
            "block6m_expand_conv 728\n",
            "block6m_expand_bn 729\n",
            "block6m_expand_activation 730\n",
            "block6m_dwconv2 731\n",
            "block6m_bn 732\n",
            "block6m_activation 733\n",
            "block6m_se_squeeze 734\n",
            "block6m_se_reshape 735\n",
            "block6m_se_reduce 736\n",
            "block6m_se_expand 737\n",
            "block6m_se_excite 738\n",
            "block6m_project_conv 739\n",
            "block6m_project_bn 740\n",
            "block6m_drop 741\n",
            "block6m_add 742\n",
            "block6n_expand_conv 743\n",
            "block6n_expand_bn 744\n",
            "block6n_expand_activation 745\n",
            "block6n_dwconv2 746\n",
            "block6n_bn 747\n",
            "block6n_activation 748\n",
            "block6n_se_squeeze 749\n",
            "block6n_se_reshape 750\n",
            "block6n_se_reduce 751\n",
            "block6n_se_expand 752\n",
            "block6n_se_excite 753\n",
            "block6n_project_conv 754\n",
            "block6n_project_bn 755\n",
            "block6n_drop 756\n",
            "block6n_add 757\n",
            "block6o_expand_conv 758\n",
            "block6o_expand_bn 759\n",
            "block6o_expand_activation 760\n",
            "block6o_dwconv2 761\n",
            "block6o_bn 762\n",
            "block6o_activation 763\n",
            "block6o_se_squeeze 764\n",
            "block6o_se_reshape 765\n",
            "block6o_se_reduce 766\n",
            "block6o_se_expand 767\n",
            "block6o_se_excite 768\n",
            "block6o_project_conv 769\n",
            "block6o_project_bn 770\n",
            "block6o_drop 771\n",
            "block6o_add 772\n",
            "block6p_expand_conv 773\n",
            "block6p_expand_bn 774\n",
            "block6p_expand_activation 775\n",
            "block6p_dwconv2 776\n",
            "block6p_bn 777\n",
            "block6p_activation 778\n",
            "block6p_se_squeeze 779\n",
            "block6p_se_reshape 780\n",
            "block6p_se_reduce 781\n",
            "block6p_se_expand 782\n",
            "block6p_se_excite 783\n",
            "block6p_project_conv 784\n",
            "block6p_project_bn 785\n",
            "block6p_drop 786\n",
            "block6p_add 787\n",
            "block6q_expand_conv 788\n",
            "block6q_expand_bn 789\n",
            "block6q_expand_activation 790\n",
            "block6q_dwconv2 791\n",
            "block6q_bn 792\n",
            "block6q_activation 793\n",
            "block6q_se_squeeze 794\n",
            "block6q_se_reshape 795\n",
            "block6q_se_reduce 796\n",
            "block6q_se_expand 797\n",
            "block6q_se_excite 798\n",
            "block6q_project_conv 799\n",
            "block6q_project_bn 800\n",
            "block6q_drop 801\n",
            "block6q_add 802\n",
            "block6r_expand_conv 803\n",
            "block6r_expand_bn 804\n",
            "block6r_expand_activation 805\n",
            "block6r_dwconv2 806\n",
            "block6r_bn 807\n",
            "block6r_activation 808\n",
            "block6r_se_squeeze 809\n",
            "block6r_se_reshape 810\n",
            "block6r_se_reduce 811\n",
            "block6r_se_expand 812\n",
            "block6r_se_excite 813\n",
            "block6r_project_conv 814\n",
            "block6r_project_bn 815\n",
            "block6r_drop 816\n",
            "block6r_add 817\n",
            "block6s_expand_conv 818\n",
            "block6s_expand_bn 819\n",
            "block6s_expand_activation 820\n",
            "block6s_dwconv2 821\n",
            "block6s_bn 822\n",
            "block6s_activation 823\n",
            "block6s_se_squeeze 824\n",
            "block6s_se_reshape 825\n",
            "block6s_se_reduce 826\n",
            "block6s_se_expand 827\n",
            "block6s_se_excite 828\n",
            "block6s_project_conv 829\n",
            "block6s_project_bn 830\n",
            "block6s_drop 831\n",
            "block6s_add 832\n",
            "block6t_expand_conv 833\n",
            "block6t_expand_bn 834\n",
            "block6t_expand_activation 835\n",
            "block6t_dwconv2 836\n",
            "block6t_bn 837\n",
            "block6t_activation 838\n",
            "block6t_se_squeeze 839\n",
            "block6t_se_reshape 840\n",
            "block6t_se_reduce 841\n",
            "block6t_se_expand 842\n",
            "block6t_se_excite 843\n",
            "block6t_project_conv 844\n",
            "block6t_project_bn 845\n",
            "block6t_drop 846\n",
            "block6t_add 847\n",
            "block6u_expand_conv 848\n",
            "block6u_expand_bn 849\n",
            "block6u_expand_activation 850\n",
            "block6u_dwconv2 851\n",
            "block6u_bn 852\n",
            "block6u_activation 853\n",
            "block6u_se_squeeze 854\n",
            "block6u_se_reshape 855\n",
            "block6u_se_reduce 856\n",
            "block6u_se_expand 857\n",
            "block6u_se_excite 858\n",
            "block6u_project_conv 859\n",
            "block6u_project_bn 860\n",
            "block6u_drop 861\n",
            "block6u_add 862\n",
            "block6v_expand_conv 863\n",
            "block6v_expand_bn 864\n",
            "block6v_expand_activation 865\n",
            "block6v_dwconv2 866\n",
            "block6v_bn 867\n",
            "block6v_activation 868\n",
            "block6v_se_squeeze 869\n",
            "block6v_se_reshape 870\n",
            "block6v_se_reduce 871\n",
            "block6v_se_expand 872\n",
            "block6v_se_excite 873\n",
            "block6v_project_conv 874\n",
            "block6v_project_bn 875\n",
            "block6v_drop 876\n",
            "block6v_add 877\n",
            "block6w_expand_conv 878\n",
            "block6w_expand_bn 879\n",
            "block6w_expand_activation 880\n",
            "block6w_dwconv2 881\n",
            "block6w_bn 882\n",
            "block6w_activation 883\n",
            "block6w_se_squeeze 884\n",
            "block6w_se_reshape 885\n",
            "block6w_se_reduce 886\n",
            "block6w_se_expand 887\n",
            "block6w_se_excite 888\n",
            "block6w_project_conv 889\n",
            "block6w_project_bn 890\n",
            "block6w_drop 891\n",
            "block6w_add 892\n",
            "block6x_expand_conv 893\n",
            "block6x_expand_bn 894\n",
            "block6x_expand_activation 895\n",
            "block6x_dwconv2 896\n",
            "block6x_bn 897\n",
            "block6x_activation 898\n",
            "block6x_se_squeeze 899\n",
            "block6x_se_reshape 900\n",
            "block6x_se_reduce 901\n",
            "block6x_se_expand 902\n",
            "block6x_se_excite 903\n",
            "block6x_project_conv 904\n",
            "block6x_project_bn 905\n",
            "block6x_drop 906\n",
            "block6x_add 907\n",
            "block6y_expand_conv 908\n",
            "block6y_expand_bn 909\n",
            "block6y_expand_activation 910\n",
            "block6y_dwconv2 911\n",
            "block6y_bn 912\n",
            "block6y_activation 913\n",
            "block6y_se_squeeze 914\n",
            "block6y_se_reshape 915\n",
            "block6y_se_reduce 916\n",
            "block6y_se_expand 917\n",
            "block6y_se_excite 918\n",
            "block6y_project_conv 919\n",
            "block6y_project_bn 920\n",
            "block6y_drop 921\n",
            "block6y_add 922\n",
            "block7a_expand_conv 923\n",
            "block7a_expand_bn 924\n",
            "block7a_expand_activation 925\n",
            "block7a_dwconv2 926\n",
            "block7a_bn 927\n",
            "block7a_activation 928\n",
            "block7a_se_squeeze 929\n",
            "block7a_se_reshape 930\n",
            "block7a_se_reduce 931\n",
            "block7a_se_expand 932\n",
            "block7a_se_excite 933\n",
            "block7a_project_conv 934\n",
            "block7a_project_bn 935\n",
            "block7b_expand_conv 936\n",
            "block7b_expand_bn 937\n",
            "block7b_expand_activation 938\n",
            "block7b_dwconv2 939\n",
            "block7b_bn 940\n",
            "block7b_activation 941\n",
            "block7b_se_squeeze 942\n",
            "block7b_se_reshape 943\n",
            "block7b_se_reduce 944\n",
            "block7b_se_expand 945\n",
            "block7b_se_excite 946\n",
            "block7b_project_conv 947\n",
            "block7b_project_bn 948\n",
            "block7b_drop 949\n",
            "block7b_add 950\n",
            "block7c_expand_conv 951\n",
            "block7c_expand_bn 952\n",
            "block7c_expand_activation 953\n",
            "block7c_dwconv2 954\n",
            "block7c_bn 955\n",
            "block7c_activation 956\n",
            "block7c_se_squeeze 957\n",
            "block7c_se_reshape 958\n",
            "block7c_se_reduce 959\n",
            "block7c_se_expand 960\n",
            "block7c_se_excite 961\n",
            "block7c_project_conv 962\n",
            "block7c_project_bn 963\n",
            "block7c_drop 964\n",
            "block7c_add 965\n",
            "block7d_expand_conv 966\n",
            "block7d_expand_bn 967\n",
            "block7d_expand_activation 968\n",
            "block7d_dwconv2 969\n",
            "block7d_bn 970\n",
            "block7d_activation 971\n",
            "block7d_se_squeeze 972\n",
            "block7d_se_reshape 973\n",
            "block7d_se_reduce 974\n",
            "block7d_se_expand 975\n",
            "block7d_se_excite 976\n",
            "block7d_project_conv 977\n",
            "block7d_project_bn 978\n",
            "block7d_drop 979\n",
            "block7d_add 980\n",
            "block7e_expand_conv 981\n",
            "block7e_expand_bn 982\n",
            "block7e_expand_activation 983\n",
            "block7e_dwconv2 984\n",
            "block7e_bn 985\n",
            "block7e_activation 986\n",
            "block7e_se_squeeze 987\n",
            "block7e_se_reshape 988\n",
            "block7e_se_reduce 989\n",
            "block7e_se_expand 990\n",
            "block7e_se_excite 991\n",
            "block7e_project_conv 992\n",
            "block7e_project_bn 993\n",
            "block7e_drop 994\n",
            "block7e_add 995\n",
            "block7f_expand_conv 996\n",
            "block7f_expand_bn 997\n",
            "block7f_expand_activation 998\n",
            "block7f_dwconv2 999\n",
            "block7f_bn 1000\n",
            "block7f_activation 1001\n",
            "block7f_se_squeeze 1002\n",
            "block7f_se_reshape 1003\n",
            "block7f_se_reduce 1004\n",
            "block7f_se_expand 1005\n",
            "block7f_se_excite 1006\n",
            "block7f_project_conv 1007\n",
            "block7f_project_bn 1008\n",
            "block7f_drop 1009\n",
            "block7f_add 1010\n",
            "block7g_expand_conv 1011\n",
            "block7g_expand_bn 1012\n",
            "block7g_expand_activation 1013\n",
            "block7g_dwconv2 1014\n",
            "block7g_bn 1015\n",
            "block7g_activation 1016\n",
            "block7g_se_squeeze 1017\n",
            "block7g_se_reshape 1018\n",
            "block7g_se_reduce 1019\n",
            "block7g_se_expand 1020\n",
            "block7g_se_excite 1021\n",
            "block7g_project_conv 1022\n",
            "block7g_project_bn 1023\n",
            "block7g_drop 1024\n",
            "block7g_add 1025\n",
            "top_conv 1026\n",
            "top_bn 1027\n",
            "top_activation 1028\n"
          ]
        }
      ],
      "source": [
        "model = EfficientNetV2L(include_top=False)\n",
        "\n",
        "n=1\n",
        "for layer in model.layers :\n",
        "  print(layer.name, n)\n",
        "  n+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tc7bsLCGtpg1",
        "outputId": "bbbd5f0f-f459-461c-8038-8607e9239cd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "############# Fold n°1 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 24.2072 - accuracy: 0.5294 - precision: 0.5287 - recall: 0.5412 - f1_score: 0.5349"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-26-3754e1aa0216>\", line 2, in <cell line: 2>\n",
            "    FineTuningKfoldingAugment(EfficientNetV2L, fine_layer_tune)\n",
            "  File \"<ipython-input-16-529488907e07>\", line 62, in FineTuningKfoldingAugment\n",
            "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 513, in recursive_create_dir_v2\n",
            "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: Saved_Model; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-26-3754e1aa0216>\", line 2, in <cell line: 2>\n",
            "    FineTuningKfoldingAugment(EfficientNetV2L, fine_layer_tune)\n",
            "  File \"<ipython-input-16-529488907e07>\", line 62, in FineTuningKfoldingAugment\n",
            "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 513, in recursive_create_dir_v2\n",
            "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: Saved_Model; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-26-3754e1aa0216>\", line 2, in <cell line: 2>\n",
            "    FineTuningKfoldingAugment(EfficientNetV2L, fine_layer_tune)\n",
            "  File \"<ipython-input-16-529488907e07>\", line 62, in FineTuningKfoldingAugment\n",
            "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 513, in recursive_create_dir_v2\n",
            "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: Saved_Model; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "fine_layer_tune=[981,951,923,848,728]\n",
        "FineTuningKfoldingAugment(EfficientNetV2L, fine_layer_tune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fqghzDdWxymK",
        "outputId": "ecf3a672-d965-423e-e563-f2613e38acd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_32 1\n",
            "conv1_pad 2\n",
            "conv1_conv 3\n",
            "pool1_pad 4\n",
            "pool1_pool 5\n",
            "conv2_block1_preact_bn 6\n",
            "conv2_block1_preact_relu 7\n",
            "conv2_block1_1_conv 8\n",
            "conv2_block1_1_bn 9\n",
            "conv2_block1_1_relu 10\n",
            "conv2_block1_2_pad 11\n",
            "conv2_block1_2_conv 12\n",
            "conv2_block1_2_bn 13\n",
            "conv2_block1_2_relu 14\n",
            "conv2_block1_0_conv 15\n",
            "conv2_block1_3_conv 16\n",
            "conv2_block1_out 17\n",
            "conv2_block2_preact_bn 18\n",
            "conv2_block2_preact_relu 19\n",
            "conv2_block2_1_conv 20\n",
            "conv2_block2_1_bn 21\n",
            "conv2_block2_1_relu 22\n",
            "conv2_block2_2_pad 23\n",
            "conv2_block2_2_conv 24\n",
            "conv2_block2_2_bn 25\n",
            "conv2_block2_2_relu 26\n",
            "conv2_block2_3_conv 27\n",
            "conv2_block2_out 28\n",
            "conv2_block3_preact_bn 29\n",
            "conv2_block3_preact_relu 30\n",
            "conv2_block3_1_conv 31\n",
            "conv2_block3_1_bn 32\n",
            "conv2_block3_1_relu 33\n",
            "conv2_block3_2_pad 34\n",
            "conv2_block3_2_conv 35\n",
            "conv2_block3_2_bn 36\n",
            "conv2_block3_2_relu 37\n",
            "max_pooling2d_10 38\n",
            "conv2_block3_3_conv 39\n",
            "conv2_block3_out 40\n",
            "conv3_block1_preact_bn 41\n",
            "conv3_block1_preact_relu 42\n",
            "conv3_block1_1_conv 43\n",
            "conv3_block1_1_bn 44\n",
            "conv3_block1_1_relu 45\n",
            "conv3_block1_2_pad 46\n",
            "conv3_block1_2_conv 47\n",
            "conv3_block1_2_bn 48\n",
            "conv3_block1_2_relu 49\n",
            "conv3_block1_0_conv 50\n",
            "conv3_block1_3_conv 51\n",
            "conv3_block1_out 52\n",
            "conv3_block2_preact_bn 53\n",
            "conv3_block2_preact_relu 54\n",
            "conv3_block2_1_conv 55\n",
            "conv3_block2_1_bn 56\n",
            "conv3_block2_1_relu 57\n",
            "conv3_block2_2_pad 58\n",
            "conv3_block2_2_conv 59\n",
            "conv3_block2_2_bn 60\n",
            "conv3_block2_2_relu 61\n",
            "conv3_block2_3_conv 62\n",
            "conv3_block2_out 63\n",
            "conv3_block3_preact_bn 64\n",
            "conv3_block3_preact_relu 65\n",
            "conv3_block3_1_conv 66\n",
            "conv3_block3_1_bn 67\n",
            "conv3_block3_1_relu 68\n",
            "conv3_block3_2_pad 69\n",
            "conv3_block3_2_conv 70\n",
            "conv3_block3_2_bn 71\n",
            "conv3_block3_2_relu 72\n",
            "conv3_block3_3_conv 73\n",
            "conv3_block3_out 74\n",
            "conv3_block4_preact_bn 75\n",
            "conv3_block4_preact_relu 76\n",
            "conv3_block4_1_conv 77\n",
            "conv3_block4_1_bn 78\n",
            "conv3_block4_1_relu 79\n",
            "conv3_block4_2_pad 80\n",
            "conv3_block4_2_conv 81\n",
            "conv3_block4_2_bn 82\n",
            "conv3_block4_2_relu 83\n",
            "max_pooling2d_11 84\n",
            "conv3_block4_3_conv 85\n",
            "conv3_block4_out 86\n",
            "conv4_block1_preact_bn 87\n",
            "conv4_block1_preact_relu 88\n",
            "conv4_block1_1_conv 89\n",
            "conv4_block1_1_bn 90\n",
            "conv4_block1_1_relu 91\n",
            "conv4_block1_2_pad 92\n",
            "conv4_block1_2_conv 93\n",
            "conv4_block1_2_bn 94\n",
            "conv4_block1_2_relu 95\n",
            "conv4_block1_0_conv 96\n",
            "conv4_block1_3_conv 97\n",
            "conv4_block1_out 98\n",
            "conv4_block2_preact_bn 99\n",
            "conv4_block2_preact_relu 100\n",
            "conv4_block2_1_conv 101\n",
            "conv4_block2_1_bn 102\n",
            "conv4_block2_1_relu 103\n",
            "conv4_block2_2_pad 104\n",
            "conv4_block2_2_conv 105\n",
            "conv4_block2_2_bn 106\n",
            "conv4_block2_2_relu 107\n",
            "conv4_block2_3_conv 108\n",
            "conv4_block2_out 109\n",
            "conv4_block3_preact_bn 110\n",
            "conv4_block3_preact_relu 111\n",
            "conv4_block3_1_conv 112\n",
            "conv4_block3_1_bn 113\n",
            "conv4_block3_1_relu 114\n",
            "conv4_block3_2_pad 115\n",
            "conv4_block3_2_conv 116\n",
            "conv4_block3_2_bn 117\n",
            "conv4_block3_2_relu 118\n",
            "conv4_block3_3_conv 119\n",
            "conv4_block3_out 120\n",
            "conv4_block4_preact_bn 121\n",
            "conv4_block4_preact_relu 122\n",
            "conv4_block4_1_conv 123\n",
            "conv4_block4_1_bn 124\n",
            "conv4_block4_1_relu 125\n",
            "conv4_block4_2_pad 126\n",
            "conv4_block4_2_conv 127\n",
            "conv4_block4_2_bn 128\n",
            "conv4_block4_2_relu 129\n",
            "conv4_block4_3_conv 130\n",
            "conv4_block4_out 131\n",
            "conv4_block5_preact_bn 132\n",
            "conv4_block5_preact_relu 133\n",
            "conv4_block5_1_conv 134\n",
            "conv4_block5_1_bn 135\n",
            "conv4_block5_1_relu 136\n",
            "conv4_block5_2_pad 137\n",
            "conv4_block5_2_conv 138\n",
            "conv4_block5_2_bn 139\n",
            "conv4_block5_2_relu 140\n",
            "conv4_block5_3_conv 141\n",
            "conv4_block5_out 142\n",
            "conv4_block6_preact_bn 143\n",
            "conv4_block6_preact_relu 144\n",
            "conv4_block6_1_conv 145\n",
            "conv4_block6_1_bn 146\n",
            "conv4_block6_1_relu 147\n",
            "conv4_block6_2_pad 148\n",
            "conv4_block6_2_conv 149\n",
            "conv4_block6_2_bn 150\n",
            "conv4_block6_2_relu 151\n",
            "max_pooling2d_12 152\n",
            "conv4_block6_3_conv 153\n",
            "conv4_block6_out 154\n",
            "conv5_block1_preact_bn 155\n",
            "conv5_block1_preact_relu 156\n",
            "conv5_block1_1_conv 157\n",
            "conv5_block1_1_bn 158\n",
            "conv5_block1_1_relu 159\n",
            "conv5_block1_2_pad 160\n",
            "conv5_block1_2_conv 161\n",
            "conv5_block1_2_bn 162\n",
            "conv5_block1_2_relu 163\n",
            "conv5_block1_0_conv 164\n",
            "conv5_block1_3_conv 165\n",
            "conv5_block1_out 166\n",
            "conv5_block2_preact_bn 167\n",
            "conv5_block2_preact_relu 168\n",
            "conv5_block2_1_conv 169\n",
            "conv5_block2_1_bn 170\n",
            "conv5_block2_1_relu 171\n",
            "conv5_block2_2_pad 172\n",
            "conv5_block2_2_conv 173\n",
            "conv5_block2_2_bn 174\n",
            "conv5_block2_2_relu 175\n",
            "conv5_block2_3_conv 176\n",
            "conv5_block2_out 177\n",
            "conv5_block3_preact_bn 178\n",
            "conv5_block3_preact_relu 179\n",
            "conv5_block3_1_conv 180\n",
            "conv5_block3_1_bn 181\n",
            "conv5_block3_1_relu 182\n",
            "conv5_block3_2_pad 183\n",
            "conv5_block3_2_conv 184\n",
            "conv5_block3_2_bn 185\n",
            "conv5_block3_2_relu 186\n",
            "conv5_block3_3_conv 187\n",
            "conv5_block3_out 188\n",
            "post_bn 189\n",
            "post_relu 190\n"
          ]
        }
      ],
      "source": [
        "model = ResNet50V2(include_top=False)\n",
        "\n",
        "n=1\n",
        "for layer in model.layers :\n",
        "  print(layer.name, n)\n",
        "  n+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EtP1JcOotpjQ",
        "outputId": "358e060c-1458-4834-97a2-d9190577a6d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "############# Fold n°1 #############\n",
            "len(y_train) : 140 and len(y_val) : 30\n",
            "Epoch 1/200\n",
            "35/35 [==============================] - ETA: 0s - loss: 30.1187 - accuracy: 0.5118 - precision: 0.5098 - recall: 0.6118 - f1_score: 0.5561"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-06a8ceece436>\", line 2, in <cell line: 2>\n",
            "    FineTuningKfoldingAugment(ResNet50V2, fine_layer_tune)\n",
            "  File \"<ipython-input-16-529488907e07>\", line 62, in FineTuningKfoldingAugment\n",
            "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 513, in recursive_create_dir_v2\n",
            "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: Saved_Model; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-06a8ceece436>\", line 2, in <cell line: 2>\n",
            "    FineTuningKfoldingAugment(ResNet50V2, fine_layer_tune)\n",
            "  File \"<ipython-input-16-529488907e07>\", line 62, in FineTuningKfoldingAugment\n",
            "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 513, in recursive_create_dir_v2\n",
            "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: Saved_Model; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-06a8ceece436>\", line 2, in <cell line: 2>\n",
            "    FineTuningKfoldingAugment(ResNet50V2, fine_layer_tune)\n",
            "  File \"<ipython-input-16-529488907e07>\", line 62, in FineTuningKfoldingAugment\n",
            "    history_fine.append(model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 513, in recursive_create_dir_v2\n",
            "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: Saved_Model; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "fine_layer_tune=[178,167,155,87]\n",
        "FineTuningKfoldingAugment(ResNet50V2, fine_layer_tune)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPUWIsB5tg7Q"
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_FqrtGcbbZvM",
        "outputId": "7fac940a-25c6-4170-b71c-f38128cf3cee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-6a169b20a420>\", line 3, in <cell line: 3>\n",
            "    X, y = create_dataset(my_path, my_classes)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 2, in create_dataset\n",
            "    X,y=create_X_y(my_path, my_classes, gray, onehot)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 30, in create_X_y\n",
            "    training_data=create_training_data(path_data, list_classes, gray)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 15, in create_training_data\n",
            "    for img in os.listdir(path):\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'Tiger-Fox-Elephant/tiger'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-6a169b20a420>\", line 3, in <cell line: 3>\n",
            "    X, y = create_dataset(my_path, my_classes)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 2, in create_dataset\n",
            "    X,y=create_X_y(my_path, my_classes, gray, onehot)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 30, in create_X_y\n",
            "    training_data=create_training_data(path_data, list_classes, gray)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 15, in create_training_data\n",
            "    for img in os.listdir(path):\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'Tiger-Fox-Elephant/tiger'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-6a169b20a420>\", line 3, in <cell line: 3>\n",
            "    X, y = create_dataset(my_path, my_classes)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 2, in create_dataset\n",
            "    X,y=create_X_y(my_path, my_classes, gray, onehot)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 30, in create_X_y\n",
            "    training_data=create_training_data(path_data, list_classes, gray)\n",
            "  File \"<ipython-input-4-0197af54f8ad>\", line 15, in create_training_data\n",
            "    for img in os.listdir(path):\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'Tiger-Fox-Elephant/tiger'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "my_path=\"Tiger-Fox-Elephant/\"\n",
        "my_classes=['tiger','Tiger_negative_class']\n",
        "X, y = create_dataset(my_path, my_classes)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=SEED) # .15 pour kfold et .3 pour normal\n",
        "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5, random_state=SEED)\n",
        "print(f\"Taille de X_train : {len(X_train)}, Taille de X_val : {len(X_val)}, Taille de X_test : {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l8Ggk_yRqWTM",
        "outputId": "6e30f938-f5df-46cf-b31e-521a2f849cc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-e2b42a7d56cd>\", line 2, in <cell line: 2>\n",
            "    histories3, score3 = trainModelNumpyAugment(stacked_model(ListModel))\n",
            "  File \"<ipython-input-19-bff3f6336977>\", line 6, in stacked_model\n",
            "    model = load_model(pathModel)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\", line 238, in load_model\n",
            "    return legacy_sm_saving_lib.load_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\", line 234, in load_model\n",
            "    raise IOError(\n",
            "OSError: No file or directory found at Saved_Model/TLModelArchi_2VGG16.h5\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-e2b42a7d56cd>\", line 2, in <cell line: 2>\n",
            "    histories3, score3 = trainModelNumpyAugment(stacked_model(ListModel))\n",
            "  File \"<ipython-input-19-bff3f6336977>\", line 6, in stacked_model\n",
            "    model = load_model(pathModel)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\", line 238, in load_model\n",
            "    return legacy_sm_saving_lib.load_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\", line 234, in load_model\n",
            "    raise IOError(\n",
            "OSError: No file or directory found at Saved_Model/TLModelArchi_2VGG16.h5\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-e2b42a7d56cd>\", line 2, in <cell line: 2>\n",
            "    histories3, score3 = trainModelNumpyAugment(stacked_model(ListModel))\n",
            "  File \"<ipython-input-19-bff3f6336977>\", line 6, in stacked_model\n",
            "    model = load_model(pathModel)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\", line 238, in load_model\n",
            "    return legacy_sm_saving_lib.load_model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\", line 234, in load_model\n",
            "    raise IOError(\n",
            "OSError: No file or directory found at Saved_Model/TLModelArchi_2VGG16.h5\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "ListModel=[\"Saved_Model/TLModelArchi_2VGG16.h5\",\"Saved_Model/TLModelArchi_2EfficientNetV2L.h5\", \"Saved_Model/TLModelArchi_2ResNet50V2.h5\"]\n",
        "trainModelNumpyAugment(stacked_model(ListModel))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ocC1yn8CKaz6",
        "RgJXlCHq3r72",
        "-fO3DjX0KhRG",
        "pO0rPpWc_ND4",
        "YZDJWo7cumO8",
        "mNgUyG-77NIP",
        "x9_70PLgD8Mx",
        "9SmGUOXAtl5z",
        "bPUWIsB5tg7Q"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}